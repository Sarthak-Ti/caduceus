# @package _global_
defaults:
  - /trainer: default
  - /loader: default
  - /dataset: DNase #this refers to the yaml file, reuse it just say classification = True override
  # - /task: regression #one of the options, uses mse loss
  - /optimizer: adamw
  - /scheduler: plateau #this gets overridden
  - /callbacks: [base, model_every_epoch]

train:
  monitor: val/loss # the metric to monitor for early stopping, the loss is what is shown below
  mode: min

task:
  _name_: regression
  loss: custom_mse_ce #this is the loss function, mse for regression, ce for classification, combines them in this custom way
  # torchmetrics: ['mse'] no need for this I don't think like perplexity, we just care about mse

encoder: id
decoder:
  _name_: sequence #the generic class, could do NDDecoder too
  mode: pool #to average the embeddings