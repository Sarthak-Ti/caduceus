{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# understanding_hyena.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shap_analysis.ism_utils import *\n",
    "multitasking_path1 = '/data/leslie/sarthak/hyena/hyena-dna/outputs/2024-03-27/18-39-11-031863/checkpoints/25-val_loss=0.52186.ckpt' #the 25 epoch one\n",
    "mult = ISMUtils('DNase_allcelltypes', multitasking_path1, classification=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNAEmbeddingModel(\n",
       "  (backbone): LMBackbone(\n",
       "    (embeddings): GPT2Embeddings(\n",
       "      (word_embeddings): Embedding(16, 128)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): Block(\n",
       "        (mixer): HyenaOperator(\n",
       "          (activation): Identity()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (in_proj): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (short_filter): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(2,), groups=384)\n",
       "          (filter_fn): HyenaFilter(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb): PositionalEmbedding()\n",
       "            (implicit_filter): Sequential(\n",
       "              (0): Linear(in_features=5, out_features=64, bias=True)\n",
       "              (1): Sin()\n",
       "              (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (3): Sin()\n",
       "              (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (5): Sin()\n",
       "              (6): Linear(in_features=64, out_features=128, bias=False)\n",
       "            )\n",
       "            (modulation): ExponentialModulation()\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Block(\n",
       "        (mixer): HyenaOperator(\n",
       "          (activation): Identity()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (in_proj): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (short_filter): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(2,), groups=384)\n",
       "          (filter_fn): HyenaFilter(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb): PositionalEmbedding()\n",
       "            (implicit_filter): Sequential(\n",
       "              (0): Linear(in_features=5, out_features=64, bias=True)\n",
       "              (1): Sin()\n",
       "              (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (3): Sin()\n",
       "              (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (5): Sin()\n",
       "              (6): Linear(in_features=64, out_features=128, bias=False)\n",
       "            )\n",
       "            (modulation): ExponentialModulation()\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (drop_f): Dropout(p=0.0, inplace=False)\n",
       "    (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=128, out_features=16, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mult.model\n",
    "mult.backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LMBackbone(\n",
       "  (embeddings): GPT2Embeddings(\n",
       "    (word_embeddings): Embedding(16, 128)\n",
       "  )\n",
       "  (layers): ModuleList(\n",
       "    (0): Block(\n",
       "      (mixer): HyenaOperator(\n",
       "        (activation): Identity()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (in_proj): Linear(in_features=128, out_features=384, bias=True)\n",
       "        (short_filter): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(2,), groups=384)\n",
       "        (filter_fn): HyenaFilter(\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (pos_emb): PositionalEmbedding()\n",
       "          (implicit_filter): Sequential(\n",
       "            (0): Linear(in_features=5, out_features=64, bias=True)\n",
       "            (1): Sin()\n",
       "            (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (3): Sin()\n",
       "            (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (5): Sin()\n",
       "            (6): Linear(in_features=64, out_features=128, bias=False)\n",
       "          )\n",
       "          (modulation): ExponentialModulation()\n",
       "        )\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (mixer): HyenaOperator(\n",
       "        (activation): Identity()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (in_proj): Linear(in_features=128, out_features=384, bias=True)\n",
       "        (short_filter): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(2,), groups=384)\n",
       "        (filter_fn): HyenaFilter(\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (pos_emb): PositionalEmbedding()\n",
       "          (implicit_filter): Sequential(\n",
       "            (0): Linear(in_features=5, out_features=64, bias=True)\n",
       "            (1): Sin()\n",
       "            (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (3): Sin()\n",
       "            (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (5): Sin()\n",
       "            (6): Linear(in_features=64, out_features=128, bias=False)\n",
       "          )\n",
       "          (modulation): ExponentialModulation()\n",
       "        )\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.0, inplace=False)\n",
       "      (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (drop_f): Dropout(p=0.0, inplace=False)\n",
       "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mult.backbone.backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1023]) tensor([[ 9,  9, 10,  ...,  8, 10,  8]])\n"
     ]
    }
   ],
   "source": [
    "#we can see the model's makeup, let's look at the backbone first\n",
    "data = mult.dataset[0][0].unsqueeze(0)\n",
    "print(data.shape, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1023, 128]) tensor([[[-0.2054,  0.3849, -0.6309,  ..., -0.2791, -0.2442,  0.3236],\n",
      "         [-0.1926,  0.3297, -0.6444,  ..., -0.2739, -0.2438,  0.2496],\n",
      "         [-0.1883,  0.2711, -0.7615,  ..., -0.2748, -0.2304,  0.3415],\n",
      "         ...,\n",
      "         [-0.1865, -1.4684, -0.0480,  ..., -0.2488, -0.2046,  0.4700],\n",
      "         [-0.1858, -1.8168, -0.2808,  ..., -0.2550, -0.1811,  0.4815],\n",
      "         [-0.1853, -1.4642, -0.5938,  ..., -0.2672, -0.1692, -0.1404]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "data1 = mult.backbone.backbone(data)\n",
    "print(data1.shape, data1) #this is the output of the backbone? without the Lm head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 torch.Size([1, 1023, 128]) None\n",
      "(tensor([[[-0.2054,  0.3849, -0.6309,  ..., -0.2791, -0.2442,  0.3236],\n",
      "         [-0.1926,  0.3297, -0.6444,  ..., -0.2739, -0.2438,  0.2496],\n",
      "         [-0.1883,  0.2711, -0.7615,  ..., -0.2748, -0.2304,  0.3415],\n",
      "         ...,\n",
      "         [-0.1865, -1.4684, -0.0480,  ..., -0.2488, -0.2046,  0.4700],\n",
      "         [-0.1858, -1.8168, -0.2808,  ..., -0.2550, -0.1811,  0.4815],\n",
      "         [-0.1853, -1.4642, -0.5938,  ..., -0.2672, -0.1692, -0.1404]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), None)\n"
     ]
    }
   ],
   "source": [
    "data2 = mult.backbone(data)\n",
    "print(len(data2), data2[0].shape,data2[1]) #this is the output of the backbone with the Lm head\n",
    "#here we see it's again 128 for each of the sequence elements\n",
    "#the none that is the second output of the backbone is something\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceDecoder(\n",
       "  (output_transform): Linear(in_features=128, out_features=322, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now let's go through the decoder head\n",
    "mult.decoder #this is the multitasking, goes from 128 to 322\n",
    "\n",
    "#ahhhh it compresses it using pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 322]) tensor([[-0.5049, -0.3075,  1.8645,  3.5166,  2.3568,  2.1814,  3.6842,  2.7295,\n",
      "          1.4710,  3.9252,  3.4050,  0.4614, -0.1982,  3.5546,  2.3553,  0.5559,\n",
      "          0.3023,  1.0751,  0.1795,  3.8263,  2.1100,  1.1665,  1.9441,  1.7290,\n",
      "          0.9602, -0.3431,  3.2601,  0.0533,  1.0779, -1.2215,  3.5453,  0.3740,\n",
      "          2.3839, -1.4882,  2.3575,  1.9609,  2.0365,  3.3059, -0.0380, -0.1618,\n",
      "         -0.4768, -1.1979, -0.3500, -0.5653, -1.2556,  0.7909,  0.9702, -0.0731,\n",
      "         -0.7344, -0.1408, -0.5081,  0.8514,  0.1175,  2.1414, -0.1052,  0.5142,\n",
      "          2.5591,  3.6029,  0.8347, -0.0326,  3.7486,  3.3513,  0.5822,  3.4517,\n",
      "          0.7170,  4.8885,  4.4089,  2.3378, -0.0816, -0.5852,  0.1949,  4.2735,\n",
      "         -0.2658,  1.2450,  4.0940,  4.2701,  4.4384,  4.4356,  0.2521,  0.0809,\n",
      "         -0.5427,  4.5116,  4.6212,  1.4247,  2.5012,  3.3803,  1.9500,  2.2894,\n",
      "          2.1764,  1.4053,  0.6714,  1.6953,  2.1111,  0.3320,  4.6367,  0.2180,\n",
      "         -0.3760,  2.1558,  2.1425, -1.5603,  0.5191,  2.1452,  1.0656,  0.8716,\n",
      "          1.4692,  1.6508,  2.7905, -0.4948,  2.1949,  2.5103,  0.9560,  2.4485,\n",
      "          1.9199,  2.3953,  1.4638,  2.5191,  1.8426,  0.9822,  2.2491,  1.7851,\n",
      "          5.0526,  2.4460,  3.3815,  4.5526,  2.3095,  1.7001,  1.9577,  3.4479,\n",
      "          4.6120,  2.3329,  3.2885,  0.5582,  2.1791,  0.9706, -0.3928,  1.1247,\n",
      "          2.3118,  3.9929,  3.8823,  1.8996,  2.9756,  3.8925,  3.8173,  1.7615,\n",
      "          0.9356,  2.1155,  3.1153,  0.9135,  4.1382,  0.6857,  2.0990,  3.1391,\n",
      "          0.6748, -1.2511,  2.0774,  2.2696,  2.3669,  0.9463,  0.3390,  2.2537,\n",
      "          2.3121,  0.3875,  0.0714,  1.0731,  0.7054,  0.9084,  0.6656,  0.8164,\n",
      "          0.6449,  0.7014,  0.4746,  0.4707,  0.2848,  0.1142,  0.3343,  0.4163,\n",
      "          0.5520,  0.4462,  0.4710,  0.5179,  0.5524,  1.0069,  0.1151,  1.0442,\n",
      "          0.8461,  0.7044,  0.5662,  1.0032,  0.1473,  0.8316,  0.0952,  0.7097,\n",
      "          0.4768,  0.4738,  0.1189,  1.0701,  0.4725,  0.9627,  1.4720,  0.7631,\n",
      "          0.7638,  1.0048,  0.7108,  0.8526,  0.9014,  0.5904,  1.1075,  1.2179,\n",
      "          1.0989,  0.7399,  0.8238,  0.9205,  0.1696,  0.9592,  1.2195,  0.6594,\n",
      "          0.9289,  1.4212,  1.0632,  0.5329,  0.8076,  0.9690,  1.0288,  0.9000,\n",
      "          1.2860,  1.6596,  1.5904,  0.7314,  1.2310,  0.8708,  1.1157,  1.0084,\n",
      "          1.1516,  1.0427,  0.7186,  1.2268,  1.0279,  1.0695,  1.2515,  1.0497,\n",
      "          1.1727,  0.7142,  1.0526,  0.8535,  1.2411,  1.3615,  1.3563,  1.2631,\n",
      "          0.8846,  1.0728,  1.1282,  1.5195,  1.0826,  1.2508,  1.1368,  1.6205,\n",
      "          0.8572,  0.8324,  1.3571,  0.7673,  0.3738,  1.4606,  1.1894,  0.6817,\n",
      "          1.3452,  1.3268,  0.4498,  1.2825,  0.7523,  1.7655,  0.2458,  0.9861,\n",
      "          0.8265,  1.3905,  1.2859,  0.6927,  0.5935,  1.5042,  1.2600,  1.3017,\n",
      "          0.2953,  0.7567,  0.8536,  0.6720,  1.2573,  1.5696,  1.0212,  1.2499,\n",
      "          1.0796,  1.4073,  1.0958,  1.2227,  0.4253,  1.5842,  1.2430,  0.5850,\n",
      "          1.1234,  1.1305,  0.8833,  1.1017,  0.6260,  1.0769,  0.3043,  1.1028,\n",
      "          1.0221,  0.8215,  1.4231,  1.2471,  0.6784,  1.1124,  0.4475,  1.6841,\n",
      "          0.9264,  1.4329,  0.3065,  0.9081,  0.5072,  0.6755,  1.0288,  1.1698,\n",
      "          0.8347,  1.4555]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#this is the output of the decoder\n",
    "data3 = mult.decoder(data2[0])\n",
    "print(data3.shape, data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1023, 128])\n"
     ]
    }
   ],
   "source": [
    "restrict = lambda x: (\n",
    "    torch.cumsum(x, dim=-2)\n",
    "    / torch.arange(\n",
    "        1, 1 + x.size(-2), device=x.device, dtype=x.dtype\n",
    "    ).unsqueeze(-1)\n",
    ")[..., -l_output:, :]\n",
    "l_output = 1024\n",
    "out = restrict(data2[0])\n",
    "print(out.shape)\n",
    "#hmmm so it does indeed keep the shape..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1023, 128])\n"
     ]
    }
   ],
   "source": [
    "restrict = lambda x: torch.cumsum(x, dim=-2)[..., -l_output:, :]\n",
    "out2 = restrict(data2[0])\n",
    "print(out2.shape)\n",
    "#ok this also doesn't actually reduce the dimensionality, so what does??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1023, 128])\n"
     ]
    }
   ],
   "source": [
    "#this is mode last\n",
    "restrict = lambda x: x[..., -l_output:, :] #yeah obviously this doesn't reduce the shape at all!!!\n",
    "out3 = restrict(data2[0])\n",
    "print(out3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1023, 128])\n"
     ]
    }
   ],
   "source": [
    "#I think l_output is actually 0, if that is the case, then what we have is\n",
    "l_output = 0\n",
    "restrict = lambda x: (\n",
    "    torch.cumsum(x, dim=-2)\n",
    "    / torch.arange(\n",
    "        1, 1 + x.size(-2), device=x.device, dtype=x.dtype\n",
    "    ).unsqueeze(-1)\n",
    ")[..., -l_output:, :]\n",
    "# l_output = 1024\n",
    "out = restrict(data2[0])\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:,-0,:] == out[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:,0,:] == out[:,-0,:] #yeah so -0 and 0 are identical..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1023, 128])\n"
     ]
    }
   ],
   "source": [
    "#wait so are we maybe messing up? in ism utils we define l_output=0 because that is what we see...\n",
    "#maybe we're doing it wrong and that's not what the real decoder is doing? I'm so confused!\n",
    "#if l_output is 1 then it takes -1:, but 0: means all, so like taking the full length!\n",
    "l_output = 0\n",
    "restrict = lambda x: (\n",
    "    torch.cumsum(x, dim=-2)\n",
    "    / torch.arange(\n",
    "        1, 1 + x.size(-2), device=x.device, dtype=x.dtype\n",
    "    ).unsqueeze(-1)\n",
    ")[..., -l_output:, :]\n",
    "# l_output = 1024\n",
    "out = restrict(data2[0])\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceDecoder(\n",
       "  (output_transform): Linear(in_features=128, out_features=322, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mult.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oh my god, it turns 0 to 1, so we only take the last element\n",
    "#the last element of pool is the same as just the average... oh my god!\n",
    "#such a complex approach to do the most simple thing!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figure out how the masking technique works when we are doing a language modeling task!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's figure this out!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
