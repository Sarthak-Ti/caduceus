{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation graph reg 2\n",
    "\n",
    "the point of this is to evaluate the CNN graph reg model in pytorch, we have it saved, can simply load it in! No decoder or anything, so simply define the model and load it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_path: /data1/lesliec/sarthak/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': {'seed': 2222,\n",
       "  'interval': 'epoch',\n",
       "  'monitor': 'val/loss',\n",
       "  'mode': 'min',\n",
       "  'ema': 0.0,\n",
       "  'test': True,\n",
       "  'debug': False,\n",
       "  'ignore_warnings': False,\n",
       "  'optimizer_param_grouping': {'bias_weight_decay': False,\n",
       "   'normalization_weight_decay': False},\n",
       "  'state': {'mode': None, 'n_context': 0, 'n_context_eval': '${.n_context}'},\n",
       "  'ckpt': 'checkpoints/last.ckpt',\n",
       "  'disable_dataset': False,\n",
       "  'validate_at_start': False,\n",
       "  'pretrained_model_path': None,\n",
       "  'pretrained_model_strict_load': True,\n",
       "  'pretrained_model_state_hook': {'_name_': None},\n",
       "  'post_init_hook': {'_name_': None},\n",
       "  'layer_decay': {'_name_': None, 'decay': 0.7},\n",
       "  'gpu_mem': '${eval:\"round(float(__import__(\\'subprocess\\').check_output(\\'nvidia-smi -i 0 --query-gpu=memory.total --format=csv,noheader,nounits\\', shell=True).strip().decode()) / 1000)\"}',\n",
       "  'global_batch_size': '${dataset.batch_size}'},\n",
       " 'wandb': {'project': 'dna',\n",
       "  'group': 'graphreg',\n",
       "  'job_type': 'training',\n",
       "  'mode': 'online',\n",
       "  'name': 'GR_pure_CNN_100k',\n",
       "  'save_dir': '.',\n",
       "  'id': '${.name}'},\n",
       " 'trainer': {'_target_': 'pytorch_lightning.Trainer',\n",
       "  'devices': 1,\n",
       "  'accelerator': 'gpu',\n",
       "  'accumulate_grad_batches': '${div_up:${train.global_batch_size}, ${eval:${trainer.devices} * ${dataset.batch_size} * ${trainer.num_nodes}}}',\n",
       "  'max_epochs': 200,\n",
       "  'gradient_clip_val': 1.0,\n",
       "  'log_every_n_steps': 10,\n",
       "  'limit_train_batches': 1.0,\n",
       "  'limit_val_batches': 1.0,\n",
       "  'num_sanity_val_steps': 0,\n",
       "  'num_nodes': 1,\n",
       "  'precision': 'bf16',\n",
       "  'strategy': 'auto'},\n",
       " 'loader': {'num_workers': '${eval:\"len(__import__(\\'os\\').sched_getaffinity(0))\"}',\n",
       "  'pin_memory': True,\n",
       "  'drop_last': True},\n",
       " 'dataset': {'_name_': 'GraphRegLoader',\n",
       "  'bed_file': None,\n",
       "  'fasta_file': None,\n",
       "  'dataset_name': 'GraphRegLoader',\n",
       "  'tokenizer_name': 'char',\n",
       "  'cache_dir': None,\n",
       "  'max_length': 100000,\n",
       "  'add_eos': False,\n",
       "  'batch_size': 128,\n",
       "  'batch_size_eval': 128,\n",
       "  'num_workers': 4,\n",
       "  'shuffle': True,\n",
       "  'pin_memory': True,\n",
       "  '__train_len': '${div_up:1_000_000_000, ${.max_length}}',\n",
       "  '__l_max': '${.max_length}',\n",
       "  'max_length_val': '${dataset.max_length}',\n",
       "  'max_length_test': '${dataset.max_length}',\n",
       "  'pad_max_length': None,\n",
       "  'rc_aug': False,\n",
       "  'use_fixed_len_val': False,\n",
       "  'replace_N_token': False,\n",
       "  'pad_interval': False,\n",
       "  'kmer_len': None,\n",
       "  'cell_type': 'K562',\n",
       "  'vocab_size': '${model.config.vocab_size}',\n",
       "  'one_hot': True,\n",
       "  'clean_data': True,\n",
       "  'remove_repeats': True},\n",
       " 'optimizer': {'_name_': 'adamw',\n",
       "  'lr': 8e-05,\n",
       "  'weight_decay': 0.1,\n",
       "  'betas': [0.9, 0.999]},\n",
       " 'scheduler': {'_name_': 'plateau',\n",
       "  'mode': '${train.mode}',\n",
       "  'factor': 0.2,\n",
       "  'patience': 20,\n",
       "  'min_lr': 0.0},\n",
       " 'callbacks': {'learning_rate_monitor': {'logging_interval': '${train.interval}'},\n",
       "  'timer': {'step': True, 'inter_step': False, 'epoch': True, 'val': True},\n",
       "  'params': {'total': True, 'trainable': True, 'fixed': True},\n",
       "  'model_checkpoint': {'monitor': '${train.monitor}',\n",
       "   'mode': '${train.mode}',\n",
       "   'save_top_k': -1,\n",
       "   'save_last': True,\n",
       "   'dirpath': 'checkpoints/',\n",
       "   'filename': '{epoch:02d}-val_loss={val/loss:.5f}',\n",
       "   'auto_insert_metric_name': False,\n",
       "   'verbose': True,\n",
       "   'every_n_epochs': 1}},\n",
       " 'task': {'_name_': 'basic',\n",
       "  'loss': 'poisson_loss',\n",
       "  'metrics': ['poisson_loss']},\n",
       " 'encoder': 'id',\n",
       " 'decoder': 'id',\n",
       " 'model': {'_name_': 'graph_reg_conv',\n",
       "  'one_hot': True,\n",
       "  'input_len': '${dataset.__l_max}',\n",
       "  'config': {'vocab_size': 4}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/data/leslie/sarthak/caduceus/')\n",
    "from caduceus.configuration_caduceus import CaduceusConfig\n",
    "import torch\n",
    "import numpy as np\n",
    "import src.dataloaders.datasets.graphreg_dataset as d\n",
    "import yaml\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "ckpt_path = '/data1/lesliec/sarthak/caduceus/outputs/2024-11-27/15-08-13-584820/checkpoints/last.ckpt'\n",
    "\n",
    "model_cfg_path = os.path.join(os.path.dirname(os.path.dirname(ckpt_path)), '.hydra', 'config.yaml')\n",
    "cfg = yaml.load(open(model_cfg_path, 'r'), Loader=yaml.FullLoader)\n",
    "\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(ckpt_path, map_location='cpu')\n",
    "dataset_args = cfg['dataset']\n",
    "split = 'test'\n",
    "dataset = d.GraphRegDataset(split, dataset_args['max_length'], rc_aug = dataset_args['rc_aug'],\n",
    "                                                            cell_type=dataset_args.get('cell_type', None),\n",
    "                                                            kmer_len=dataset_args.get('kmer_len', None),\n",
    "                                                            remove_repeats=dataset_args.get('remove_repeats', False),\n",
    "                                                            has_TSS=dataset_args.get('has_TSS', False),\n",
    "                                                            clean_data=dataset_args.get('clean_data', True),\n",
    "                                                            vocab_size=cfg['model']['config']['vocab_size'],\n",
    "                                                            one_hot = dataset_args['one_hot'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_name_': 'GraphRegLoader',\n",
       " 'bed_file': None,\n",
       " 'fasta_file': None,\n",
       " 'dataset_name': 'GraphRegLoader',\n",
       " 'tokenizer_name': 'char',\n",
       " 'cache_dir': None,\n",
       " 'max_length': 100000,\n",
       " 'add_eos': False,\n",
       " 'batch_size': 128,\n",
       " 'batch_size_eval': 128,\n",
       " 'num_workers': 4,\n",
       " 'shuffle': True,\n",
       " 'pin_memory': True,\n",
       " '__train_len': '${div_up:1_000_000_000, ${.max_length}}',\n",
       " '__l_max': '${.max_length}',\n",
       " 'max_length_val': '${dataset.max_length}',\n",
       " 'max_length_test': '${dataset.max_length}',\n",
       " 'pad_max_length': None,\n",
       " 'rc_aug': False,\n",
       " 'use_fixed_len_val': False,\n",
       " 'replace_N_token': False,\n",
       " 'pad_interval': False,\n",
       " 'kmer_len': None,\n",
       " 'cell_type': 'K562',\n",
       " 'vocab_size': '${model.config.vocab_size}',\n",
       " 'one_hot': True,\n",
       " 'clean_data': True,\n",
       " 'remove_repeats': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "    state_dict[\"state_dict\"], \"model.\"\n",
    ")\n",
    "model_state_dict = state_dict[\"state_dict\"]\n",
    "# need to remove torchmetrics. to remove keys, need to convert to list first\n",
    "for key in list(model_state_dict.keys()):\n",
    "    if \"torchmetrics\" in key:\n",
    "        model_state_dict.pop(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_name_': 'graph_reg_conv',\n",
       " 'one_hot': True,\n",
       " 'input_len': '${dataset.__l_max}'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg['model'].pop('config')\n",
    "cfg['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.sequence.conv import GraphRegConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GraphRegConvNet(**cfg['model'])\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphRegConvNet(\n",
       "  (conv1): Conv1d(4, 256, kernel_size=(21,), stride=(1,), padding=same)\n",
       "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (mp1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dp1): Dropout(p=0.5, inplace=False)\n",
       "  (conv2): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=same)\n",
       "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (mp2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dp2): Dropout(p=0.5, inplace=False)\n",
       "  (conv3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same)\n",
       "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (mp3): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dp3): Dropout(p=0.5, inplace=False)\n",
       "  (conv4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same)\n",
       "  (bn4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (mp4): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dp4): Dropout(p=0.5, inplace=False)\n",
       "  (conv5): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=same)\n",
       "  (bn5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dp5): Dropout(p=0.5, inplace=False)\n",
       "  (conv6_1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(2,))\n",
       "  (bn6_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dp6_1): Dropout(p=0.5, inplace=False)\n",
       "  (conv6_2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(4,))\n",
       "  (bn6_2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dp6_2): Dropout(p=0.5, inplace=False)\n",
       "  (conv6_3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(8,))\n",
       "  (bn6_3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dp6_3): Dropout(p=0.5, inplace=False)\n",
       "  (conv6_4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(16,))\n",
       "  (bn6_4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dp6_4): Dropout(p=0.5, inplace=False)\n",
       "  (conv6_5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(32,))\n",
       "  (bn6_5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dp6_5): Dropout(p=0.5, inplace=False)\n",
       "  (conv6_6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(64,))\n",
       "  (bn6_6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dp6_6): Dropout(p=0, inplace=False)\n",
       "  (conv_me3): Conv1d(64, 1, kernel_size=(5,), stride=(1,), padding=same)\n",
       "  (conv_27ac): Conv1d(64, 1, kernel_size=(5,), stride=(1,), padding=same)\n",
       "  (conv_dnase): Conv1d(64, 1, kernel_size=(5,), stride=(1,), padding=same)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 100000]), torch.Size([1000, 3]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = dataset[0]\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(a.unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2756"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'train'\n",
    "dataset = d.GraphRegDataset(split, dataset_args['max_length'], rc_aug = dataset_args['rc_aug'],\n",
    "                                                            cell_type=dataset_args.get('cell_type', None),\n",
    "                                                            kmer_len=dataset_args.get('kmer_len', None),\n",
    "                                                            remove_repeats=dataset_args.get('remove_repeats', False),\n",
    "                                                            has_TSS=dataset_args.get('has_TSS', False),\n",
    "                                                            clean_data=dataset_args.get('clean_data', True),\n",
    "                                                            one_hot = dataset_args['one_hot'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21165"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 662/662 [01:32<00:00,  7.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "true_vals = np.zeros((len(dataset),1000,3))\n",
    "pred_vals = np.zeros((len(dataset),1000,3))\n",
    "#now make a dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "idx = 0\n",
    "#can also do torch no grad if want bigger batch size, but this is fast enough\n",
    "for i, (x, y) in enumerate(tqdm(dataloader)):\n",
    "    pred = model(x.cuda())\n",
    "    true_vals[idx:idx+x.shape[0]] = y.detach().cpu().numpy()\n",
    "    pred_vals[idx:idx+x.shape[0]] = pred.detach().cpu().numpy()\n",
    "    idx += x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print((true_vals.sum(0) == 0).sum()) #now many rows are 0\n",
    "print((true_vals.sum(1) == 0).sum())\n",
    "#and for pred\n",
    "print((pred_vals.sum(0) == 0).sum()) #now many rows are 0\n",
    "print((pred_vals.sum(1) == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#true vals differs a bit, uh oh\n",
    "true = np.load('/data1/lesliec/sarthak/data/GraphReg/model_out/true_train.npy')\n",
    "np.allclose(true_vals, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21165, 1000, 3) (21165, 1000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(true.shape, true_vals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(true_vals[0] == dataset[0][1].numpy()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    assert (true_vals[i] == dataset[i][1].numpy()).all()\n",
    "\n",
    "#ok so this is indeed correct, telling us there's some difference between the datasets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120.16015625"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(true-true_vals).max() #yeah that's huge!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m d\u001b[38;5;241m.\u001b[39mGraphRegDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100_000\u001b[39m, clean_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, one_hot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, remove_repeats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset)):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (true_vals[i] \u001b[38;5;241m==\u001b[39m dataset[i][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy())\u001b[38;5;241m.\u001b[39mall()\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = d.GraphRegDataset('train', 100_000, clean_data=True, one_hot=True, remove_repeats=True)\n",
    "#so we seem to have given some values that are different?\n",
    "for i in range(len(dataset)):\n",
    "    assert (true_vals[i] == dataset[i][1].numpy()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21165,)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "a = (true_vals == true).all(2).all(1)\n",
    "print(a.shape)\n",
    "print(sum(a)) #so none of these values are corect whereas it seems like above the issue is more some random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False K562 None True True True\n"
     ]
    }
   ],
   "source": [
    "i #wait no it's at i = 0. So some issue with the parameters of my dataset class!!\n",
    "'''dataset = d.GraphRegDataset(split, dataset_args['max_length'], rc_aug = dataset_args['rc_aug'],\n",
    "                                                            cell_type=dataset_args.get('cell_type', None),\n",
    "                                                            kmer_len=dataset_args.get('kmer_len', None),\n",
    "                                                            remove_repeats=dataset_args.get('remove_repeats', False),\n",
    "                                                            has_TSS=dataset_args.get('has_TSS', False),\n",
    "                                                            clean_data=dataset_args.get('clean_data', True),\n",
    "                                                            vocab_size=cfg['model']['config']['vocab_size'],\n",
    "                                                            one_hot = dataset_args['one_hot'],)'''\n",
    "\n",
    "print(dataset_args['rc_aug'], dataset_args['cell_type'], dataset_args['kmer_len'], dataset_args['remove_repeats'], dataset_args['clean_data'], dataset_args['one_hot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oh I found the main issue, lmfaooo!!! The issue is that we had our original dataset with k562 data, but when we don't specify K562 it defaults to GM12878, so we need to specify K562 in the dataset_args\n",
    "#ok let's rewrite this as train data for GM12878, remove preds and repredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21165, 1000, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21165, 1000, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = d.GraphRegDataset('train', 100_000, clean_data=True, one_hot=True, remove_repeats=True) #this is GM12878\n",
    "dataset.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(dataset.labels, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21165, 1000, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_vals.shape #prediction was indeed k562 so save it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/data1/lesliec/sarthak/data/GraphReg/model_out/pred_train_pt_K562.npy', pred_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and save out the k562 true data\n",
    "np.save('/data1/lesliec/sarthak/data/GraphReg/model_out/true_train_K562.npy', true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_path: /data1/lesliec/sarthak/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's redo the dataset and evaluate it on the test set\n",
    "\n",
    "import sys\n",
    "sys.path.append('/data/leslie/sarthak/caduceus/')\n",
    "import torch\n",
    "import numpy as np\n",
    "import src.dataloaders.datasets.graphreg_dataset as d\n",
    "import yaml\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "ckpt_path = '/data1/lesliec/sarthak/caduceus/outputs/2024-11-27/15-08-13-584820/checkpoints/last.ckpt'\n",
    "\n",
    "model_cfg_path = os.path.join(os.path.dirname(os.path.dirname(ckpt_path)), '.hydra', 'config.yaml')\n",
    "cfg = yaml.load(open(model_cfg_path, 'r'), Loader=yaml.FullLoader)\n",
    "\n",
    "\n",
    "state_dict = torch.load(ckpt_path, map_location='cpu')\n",
    "dataset_args = cfg['dataset']\n",
    "split = 'test'\n",
    "dataset = d.GraphRegDataset(split, dataset_args['max_length'], rc_aug = dataset_args['rc_aug'],\n",
    "                                                            cell_type=dataset_args.get('cell_type', None),\n",
    "                                                            kmer_len=dataset_args.get('kmer_len', None),\n",
    "                                                            remove_repeats=dataset_args.get('remove_repeats', False),\n",
    "                                                            has_TSS=dataset_args.get('has_TSS', False),\n",
    "                                                            clean_data=dataset_args.get('clean_data', True),\n",
    "                                                            vocab_size=cfg['model']['config']['vocab_size'],\n",
    "                                                            one_hot = dataset_args['one_hot'],)\n",
    "dataset_args\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "    state_dict[\"state_dict\"], \"model.\"\n",
    ")\n",
    "model_state_dict = state_dict[\"state_dict\"]\n",
    "# need to remove torchmetrics. to remove keys, need to convert to list first\n",
    "for key in list(model_state_dict.keys()):\n",
    "    if \"torchmetrics\" in key:\n",
    "        model_state_dict.pop(key)\n",
    "\n",
    "cfg['model'].pop('config')\n",
    "cfg['model']\n",
    "from src.models.sequence.conv import GraphRegConvNet\n",
    "model = GraphRegConvNet(**cfg['model'])\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:16<00:00,  5.36it/s]\n"
     ]
    }
   ],
   "source": [
    "model = model.eval().cuda()\n",
    "from tqdm import tqdm\n",
    "true_vals = np.zeros((len(dataset),1000,3))\n",
    "pred_vals = np.zeros((len(dataset),1000,3))\n",
    "#now make a dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "idx = 0\n",
    "#can also do torch no grad if want bigger batch size, but this is fast enough\n",
    "with torch.no_grad():\n",
    "    for i, (x, y) in enumerate(tqdm(dataloader)):\n",
    "        pred = model(x.cuda())\n",
    "        true_vals[idx:idx+x.shape[0]] = y.detach().cpu().numpy()\n",
    "        pred_vals[idx:idx+x.shape[0]] = pred.detach().cpu().numpy()\n",
    "        idx += x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now load in the true values\n",
    "true = np.load('/data1/lesliec/sarthak/data/GraphReg/model_out/true_test_K562.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(true_vals, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now save out the predictions\n",
    "np.save('/data1/lesliec/sarthak/data/GraphReg/model_out/pred_test_pt_K562.npy', pred_vals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
