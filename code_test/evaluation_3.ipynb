{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluating models after all training\n",
    "\n",
    "We have 3 models on DNase, and want to test all of them\n",
    "\n",
    "There's 2 for the cell type specific model that we should explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.57483\n",
      "381-val_loss=3.57483.ckpt\n"
     ]
    }
   ],
   "source": [
    "#first we need to find the lowest validation loss for the multitasking model\n",
    "import os\n",
    "import numpy as np\n",
    "file_list = []\n",
    "name_list = []\n",
    "for tempfile in os.listdir('/data/leslie/sarthak/hyena/hyena-dna/outputs/2024-02-23/09-35-33-196632/checkpoints/'):\n",
    "    # print(tempfile[-12:-5])\n",
    "    file_list.append(tempfile)\n",
    "    #now do a try except to see if the file is a float\n",
    "    try:\n",
    "        name_list.append(float(tempfile[-12:-5]))\n",
    "    except:\n",
    "        name_list.append(1000)\n",
    "    # name_list.append(float(tempfile[-12:-5]))\n",
    "        \n",
    "#print the minimum of name list\n",
    "print(min(name_list))\n",
    "#find that index and print the file_list index\n",
    "print(file_list[name_list.index(min(name_list))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can use the ISM utils for this, as that is what we've been using for evaluation for explainability, so good to use this still\n",
    "from evals.evals_utils import Evals\n",
    "multitasking_path = '/data/leslie/sarthak/hyena/hyena-dna/outputs/2024-02-23/09-35-33-196632/checkpoints/381-val_loss=3.57483.ckpt'\n",
    "cts_path = '/data/leslie/sarthak/hyena/hyena-dna/outputs/2024-02-29/15-45-02-282170/checkpoints/last.ckpt'\n",
    "cts_path2 = '/data/leslie/sarthak/hyena/hyena-dna/outputs/2024-02-09/17-38-16-568113/checkpoints/last.ckpt' #this is again the 10% 100 epochs one\n",
    "ctst_path = '/data/leslie/sarthak/hyena/hyena-dna/outputs/2024-02-23/09-35-11-173861/checkpoints/last.ckpt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's try the ctst path\n",
    "eval_ctst = Evals('DNase_ctst',ctst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8275 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 287/8275 [06:08<2:50:54,  1.28s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#now let's do evals\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43meval_ctst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/lila/data/leslie/sarthak/hyena/hyena-dna/evals/evals_utils.py:142\u001b[0m, in \u001b[0;36mEvals.evaluate\u001b[0;34m(self, batch_size, num_workers)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    141\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 142\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDNase\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDNase\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mseq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/hyena-dna/lib/python3.11/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1185\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/hyena-dna/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/hyena-dna/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/hyena-dna/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/hyena-dna/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/hyena-dna/lib/python3.11/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/hyena-dna/lib/python3.11/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/hyena-dna/lib/python3.11/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/hyena-dna/lib/python3.11/multiprocessing/connection.py:947\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    944\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 947\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/hyena-dna/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#now let's do evals\n",
    "eval_ctst.evaluate(num_workers = 1, batch_size = 2048)\n",
    "#yeah it seems to be working just fine! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's try the multitasking path\n",
    "eval_multitasking = Evals('DNase_allcelltypes',multitasking_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/52 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [01:09<00:00,  1.33s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-10.0000,  -0.4581, -10.0000,  ..., -10.0000,  -1.7576, -10.0000],\n",
       "         [-10.0000,  -1.1888, -10.0000,  ..., -10.0000,  -3.0268,  -2.2397],\n",
       "         [  0.2071,   1.3613,  -2.4325,  ...,  -0.7399,   4.2481,  -0.7007],\n",
       "         ...,\n",
       "         [  0.9784,   0.6225,   0.2469,  ...,   0.3363,   0.6615,  -0.4536],\n",
       "         [  1.4823,   1.6966,   0.2309,  ...,   0.2233,   0.8615,  -0.2049],\n",
       "         [  0.8997,   0.8567,   0.4843,  ...,   0.1876,   0.8940,  -1.0668]]),\n",
       " tensor([[-2.0285, -1.7535, -2.3377,  ..., -2.4311, -1.2368, -1.2885],\n",
       "         [-3.5559, -3.0873, -3.0547,  ..., -2.6732, -0.8077, -1.1371],\n",
       "         [-1.8445, -1.1222, -2.3453,  ..., -3.5471, -0.8294, -2.4889],\n",
       "         ...,\n",
       "         [ 0.0943,  0.0991,  0.4014,  ..., -0.3053,  0.1748,  0.2073],\n",
       "         [ 1.2437,  1.4676,  0.4445,  ..., -0.0990,  0.8812,  0.2544],\n",
       "         [ 0.5568,  0.6213,  0.4431,  ..., -0.5057,  0.3080,  0.3311]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_multitasking.dataset.cell_types = 161 #a hack because misdefined it\n",
    "eval_multitasking.evaluate(num_workers = 1, batch_size = 2048)\n",
    "#161 times less data, so it does work out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0000e+01, -4.5808e-01, -1.0000e+01, -1.0000e+01, -1.8792e+00,\n",
      "        -1.0000e+01, -2.3478e+00, -1.8173e+00, -6.1973e-01, -3.1970e+00,\n",
      "        -3.1362e+00, -6.3732e-01, -1.0000e+01, -1.0000e+01, -1.0000e+01,\n",
      "        -1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01, -1.6359e+00,\n",
      "        -2.9812e+00, -1.0000e+01, -1.0000e+01, -1.9674e+00, -1.0000e+01,\n",
      "        -1.0000e+01, -1.0000e+01, -1.1343e+00, -1.4971e+00, -1.0000e+01,\n",
      "        -1.0000e+01, -1.0000e+01, -1.6084e+00, -1.0000e+01, -1.0000e+01,\n",
      "        -2.0236e+00, -2.5367e+00, -1.1614e-01, -5.7076e-01, -1.0000e+01,\n",
      "        -1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01,\n",
      "        -6.2989e-01, -1.0000e+01, -3.2462e-01, -1.0000e+01, -1.0000e+01,\n",
      "        -1.0000e+01, -2.0274e-01, -1.0000e+01, -1.7594e+00, -1.0000e+01,\n",
      "        -7.5590e-01, -1.1066e+00, -1.7550e+00, -1.0000e+01, -1.0000e+01,\n",
      "        -1.2859e+00, -1.0000e+01, -4.0290e-02, -1.0000e+01, -5.8336e-01,\n",
      "        -1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01,\n",
      "        -1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01, -7.3588e-01,\n",
      "        -4.0794e-01, -1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01,\n",
      "        -1.0000e+01, -2.7017e+00, -1.0000e+01,  1.8350e+00, -5.8716e-02,\n",
      "        -2.0472e+00,  6.2031e-04, -1.5060e+00, -1.0000e+01,  3.8892e-01,\n",
      "        -5.4557e-01, -7.9473e-01, -1.0000e+01, -1.0000e+01, -2.2882e+00,\n",
      "        -1.0000e+01, -1.0000e+01, -1.7029e+00, -1.0000e+01, -1.0000e+01,\n",
      "        -1.0000e+01, -1.0000e+01, -1.0525e+00, -5.3042e-01,  3.1996e-01,\n",
      "        -2.8669e-01, -9.9336e-01, -2.0395e-01, -1.0798e+00, -1.5536e-01,\n",
      "        -1.0000e+01, -1.0000e+01, -1.0000e+01,  1.6758e-01,  2.8610e-01,\n",
      "        -1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01,  1.6354e-01,\n",
      "        -1.0000e+01, -1.0000e+01, -1.0000e+01, -2.0694e+00, -1.7942e+00,\n",
      "        -1.0000e+01, -7.3466e-01, -1.0402e+00,  9.2766e-02, -1.6520e+00,\n",
      "        -1.2083e+00, -1.0000e+01, -1.5517e+00,  1.2717e-01, -1.0000e+01,\n",
      "        -1.9727e+00, -1.7651e+00, -1.5085e+00, -1.0000e+01, -1.1466e+00,\n",
      "        -1.0000e+01, -1.0000e+01, -1.0000e+01, -1.2911e-01, -1.0000e+01,\n",
      "        -1.0000e+01, -1.0000e+01, -8.9330e-01, -2.7886e+00, -8.8353e-01,\n",
      "        -1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01, -1.5294e+00,\n",
      "        -6.4778e-01, -1.0000e+01, -1.0000e+01, -1.0000e+01, -1.7576e+00,\n",
      "        -1.0000e+01])\n"
     ]
    }
   ],
   "source": [
    "#we see some values, let's just use that\n",
    "a,b = eval_multitasking.dataset[0]\n",
    "print(b) #exact same labels, at least what is shown, now let's see the predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 161])\n",
      "tensor([[-2.0285, -1.7535, -2.3377, -1.0759, -1.6841, -1.4012, -0.8913, -0.6950,\n",
      "         -1.3474, -0.6109, -0.7014, -1.0829, -1.6052, -0.5472, -1.0905, -1.4953,\n",
      "         -1.6828, -1.0294, -1.9775, -0.5552, -1.5356, -1.3920, -1.9695, -2.0644,\n",
      "         -1.5830, -2.4532, -0.8513, -1.6068, -1.3586, -2.7661, -0.8429, -2.1444,\n",
      "         -1.3913, -2.9047, -1.9589, -1.3889, -1.7917, -0.2223, -3.0429, -2.7787,\n",
      "         -3.8464, -4.3981, -2.6890, -3.3632, -5.7655, -1.8744, -2.4023, -2.7644,\n",
      "         -1.3747, -3.3157, -3.5665, -0.7733, -1.8525, -0.4034, -2.2569, -1.2688,\n",
      "         -1.0485, -1.3464, -1.4851, -2.9671, -0.7305, -0.8996, -1.9522, -1.0046,\n",
      "         -2.1862, -0.5593, -0.5569, -1.5593, -2.8010, -3.7193, -2.6134, -0.6727,\n",
      "         -3.8209, -1.7621, -0.9491, -1.2655, -1.0223, -1.3570, -4.0295, -3.6925,\n",
      "         -4.4448, -0.5188, -1.0054, -0.8318, -0.9717, -1.0878,  0.2433, -2.1715,\n",
      "         -1.1041, -0.9827, -3.2571, -1.4903, -1.2402, -3.7635, -0.9459, -3.5869,\n",
      "         -3.3858, -0.7650, -1.7542, -3.1920, -2.4737, -1.4467, -0.8371, -1.8190,\n",
      "         -0.7262, -0.6169, -1.0217, -2.6325, -1.6670,  0.3892, -1.2384, -0.7266,\n",
      "         -1.8750, -0.9968, -0.7367, -0.8665, -1.6147, -1.4588, -1.4388, -0.1189,\n",
      "         -0.6539, -0.6190, -0.1997, -1.0315, -1.3085, -1.0932, -1.5974,  0.4844,\n",
      "         -0.0448, -1.8098,  0.4536, -1.6999, -1.4981, -1.6783, -0.7594, -1.7706,\n",
      "         -1.7212, -0.4351, -1.0471, -0.4392, -1.0658, -0.0887, -0.8736, -0.2669,\n",
      "         -1.5136, -0.5935, -0.6945, -1.4454, -0.6317, -1.6553, -1.2362, -0.7285,\n",
      "         -1.6891, -1.1800,  0.3260, -0.4107, -0.0579, -1.8854, -2.4311, -1.2368,\n",
      "         -1.2885]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "temp,_ = eval_multitasking.backbone(a.unsqueeze(0).cuda())\n",
    "out = eval_multitasking.decoder(temp)\n",
    "print(out.shape)\n",
    "print(out)\n",
    "#once again we can manually verify the begining and last 3 are identical, so this means our model is good!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-10.0000,  -1.1888, -10.0000,  -2.6834, -10.0000, -10.0000, -10.0000,\n",
      "        -10.0000, -10.0000,  -3.1970,  -3.1362,  -0.6400, -10.0000,  -2.7933,\n",
      "        -10.0000, -10.0000, -10.0000, -10.0000, -10.0000,  -2.9364, -10.0000,\n",
      "        -10.0000, -10.0000, -10.0000, -10.0000, -10.0000, -10.0000, -10.0000,\n",
      "        -10.0000, -10.0000,  -1.9988, -10.0000, -10.0000, -10.0000, -10.0000,\n",
      "         -2.0236,  -2.5367, -10.0000, -10.0000,  -0.6557, -10.0000, -10.0000,\n",
      "        -10.0000, -10.0000, -10.0000,  -0.4904, -10.0000, -10.0000, -10.0000,\n",
      "        -10.0000, -10.0000,   1.0666,   0.1828,   0.7807,  -0.4622,  -0.5024,\n",
      "         -1.3944, -10.0000, -10.0000, -10.0000,  -1.4567,  -1.5473,   0.2794,\n",
      "         -1.5674,   0.1411,  -1.2771,  -1.8280,  -1.3054, -10.0000, -10.0000,\n",
      "        -10.0000,  -1.2153, -10.0000, -10.0000,  -1.3412,  -1.8704, -10.0000,\n",
      "        -10.0000, -10.0000, -10.0000, -10.0000,  -2.5884, -10.0000,  -1.2475,\n",
      "         -0.9299,  -1.9488,  -0.5997,  -1.9992,  -0.9325, -10.0000,  -0.3091,\n",
      "         -0.8643, -10.0000,  -0.8927,  -2.0479, -10.0000, -10.0000,  -0.5906,\n",
      "        -10.0000, -10.0000, -10.0000,  -1.3991,   0.0885, -10.0000,  -1.1150,\n",
      "        -10.0000,  -1.4759, -10.0000,  -2.7343,   0.0923, -10.0000,  -2.1830,\n",
      "        -10.0000,  -0.3405,  -0.5072,  -1.9499, -10.0000,  -1.0593,  -1.0262,\n",
      "          1.0863,  -2.9089,  -0.6978,  -1.0936,  -2.3465,  -2.5884,  -0.7039,\n",
      "         -2.2640,  -1.0745,  -0.6802,  -2.0783,  -0.4656,  -1.5352, -10.0000,\n",
      "         -0.5768, -10.0000,   0.1599,  -2.8513, -10.0000,  -1.6389,  -0.4903,\n",
      "        -10.0000,   0.0200,  -1.3321,   0.8549,  -0.3134,  -0.1487,  -0.8417,\n",
      "         -0.6985,  -1.6844, -10.0000, -10.0000,  -3.1181, -10.0000,   0.8081,\n",
      "         -0.5790,  -0.0358,   0.2702, -10.0000, -10.0000,  -3.0268,  -2.2397])\n",
      "torch.Size([1, 161])\n",
      "tensor([[-3.5559, -3.0873, -3.0547, -2.4017, -2.8063, -2.3336, -2.3730, -2.3060,\n",
      "         -2.7595, -1.9933, -2.3559, -2.5761, -2.4999, -1.7539, -2.0243, -3.4984,\n",
      "         -3.2285, -3.1609, -4.2163, -2.1895, -2.2527, -3.0391, -2.8889, -2.8701,\n",
      "         -2.2294, -5.1066, -2.1001, -3.5466, -2.2536, -4.1194, -1.9413, -4.8992,\n",
      "         -2.3394, -5.4292, -2.8976, -1.6674, -2.2891, -0.6571, -4.7485, -4.0562,\n",
      "         -5.6667, -6.2448, -4.7260, -4.6776, -7.0778, -2.9589, -3.3035, -4.8636,\n",
      "         -3.3275, -4.9956, -5.8388, -0.3233, -2.3294, -0.2281, -2.3019, -1.2169,\n",
      "         -0.5996, -1.2744, -2.3685, -3.5180, -1.3142, -1.2302, -2.4780, -1.4079,\n",
      "         -2.6818, -1.1991, -1.3367, -1.3387, -2.4779, -5.6283, -3.1915, -1.2001,\n",
      "         -4.8324, -2.3316, -1.4812, -1.4055, -1.4550, -1.1644, -3.7868, -5.2664,\n",
      "         -5.1092, -1.0143, -1.0836,  0.0249, -1.2900, -0.9465, -0.7644, -1.4505,\n",
      "         -1.6013, -1.5636, -3.8574, -2.5641, -0.8001, -4.0770, -1.4744, -4.4106,\n",
      "         -4.9322, -0.8520, -1.4115, -3.6779, -3.9530, -0.5957,  0.2125, -2.2101,\n",
      "         -0.9050,  0.3325, -1.4076, -3.4691, -1.3218,  0.7638, -1.5506,  0.0514,\n",
      "         -1.7666, -1.4931,  0.0935, -0.0540, -1.0818, -1.6247, -1.7464,  0.7937,\n",
      "         -1.1136,  0.2534,  0.0429, -0.9060, -0.8288, -0.4516, -1.2447, -1.1104,\n",
      "         -0.3358, -1.5518, -0.5728, -0.7188, -1.1105, -2.1622, -0.5988, -1.5426,\n",
      "         -1.5628, -1.0800, -0.6740,  0.0781, -0.1802,  0.1768, -1.2586, -0.4359,\n",
      "         -0.9274, -0.6679, -0.7617, -2.2924, -1.0070, -2.1330, -1.2798, -1.1702,\n",
      "         -2.2992, -0.7361,  0.0280,  0.5421,  0.4359, -2.1751, -2.6732, -0.8077,\n",
      "         -1.1371]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#let's do it again for the second input, here's the expected\n",
    "# target [-10.0000,  -1.1888, -10.0000,  ..., -10.0000,  -3.0268,  -2.2397],\n",
    "# output [-3.5559, -3.0873, -3.0547,  ..., -2.6732, -0.8077, -1.1371],\n",
    "a,b = eval_multitasking.dataset[1]\n",
    "print(b) #exact same labels, at least what is shown, now let's see the predicitons\n",
    "temp,_ = eval_multitasking.backbone(a.unsqueeze(0).cuda())\n",
    "out = eval_multitasking.decoder(temp)\n",
    "print(out.shape)\n",
    "print(out)\n",
    "#once again completely identical, so I think it's safe to say this model is fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/8275 [00:09<4:11:46,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-10.0000,  -0.4581, -10.0000,  ..., -10.0000,  -1.7576, -10.0000],\n",
      "        [-10.0000,  -1.1888, -10.0000,  ..., -10.0000,  -3.0268,  -2.2397],\n",
      "        [  0.2071,   1.3613,  -2.4325,  ...,  -0.7399,   4.2481,  -0.7007],\n",
      "        ...,\n",
      "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]]), tensor([[ 0.8877,  0.8289,  0.6171,  ...,  0.8529,  0.9480,  1.1287],\n",
      "        [-3.2399, -2.5506, -2.3602,  ..., -1.9085, -0.4064, -0.5675],\n",
      "        [ 0.0562,  0.7432,  0.3454,  ...,  0.4906,  2.2379,  1.2410],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]))\n"
     ]
    }
   ],
   "source": [
    "#we will break the ctst model and then evaluate the results to see if they are the same as running the data raw from the dataset.\n",
    "#so do both models, check outputs are what we expect, and then we can move on to the next step\n",
    "\n",
    "#we can use the ISM utils for this, as that is what we've been using for evaluation for explainability, so good to use this still\n",
    "from evals.evals_utils import Evals\n",
    "multitasking_path = '/data/leslie/sarthak/hyena/hyena-dna/outputs/2024-02-23/09-35-33-196632/checkpoints/381-val_loss=3.57483.ckpt'\n",
    "cts_path = '/data/leslie/sarthak/hyena/hyena-dna/outputs/2024-02-29/15-45-02-282170/checkpoints/last.ckpt'\n",
    "cts_path2 = '/data/leslie/sarthak/hyena/hyena-dna/outputs/2024-02-09/17-38-16-568113/checkpoints/last.ckpt' #this is again the 10% 100 epochs one\n",
    "ctst_path = '/data/leslie/sarthak/hyena/hyena-dna/outputs/2024-02-23/09-35-11-173861/checkpoints/last.ckpt'\n",
    "\n",
    "#let's try the ctst path\n",
    "eval_ctst = Evals('DNase_ctst',ctst_path)\n",
    "#now let's do evals\n",
    "outs = eval_ctst.evaluate(num_workers = 1, batch_size = 2048)\n",
    "#yeah it seems to be working just fine! \n",
    "print(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-10.])\n",
      "tensor([[0.8877]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#let's again manually verify the first and last 3\n",
    "a,b = eval_ctst.dataset[0]\n",
    "print(b)\n",
    "temp,_ = eval_ctst.backbone(a.unsqueeze(0).cuda())\n",
    "out = eval_ctst.decoder(temp)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_list = []\n",
    "target_list = []\n",
    "for i in range(161):\n",
    "    a,b = eval_ctst.dataset[i]\n",
    "    temp,_ = eval_ctst.backbone(a.unsqueeze(0).cuda())\n",
    "    out = eval_ctst.decoder(temp)\n",
    "    target_list.append(b.item())\n",
    "    # print(out)\n",
    "    out_list.append(out.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8877016305923462,\n",
       " 0.8288659453392029,\n",
       " 0.6171100735664368,\n",
       " 1.0251190662384033,\n",
       " 0.8650311827659607,\n",
       " 1.0687533617019653,\n",
       " 1.0536092519760132,\n",
       " 1.0084726810455322,\n",
       " 1.1312285661697388,\n",
       " 1.091808795928955,\n",
       " 1.0137736797332764,\n",
       " 1.0664992332458496,\n",
       " 1.0612125396728516,\n",
       " 1.135503888130188,\n",
       " 1.0520257949829102,\n",
       " 0.7574980854988098,\n",
       " 0.9037701487541199,\n",
       " 0.8775949478149414,\n",
       " 0.6452786326408386,\n",
       " 1.0623294115066528,\n",
       " 0.8897803425788879,\n",
       " 0.8670477867126465,\n",
       " 0.9691247344017029,\n",
       " 0.9366050362586975,\n",
       " 1.0489659309387207,\n",
       " 0.44417253136634827,\n",
       " 0.874826192855835,\n",
       " 0.8417102098464966,\n",
       " 1.0960173606872559,\n",
       " 0.6833798289299011,\n",
       " 1.027572512626648,\n",
       " 0.44195127487182617,\n",
       " 1.076371431350708,\n",
       " 0.2882196307182312,\n",
       " 0.9506875872612,\n",
       " 1.101499319076538,\n",
       " 1.0688049793243408,\n",
       " 1.4491207599639893,\n",
       " 0.3372284173965454,\n",
       " 0.39476603269577026,\n",
       " -0.2145477533340454,\n",
       " -0.9650071859359741,\n",
       " 0.19831526279449463,\n",
       " -0.11373310536146164,\n",
       " -1.6251115798950195,\n",
       " 0.5751596093177795,\n",
       " 0.2966262698173523,\n",
       " 0.09618473052978516,\n",
       " 0.1631401926279068,\n",
       " 0.07136344164609909,\n",
       " -0.30866342782974243,\n",
       " 1.4710044860839844,\n",
       " 0.9542654752731323,\n",
       " 1.5173048973083496,\n",
       " 0.7639192938804626,\n",
       " 0.36341410875320435,\n",
       " 0.7800998091697693,\n",
       " 1.0302730798721313,\n",
       " 0.7263779044151306,\n",
       " 0.19977602362632751,\n",
       " 1.1484994888305664,\n",
       " 1.1544303894042969,\n",
       " 0.8677965998649597,\n",
       " 1.0388349294662476,\n",
       " 0.7964580059051514,\n",
       " 1.3281631469726562,\n",
       " 1.045041561126709,\n",
       " 1.11963951587677,\n",
       " 0.6965823769569397,\n",
       " -0.5862695574760437,\n",
       " 0.4261925220489502,\n",
       " 1.2568122148513794,\n",
       " 0.29268878698349,\n",
       " 1.0008560419082642,\n",
       " 1.054672122001648,\n",
       " 0.6838834285736084,\n",
       " 0.9087478518486023,\n",
       " 0.9445696473121643,\n",
       " 0.3864254057407379,\n",
       " -0.1253979206085205,\n",
       " -0.4660249352455139,\n",
       " 1.157609462738037,\n",
       " 0.9936849474906921,\n",
       " 1.4641871452331543,\n",
       " 1.0276494026184082,\n",
       " 1.315723180770874,\n",
       " 1.5367062091827393,\n",
       " 0.9955464601516724,\n",
       " 0.9660351872444153,\n",
       " 0.47501039505004883,\n",
       " 0.2770039439201355,\n",
       " 0.895105242729187,\n",
       " 1.321714997291565,\n",
       " -0.21605342626571655,\n",
       " 1.0220613479614258,\n",
       " -0.38981446623802185,\n",
       " 0.2783688008785248,\n",
       " 1.0090603828430176,\n",
       " 0.9384823441505432,\n",
       " 0.036841556429862976,\n",
       " 0.403315931558609,\n",
       " 1.1352256536483765,\n",
       " 1.1294667720794678,\n",
       " 0.015115797519683838,\n",
       " 1.091042160987854,\n",
       " 1.121351718902588,\n",
       " 0.9419682025909424,\n",
       " 0.38853269815444946,\n",
       " 0.910659909248352,\n",
       " 1.1380517482757568,\n",
       " 1.0368746519088745,\n",
       " 1.0414351224899292,\n",
       " 0.8873235583305359,\n",
       " 1.1636238098144531,\n",
       " 1.0122606754302979,\n",
       " 1.1452052593231201,\n",
       " 0.9820482134819031,\n",
       " 0.3204892575740814,\n",
       " 0.9533626437187195,\n",
       " 1.231772780418396,\n",
       " 0.6384636163711548,\n",
       " 0.9895219802856445,\n",
       " 1.3031001091003418,\n",
       " 0.7432273030281067,\n",
       " 1.118687629699707,\n",
       " 1.494399070739746,\n",
       " 0.8491559028625488,\n",
       " 0.9270780682563782,\n",
       " 0.932393491268158,\n",
       " 0.7612958550453186,\n",
       " 1.191776156425476,\n",
       " 0.5166600346565247,\n",
       " 1.0779472589492798,\n",
       " 0.2827743887901306,\n",
       " 1.2687675952911377,\n",
       " 0.547595739364624,\n",
       " 1.0201244354248047,\n",
       " 1.1308398246765137,\n",
       " 1.1918842792510986,\n",
       " 1.1862058639526367,\n",
       " 1.3484983444213867,\n",
       " 1.2206330299377441,\n",
       " 1.0868685245513916,\n",
       " 1.2065677642822266,\n",
       " 1.3500529527664185,\n",
       " 1.2530325651168823,\n",
       " 1.1319990158081055,\n",
       " 0.6003899574279785,\n",
       " 1.2976863384246826,\n",
       " 0.5456631779670715,\n",
       " 1.2281997203826904,\n",
       " 1.230165958404541,\n",
       " 0.9099730849266052,\n",
       " 0.4497579336166382,\n",
       " 1.2018682956695557,\n",
       " 1.0645079612731934,\n",
       " 1.2572511434555054,\n",
       " 0.8413184285163879,\n",
       " 0.8528645038604736,\n",
       " 0.9480212330818176,\n",
       " 1.128691554069519]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-10.0,\n",
       " -0.4580809772014618,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -1.879201054573059,\n",
       " -10.0,\n",
       " -2.3478338718414307,\n",
       " -1.8173274993896484,\n",
       " -0.6197326183319092,\n",
       " -3.1969776153564453,\n",
       " -3.1362497806549072,\n",
       " -0.6373192667961121,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -1.6359361410140991,\n",
       " -2.9811601638793945,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -1.9674078226089478,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -1.134278416633606,\n",
       " -1.4970508813858032,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -1.608433485031128,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -2.0236284732818604,\n",
       " -2.536665678024292,\n",
       " -0.11614356935024261,\n",
       " -0.5707607865333557,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -0.6298944354057312,\n",
       " -10.0,\n",
       " -0.324618399143219,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -0.20274455845355988,\n",
       " -10.0,\n",
       " -1.759379506111145,\n",
       " -10.0,\n",
       " -0.7559024095535278,\n",
       " -1.106569528579712,\n",
       " -1.7550193071365356,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -1.285852313041687,\n",
       " -10.0,\n",
       " -0.040289830416440964,\n",
       " -10.0,\n",
       " -0.5833625197410583,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -0.7358813285827637,\n",
       " -0.4079364240169525,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -2.7017107009887695,\n",
       " -10.0,\n",
       " 1.8350414037704468,\n",
       " -0.05871603265404701,\n",
       " -2.047153949737549,\n",
       " 0.0006203061202540994,\n",
       " -1.5060299634933472,\n",
       " -10.0,\n",
       " 0.388921320438385,\n",
       " -0.5455690622329712,\n",
       " -0.7947289943695068,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -2.2881839275360107,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -1.7028698921203613,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -1.052544355392456,\n",
       " -0.5304241180419922,\n",
       " 0.31995636224746704,\n",
       " -0.2866870164871216,\n",
       " -0.9933604001998901,\n",
       " -0.20394501090049744,\n",
       " -1.0798184871673584,\n",
       " -0.1553577184677124,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " 0.16758452355861664,\n",
       " 0.28610438108444214,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " 0.16353993117809296,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -2.069425344467163,\n",
       " -1.7942336797714233,\n",
       " -10.0,\n",
       " -0.7346633076667786,\n",
       " -1.0401614904403687,\n",
       " 0.09276645630598068,\n",
       " -1.6520395278930664,\n",
       " -1.2082874774932861,\n",
       " -10.0,\n",
       " -1.5517327785491943,\n",
       " 0.1271722912788391,\n",
       " -10.0,\n",
       " -1.9726548194885254,\n",
       " -1.765112280845642,\n",
       " -1.5085489749908447,\n",
       " -10.0,\n",
       " -1.1465851068496704,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -0.12911361455917358,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -0.8933027982711792,\n",
       " -2.788639783859253,\n",
       " -0.8835291266441345,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -1.5293983221054077,\n",
       " -0.6477789282798767,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -10.0,\n",
       " -1.7575668096542358,\n",
       " -10.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list #once again perfect match, let's check the second ccre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.2398972511291504, -2.550564765930176, -2.360163927078247, -1.5194250345230103, -2.008556365966797, -1.727140188217163, -1.656821370124817, -1.594294786453247, -2.4293134212493896, -1.534557580947876, -1.537028193473816, -2.547062635421753, -2.678487777709961, -1.2757834196090698, -1.4589704275131226, -2.978858232498169, -3.077796220779419, -2.7968521118164062, -3.453587770462036, -1.388540506362915, -1.872012734413147, -2.6339356899261475, -2.3298227787017822, -2.1010525226593018, -2.03116774559021, -3.107649564743042, -1.980186104774475, -3.30318284034729, -2.127579689025879, -3.684777021408081, -1.4978086948394775, -3.933847427368164, -1.2939006090164185, -3.728515863418579, -2.009373903274536, -1.1691880226135254, -1.8437838554382324, -0.0510450154542923, -3.1424453258514404, -2.839461088180542, -3.718681573867798, -4.261534214019775, -3.3418123722076416, -3.0252020359039307, -4.216183662414551, -2.4816091060638428, -2.0885581970214844, -3.054487943649292, -3.000681161880493, -3.0987229347229004, -3.5360612869262695, 0.13016700744628906, -2.1231467723846436, 0.052928198128938675, -2.101015329360962, -1.106257438659668, -0.31026172637939453, -0.25761908292770386, -1.7159684896469116, -2.206425666809082, -0.14664702117443085, -0.05219709873199463, -1.5076220035552979, -0.2722248435020447, -2.0794003009796143, -0.4072352349758148, -0.32970336079597473, -0.22384190559387207, -0.8127266764640808, -3.6157896518707275, -2.3698012828826904, -0.06800907850265503, -3.3403854370117188, -2.167964220046997, -0.1536065638065338, -0.32209351658821106, -0.045457929372787476, -0.6300351023674011, -3.2619900703430176, -3.5952308177948, -3.9049761295318604, -0.4064810872077942, 0.10420982539653778, 0.015834413468837738, -0.49829787015914917, -0.27504438161849976, 0.058218538761138916, -0.6219432950019836, -0.6149119138717651, -1.3781821727752686, -3.0694355964660645, -2.09049391746521, -0.17751610279083252, -3.2111265659332275, -0.6987887620925903, -2.6596872806549072, -3.53570294380188, -0.2751745581626892, -0.6692448854446411, -2.09084153175354, -3.120084047317505, 0.2546667456626892, 0.3956054747104645, -2.6270248889923096, -0.5250270962715149, 0.581199049949646, -0.29019200801849365, -2.3241183757781982, -0.6528048515319824, 0.741622269153595, -1.4441096782684326, 0.5261829495429993, -1.11940336227417, -0.44170495867729187, 0.4550876021385193, 0.5314100980758667, -0.08178681135177612, -1.887986183166504, -0.6691265106201172, 0.691132128238678, -0.20512060821056366, 0.5136356949806213, 0.47070246934890747, -0.07610262930393219, -0.12824572622776031, 0.2429685890674591, 0.06426562368869781, 0.05577217787504196, -0.26641523838043213, -0.01603943109512329, 0.06872811913490295, -0.9401448369026184, 0.055174171924591064, -2.1794049739837646, 0.0721849724650383, -0.8803806900978088, -0.5108817219734192, -0.3390289545059204, 0.15867392718791962, 0.3026057183742523, 0.09335334599018097, 0.44548606872558594, -0.21771873533725739, -0.3750145137310028, 0.13829047977924347, -0.08564302325248718, -0.3033190071582794, -1.4716510772705078, -0.1411721557378769, -1.1158677339553833, -0.3289521038532257, -0.48314785957336426, -2.2490322589874268, -0.5501213669776917, 0.13136467337608337, 0.5573109984397888, 0.38684093952178955, -1.5850749015808105, -1.9085302352905273, -0.4064233899116516, -0.5674684047698975]\n",
      "[-10.0, -1.1887824535369873, -10.0, -2.6833858489990234, -10.0, -10.0, -10.0, -10.0, -10.0, -3.1969776153564453, -3.1362497806549072, -0.6400231122970581, -10.0, -2.7933340072631836, -10.0, -10.0, -10.0, -10.0, -10.0, -2.9363996982574463, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1.998849630355835, -10.0, -10.0, -10.0, -10.0, -2.0236284732818604, -2.536665678024292, -10.0, -10.0, -0.655671238899231, -10.0, -10.0, -10.0, -10.0, -10.0, -0.4903869330883026, -10.0, -10.0, -10.0, -10.0, -10.0, 1.06658136844635, 0.1828390210866928, 0.7806593179702759, -0.4622040092945099, -0.5024291276931763, -1.3944478034973145, -10.0, -10.0, -10.0, -1.4566693305969238, -1.547255516052246, 0.2794352173805237, -1.567384123802185, 0.14112979173660278, -1.2770898342132568, -1.828007698059082, -1.3054472208023071, -10.0, -10.0, -10.0, -1.2153116464614868, -10.0, -10.0, -1.3411656618118286, -1.8703548908233643, -10.0, -10.0, -10.0, -10.0, -10.0, -2.5883989334106445, -10.0, -1.2475354671478271, -0.9298538565635681, -1.9488379955291748, -0.5997374653816223, -1.9992496967315674, -0.9324906468391418, -10.0, -0.3091193735599518, -0.8642642498016357, -10.0, -0.8926644325256348, -2.047895908355713, -10.0, -10.0, -0.5905786752700806, -10.0, -10.0, -10.0, -1.399096131324768, 0.0884815976023674, -10.0, -1.115040898323059, -10.0, -1.4758903980255127, -10.0, -2.7342734336853027, 0.09232824295759201, -10.0, -2.1829795837402344, -10.0, -0.34054824709892273, -0.5071597099304199, -1.949899435043335, -10.0, -1.0592542886734009, -1.02619469165802, 1.0863373279571533, -2.9089202880859375, -0.6977826952934265, -1.0935816764831543, -2.3464784622192383, -2.588432550430298, -0.7038843035697937, -2.263981342315674, -1.0744954347610474, -0.6802108883857727, -2.078263521194458, -0.46556365489959717, -1.535206913948059, -10.0, -0.5768289566040039, -10.0, 0.1599285751581192, -2.8513219356536865, -10.0, -1.638949990272522, -0.49033913016319275, -10.0, 0.020006461068987846, -1.3320528268814087, 0.8548859357833862, -0.31335169076919556, -0.14869368076324463, -0.8416526317596436, -0.6984882950782776, -1.6843786239624023, -10.0, -10.0, -3.118088722229004, -10.0, 0.8080921769142151, -0.5789642930030823, -0.03581441566348076, 0.27019500732421875, -10.0, -10.0, -3.0268118381500244, -2.2396504878997803]\n"
     ]
    }
   ],
   "source": [
    "out_list = []\n",
    "target_list = []\n",
    "for i in range(161,322):\n",
    "    a,b = eval_ctst.dataset[i]\n",
    "    temp,_ = eval_ctst.backbone(a.unsqueeze(0).cuda())\n",
    "    out = eval_ctst.decoder(temp)\n",
    "    target_list.append(b.item())\n",
    "    # print(out)\n",
    "    out_list.append(out.item())\n",
    "print(out_list)\n",
    "print(target_list)\n",
    "#great, again the exact results we were hoping for!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/8275 [00:08<3:56:14,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-10.0000,  -0.4581, -10.0000,  ..., -10.0000,  -1.7576, -10.0000],\n",
      "        [-10.0000,  -1.1888, -10.0000,  ..., -10.0000,  -3.0268,  -2.2397],\n",
      "        [  0.2071,   1.3613,  -2.4325,  ...,  -0.7399,   4.2481,  -0.7007],\n",
      "        ...,\n",
      "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]]), tensor([[ 0.4608,  0.1812, -0.1047,  ...,  0.4467,  0.4108,  0.7876],\n",
      "        [-3.6945, -3.5483, -2.6489,  ..., -1.0422, -0.2208,  0.1486],\n",
      "        [ 0.5602,  0.2501, -0.6051,  ..., -0.5439,  0.4893,  0.0056],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]))\n"
     ]
    }
   ],
   "source": [
    "#final test with the normal DNase model\n",
    "# import pretty_errors\n",
    "from evals.evals_utils import Evals\n",
    "multitasking_path = '/data/leslie/sarthak/hyena/hyena-dna/outputs/2024-02-23/09-35-33-196632/checkpoints/381-val_loss=3.57483.ckpt'\n",
    "cts_path = '/data/leslie/sarthak/hyena/hyena-dna/outputs/2024-02-29/15-45-02-282170/checkpoints/last.ckpt'\n",
    "cts_path2 = '/data/leslie/sarthak/hyena/hyena-dna/outputs/2024-02-09/17-38-16-568113/checkpoints/last.ckpt' #this is again the 10% 100 epochs one\n",
    "ctst_path = '/data/leslie/sarthak/hyena/hyena-dna/outputs/2024-02-23/09-35-11-173861/checkpoints/last.ckpt'\n",
    "\n",
    "#let's try the ctst path\n",
    "eval_cts = Evals('DNase',cts_path, cfg = 'DNase_full.yaml')\n",
    "#now let's do evals\n",
    "outs = eval_cts.evaluate(num_workers = 1, batch_size = 2048)\n",
    "#yeah it seems to be working just fine! \n",
    "print(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4607941508293152, 0.1811811774969101, -0.10472239553928375, 0.29314929246902466, 0.18910421431064606, 0.39730584621429443, 0.3942635655403137, 0.4120621085166931, 0.5110092163085938, 0.6531122922897339, 0.6351823806762695, 0.49672237038612366, 0.733195424079895, 0.6328740119934082, 0.6094671487808228, 0.2716315984725952, 0.3630925714969635, 0.40567511320114136, 0.13957206904888153, 0.645267128944397, 0.2515438199043274, 0.41526561975479126, 0.4243916869163513, 0.39014509320259094, 0.7317792177200317, -0.22715282440185547, 0.4914673864841461, 0.2307317554950714, 0.7316731214523315, 0.11366632580757141, 0.7488692998886108, -0.6944421529769897, 0.36057934165000916, -0.46730872988700867, 0.22033847868442535, 0.6183946132659912, 0.5576953887939453, 1.0357459783554077, -1.3381800651550293, -0.7081025838851929, -2.306936740875244, -2.5576529502868652, -1.4282139539718628, -1.6125112771987915, -3.744837522506714, -0.1413612961769104, -0.40741002559661865, -1.420728087425232, 0.05333268642425537, -1.9519506692886353, -2.257211208343506, 0.9474704265594482, -0.11407830566167831, 0.9419512748718262, 0.07246562093496323, 0.21059784293174744, -0.3799917995929718, 0.05250599980354309, 0.018259722739458084, -1.0811710357666016, 0.23664826154708862, 0.26049330830574036, 0.4409591257572174, 0.3035798966884613, 0.04092735797166824, 0.8550610542297363, 0.07679688930511475, 0.39361855387687683, 0.5668292045593262, -1.8945674896240234, -0.2399374097585678, 0.8083170652389526, -1.2900404930114746, 0.2649920582771301, 0.27359306812286377, -0.20560024678707123, -0.10723736137151718, -0.6222259998321533, -1.1061517000198364, -2.2931933403015137, -2.364675521850586, -0.10614529997110367, -0.2195717990398407, 0.7782320976257324, 0.09001156687736511, 0.2056153267621994, 1.0795767307281494, -0.39723384380340576, -0.40888455510139465, -0.5255979299545288, -1.3517886400222778, -0.1545400619506836, 0.45740190148353577, -3.056610345840454, 0.23516106605529785, -1.8580381870269775, -1.2787808179855347, 0.5131816864013672, 0.07669643312692642, -0.5456054210662842, -0.39173516631126404, 0.6803799867630005, 1.170194387435913, -1.2348084449768066, 0.841022253036499, 1.093016505241394, 0.4641578495502472, -0.4320767819881439, 0.4203752875328064, 1.004367709159851, 0.5875682830810547, 0.7822251319885254, 0.6619676351547241, 0.7020918130874634, 0.8951249122619629, 0.877310037612915, 0.5128319263458252, -0.2854991853237152, 0.42418965697288513, 1.0606168508529663, 0.073326475918293, 0.83674156665802, 0.9844532012939453, -0.08824042230844498, 0.3735867440700531, 0.8365422487258911, 0.34531280398368835, 0.267694890499115, 0.38906946778297424, -0.05984174460172653, 0.3059540092945099, -0.4562942683696747, 0.8157258033752441, -0.549646258354187, 1.424462914466858, -0.17657387256622314, 0.09045484662055969, 0.5007842779159546, 0.3677939474582672, 0.6152993440628052, 0.6718692779541016, 0.6693117618560791, -0.07614616304636002, 0.7327086925506592, 1.1931535005569458, 0.8914676904678345, 0.3532322943210602, -0.13605886697769165, 0.5409406423568726, -0.45641395449638367, 0.6773478984832764, 0.5366324186325073, 0.2345973551273346, 0.30289599299430847, 0.9602669477462769, 0.8516650199890137, 1.0486574172973633, 0.15874716639518738, 0.4467008709907532, 0.41084322333335876, 0.7876120805740356]\n",
      "[-10.0, -0.4580809772014618, -10.0, -10.0, -1.879201054573059, -10.0, -2.3478338718414307, -1.8173274993896484, -0.6197326183319092, -3.1969776153564453, -3.1362497806549072, -0.6373192667961121, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1.6359361410140991, -2.9811601638793945, -10.0, -10.0, -1.9674078226089478, -10.0, -10.0, -10.0, -1.134278416633606, -1.4970508813858032, -10.0, -10.0, -10.0, -1.608433485031128, -10.0, -10.0, -2.0236284732818604, -2.536665678024292, -0.11614356935024261, -0.5707607865333557, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -0.6298944354057312, -10.0, -0.324618399143219, -10.0, -10.0, -10.0, -0.20274455845355988, -10.0, -1.759379506111145, -10.0, -0.7559024095535278, -1.106569528579712, -1.7550193071365356, -10.0, -10.0, -1.285852313041687, -10.0, -0.040289830416440964, -10.0, -0.5833625197410583, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -0.7358813285827637, -0.4079364240169525, -10.0, -10.0, -10.0, -10.0, -10.0, -2.7017107009887695, -10.0, 1.8350414037704468, -0.05871603265404701, -2.047153949737549, 0.0006203061202540994, -1.5060299634933472, -10.0, 0.388921320438385, -0.5455690622329712, -0.7947289943695068, -10.0, -10.0, -2.2881839275360107, -10.0, -10.0, -1.7028698921203613, -10.0, -10.0, -10.0, -10.0, -1.052544355392456, -0.5304241180419922, 0.31995636224746704, -0.2866870164871216, -0.9933604001998901, -0.20394501090049744, -1.0798184871673584, -0.1553577184677124, -10.0, -10.0, -10.0, 0.16758452355861664, 0.28610438108444214, -10.0, -10.0, -10.0, -10.0, 0.16353993117809296, -10.0, -10.0, -10.0, -2.069425344467163, -1.7942336797714233, -10.0, -0.7346633076667786, -1.0401614904403687, 0.09276645630598068, -1.6520395278930664, -1.2082874774932861, -10.0, -1.5517327785491943, 0.1271722912788391, -10.0, -1.9726548194885254, -1.765112280845642, -1.5085489749908447, -10.0, -1.1465851068496704, -10.0, -10.0, -10.0, -0.12911361455917358, -10.0, -10.0, -10.0, -0.8933027982711792, -2.788639783859253, -0.8835291266441345, -10.0, -10.0, -10.0, -10.0, -1.5293983221054077, -0.6477789282798767, -10.0, -10.0, -10.0, -1.7575668096542358, -10.0]\n"
     ]
    }
   ],
   "source": [
    "out_list = []\n",
    "target_list = []\n",
    "for i in range(161):\n",
    "    a,b = eval_cts.dataset[i]\n",
    "    temp,_ = eval_cts.backbone(a.unsqueeze(0).cuda())\n",
    "    out = eval_cts.decoder(temp)\n",
    "    target_list.append(b.item())\n",
    "    # print(out)\n",
    "    out_list.append(out.item())\n",
    "print(out_list)\n",
    "print(target_list)\n",
    "#again it's identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.6944572925567627, -3.5482840538024902, -2.6488823890686035, -1.5765224695205688, -2.0324881076812744, -1.9059442281723022, -1.935296893119812, -1.8656620979309082, -2.807563304901123, -1.7708081007003784, -1.7910076379776, -2.974327564239502, -3.157135009765625, -1.4886542558670044, -1.6838747262954712, -3.262155532836914, -3.2835679054260254, -3.0905637741088867, -3.900477886199951, -1.6204434633255005, -2.0744025707244873, -3.1481966972351074, -2.687521457672119, -2.5804500579833984, -2.1136252880096436, -4.300700664520264, -2.3060755729675293, -3.5245251655578613, -2.606001138687134, -4.313931941986084, -1.5561338663101196, -4.34887170791626, -2.220216989517212, -5.105462551116943, -2.5611324310302734, -1.5914322137832642, -1.86241614818573, 0.3044491112232208, -3.1939897537231445, -2.222928047180176, -3.2100372314453125, -3.5089094638824463, -2.8917698860168457, -2.4294347763061523, -3.883242130279541, -1.6462360620498657, -1.343845009803772, -2.3092904090881348, -1.3396259546279907, -2.6582815647125244, -3.0010859966278076, 0.6580632925033569, -0.6834564208984375, 0.984283447265625, -0.713620662689209, -1.110417366027832, -0.5802149772644043, -0.03529435768723488, -1.6055673360824585, -1.6840240955352783, -0.06722088158130646, 0.002575572580099106, -1.2136214971542358, 0.017127525061368942, -0.8849719762802124, 0.06268461793661118, -0.11986876279115677, -0.04067457839846611, -0.42076870799064636, -2.258789539337158, -1.4747320413589478, 0.1699948012828827, -2.6361477375030518, -1.4653714895248413, -0.052640561014413834, -0.19160665571689606, 0.13670791685581207, -0.4982781708240509, -2.4623777866363525, -3.049304246902466, -2.7216358184814453, -0.426930695772171, 0.15234710276126862, 0.6233233213424683, -0.48487570881843567, -0.149422749876976, 0.6356405019760132, -0.47928479313850403, -0.7609539031982422, -1.2304365634918213, -2.061647891998291, -1.382280945777893, -0.20233027637004852, -2.181475877761841, -0.2662754952907562, -2.241938591003418, -3.082736015319824, -0.28951361775398254, -0.000890292227268219, -1.1384730339050293, -1.758261799812317, 0.2443910837173462, 0.433746874332428, -1.7250893115997314, -0.04298394173383713, 0.4689336121082306, -0.13550665974617004, -1.255130648612976, -0.16212251782417297, 0.5453355312347412, -0.9266834259033203, 0.4271168112754822, -0.9526975154876709, -0.15838170051574707, 0.34226343035697937, 0.3696880638599396, -0.06749188899993896, -1.1884381771087646, -0.6517457962036133, 0.6323513984680176, -0.3312434256076813, 0.42851176857948303, 0.48398157954216003, 0.19137364625930786, 0.25212588906288147, 0.08996115624904633, 0.04581731557846069, 0.5946352481842041, -0.10364609956741333, -0.026654381304979324, 0.7556709051132202, -0.4591563642024994, 0.7181116342544556, -1.4311208724975586, 0.20228087902069092, -0.21380293369293213, -0.23324882984161377, 0.32024145126342773, 0.2978803813457489, 0.31939268112182617, 0.4509567320346832, 0.29939645528793335, -0.15612998604774475, 0.1114068329334259, 0.1736413836479187, 0.7545766830444336, -0.05575264245271683, -0.5088237524032593, 0.10936715453863144, -0.8974075317382812, 0.016947489231824875, -0.374306321144104, -1.0978981256484985, -0.21696512401103973, 0.8823245763778687, 0.7457247972488403, 0.9218277931213379, -1.541843295097351, -1.042206883430481, -0.22077396512031555, 0.14859749376773834]\n",
      "[-10.0, -1.1887824535369873, -10.0, -2.6833858489990234, -10.0, -10.0, -10.0, -10.0, -10.0, -3.1969776153564453, -3.1362497806549072, -0.6400231122970581, -10.0, -2.7933340072631836, -10.0, -10.0, -10.0, -10.0, -10.0, -2.9363996982574463, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1.998849630355835, -10.0, -10.0, -10.0, -10.0, -2.0236284732818604, -2.536665678024292, -10.0, -10.0, -0.655671238899231, -10.0, -10.0, -10.0, -10.0, -10.0, -0.4903869330883026, -10.0, -10.0, -10.0, -10.0, -10.0, 1.06658136844635, 0.1828390210866928, 0.7806593179702759, -0.4622040092945099, -0.5024291276931763, -1.3944478034973145, -10.0, -10.0, -10.0, -1.4566693305969238, -1.547255516052246, 0.2794352173805237, -1.567384123802185, 0.14112979173660278, -1.2770898342132568, -1.828007698059082, -1.3054472208023071, -10.0, -10.0, -10.0, -1.2153116464614868, -10.0, -10.0, -1.3411656618118286, -1.8703548908233643, -10.0, -10.0, -10.0, -10.0, -10.0, -2.5883989334106445, -10.0, -1.2475354671478271, -0.9298538565635681, -1.9488379955291748, -0.5997374653816223, -1.9992496967315674, -0.9324906468391418, -10.0, -0.3091193735599518, -0.8642642498016357, -10.0, -0.8926644325256348, -2.047895908355713, -10.0, -10.0, -0.5905786752700806, -10.0, -10.0, -10.0, -1.399096131324768, 0.0884815976023674, -10.0, -1.115040898323059, -10.0, -1.4758903980255127, -10.0, -2.7342734336853027, 0.09232824295759201, -10.0, -2.1829795837402344, -10.0, -0.34054824709892273, -0.5071597099304199, -1.949899435043335, -10.0, -1.0592542886734009, -1.02619469165802, 1.0863373279571533, -2.9089202880859375, -0.6977826952934265, -1.0935816764831543, -2.3464784622192383, -2.588432550430298, -0.7038843035697937, -2.263981342315674, -1.0744954347610474, -0.6802108883857727, -2.078263521194458, -0.46556365489959717, -1.535206913948059, -10.0, -0.5768289566040039, -10.0, 0.1599285751581192, -2.8513219356536865, -10.0, -1.638949990272522, -0.49033913016319275, -10.0, 0.020006461068987846, -1.3320528268814087, 0.8548859357833862, -0.31335169076919556, -0.14869368076324463, -0.8416526317596436, -0.6984882950782776, -1.6843786239624023, -10.0, -10.0, -3.118088722229004, -10.0, 0.8080921769142151, -0.5789642930030823, -0.03581441566348076, 0.27019500732421875, -10.0, -10.0, -3.0268118381500244, -2.2396504878997803]\n"
     ]
    }
   ],
   "source": [
    "out_list = []\n",
    "target_list = []\n",
    "for i in range(161,322):\n",
    "    a,b = eval_cts.dataset[i]\n",
    "    temp,_ = eval_cts.backbone(a.unsqueeze(0).cuda())\n",
    "    out = eval_cts.decoder(temp)\n",
    "    target_list.append(b.item())\n",
    "    # print(out)\n",
    "    out_list.append(out.item())\n",
    "print(out_list)\n",
    "print(target_list)\n",
    "#again it's identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([105252, 161])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs[0].shape #it's a tensor, so we can just use torch.save to save it out!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now testing the evaluations\n",
    "\n",
    "Firwst load in the models nad make sure targets are identical\n",
    "\n",
    "Then do some similar plots to compare the 4 models,  and find the global mse and stuff liek that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
