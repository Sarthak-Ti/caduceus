{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# more evaluatations for the joint model\n",
    "\n",
    "First seeing can we trian a model with masking rate of 0, what does it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/data1/lesliec/sarthak/caduceus/')\n",
    "from src.dataloaders.datasets.general_dataset import GeneralDataset\n",
    "dataset = GeneralDataset(\n",
    "    split='train',\n",
    "    preprocess=False,\n",
    "    data_path='/data1/lesliec/sarthak/data/DK_zarr/zarr_arrays/cell_type_arrays/GM12878_DNase.npz',\n",
    "    length=524288,\n",
    "    shift_sequences=1000,\n",
    "    load_in=False,\n",
    "    mlm=.25,\n",
    "    acc_mlm=.25,\n",
    "    acc_type='continuous',\n",
    "    acc_mask_size=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see an example\n",
    "out = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([524288, 6])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([524288, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "random_pred = torch.rand(out[1][0][:,:-1].shape)\n",
    "random_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 524288, 5]), torch.Size([1, 524288, 6]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_pred.unsqueeze(0).shape, out[1][0].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6429)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and then we compute the loss\n",
    "import torch.nn.functional as F\n",
    "def ce_loss_mask_seq(x, y):\n",
    "    \"\"\"\n",
    "    Cross entropy loss for sequence classification.\n",
    "    \n",
    "    x: tuple (seq, dummy)\n",
    "         - seq: (batch_size, seq_len, vocab_size)\n",
    "    y: tuple (seq_unmask, dummy)\n",
    "         - seq_unmask: (batch_size, seq_len, vocab_size+1)  (last channel is the mask)\n",
    "    \"\"\"\n",
    "    seq = x[0]\n",
    "    seq_unmask = y[0]\n",
    "    \n",
    "    # Create mask from last column of seq_unmask\n",
    "    mask = seq_unmask[:, :, -1] == 1\n",
    "    seq_pred = seq[mask]\n",
    "    # Remove mask channel from target; resulting shape is (N, vocab_size)\n",
    "    seq_target = seq_unmask[mask][:, :-1]\n",
    "    \n",
    "    loss = F.cross_entropy(seq_pred, seq_target)\n",
    "    return loss\n",
    "ce_loss_mask_seq((random_pred.unsqueeze(0),None), (out[1][0].unsqueeze(0),None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"bernoulli_tensor_cpu_p_\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#see that works, what if mask returns nothing\u001b[39;00m\n\u001b[1;32m      2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m GeneralDataset(\n\u001b[1;32m      3\u001b[0m     split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     preprocess\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     acc_mask_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/data1/lesliec/sarthak/caduceus/src/dataloaders/datasets/general_dataset.py:422\u001b[0m, in \u001b[0;36mGeneralDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mone_hot:\n\u001b[1;32m    420\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLM only works with one hot encoding for now, but can easily be generalized to this\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 422\u001b[0m     seq, seq_unmask \u001b[38;5;241m=\u001b[39m \u001b[43mmask_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_pct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace_with_N\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace_with_N\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#this will mask the data and return the unmasked data as well, so we can use it for the rest of the processing\u001b[39;00m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;66;03m# seq_unmask = seq_unmask.transpose(1, 0) #transpose it to be 6 x length, so we can use it for the rest of the processing\u001b[39;00m\n\u001b[1;32m    425\u001b[0m seq \u001b[38;5;241m=\u001b[39m seq\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m#transpose it to be 6 x length, so we can use it for the rest of the processing\u001b[39;00m\n",
      "File \u001b[0;32m/data1/lesliec/sarthak/caduceus/src/dataloaders/datasets/general_dataset.py:127\u001b[0m, in \u001b[0;36mmask_seq\u001b[0;34m(seq, mask_pct, replace_with_N, span, stype, weights)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m#clip to make sure between 0 and 1\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     probability_matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(probability_matrix, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#clip to make sure between 0 and 1     \u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m masked_indices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbernoulli\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobability_matrix\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mbool() \u001b[38;5;66;03m#finds which indices to mask, so shape is length, and is True or False for each index\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# Get positions that were chosen to be masked\u001b[39;00m\n\u001b[1;32m    130\u001b[0m all_mask_positions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnonzero(masked_indices)\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m*\u001b[39mspan \u001b[38;5;66;03m#squeeze to remove the extra dimension, and multiply by span to get the actual positions in the original sequence\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"bernoulli_tensor_cpu_p_\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "#see that works, what if mask returns nothing\n",
    "dataset = GeneralDataset(\n",
    "    split='train',\n",
    "    preprocess=False,\n",
    "    data_path='/data1/lesliec/sarthak/data/DK_zarr/zarr_arrays/cell_type_arrays/GM12878_DNase.npz',\n",
    "    length=524288,\n",
    "    shift_sequences=1000,\n",
    "    load_in=False,\n",
    "    mlm=0,\n",
    "    acc_mlm=.25,\n",
    "    acc_type='continuous',\n",
    "    acc_mask_size=500,\n",
    ")\n",
    "out = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524288,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's see what it's doing and what the issue is\n",
    "chrom, start, end, split = dataset.sequences.iloc[0]\n",
    "seq = dataset.genome[chrom][start:end]\n",
    "seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = torch.LongTensor(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([524288, 5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = seq\n",
    "x_onehot = torch.nn.functional.one_hot(x-7, num_classes=5).float() #N is its own class, also no transpose, so shape is seq_lenx5\n",
    "seq = x_onehot\n",
    "seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "span=1\n",
    "mask_pct = 0.15\n",
    "num_elements = seq.shape[0]//span\n",
    "probability_matrix = torch.full((num_elements,), mask_pct)\n",
    "masked_indices = torch.bernoulli(probability_matrix).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"bernoulli_tensor_cpu_p_\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m num_elements \u001b[38;5;241m=\u001b[39m seq\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mspan\n\u001b[1;32m      4\u001b[0m probability_matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((num_elements,), mask_pct)\n\u001b[0;32m----> 5\u001b[0m masked_indices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbernoulli\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobability_matrix\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mbool()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"bernoulli_tensor_cpu_p_\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "span=1\n",
    "mask_pct = 0\n",
    "num_elements = seq.shape[0]//span\n",
    "probability_matrix = torch.full((num_elements,), mask_pct)\n",
    "masked_indices = torch.bernoulli(probability_matrix).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_matrix.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "span=1\n",
    "mask_pct = 0\n",
    "num_elements = seq.shape[0]//span\n",
    "probability_matrix = torch.full((num_elements,), mask_pct).float()\n",
    "masked_indices = torch.bernoulli(probability_matrix).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "span=1\n",
    "mask_pct = 0.15\n",
    "num_elements = seq.shape[0]//span\n",
    "probability_matrix = torch.full((num_elements,), mask_pct).float()\n",
    "masked_indices = torch.bernoulli(probability_matrix).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 524288, 5]), torch.Size([1, 524288, 6]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_pred.unsqueeze(0).shape, out[1][0].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/data1/lesliec/sarthak/caduceus/')\n",
    "from src.dataloaders.datasets.general_dataset import GeneralDataset\n",
    "#and then we compute the loss\n",
    "#see that works, what if mask returns nothing\n",
    "dataset = GeneralDataset(\n",
    "    split='train',\n",
    "    preprocess=False,\n",
    "    data_path='/data1/lesliec/sarthak/data/DK_zarr/zarr_arrays/cell_type_arrays/GM12878_DNase.npz',\n",
    "    length=524288,\n",
    "    shift_sequences=1000,\n",
    "    load_in=False,\n",
    "    mlm=0,\n",
    "    acc_mlm=.25,\n",
    "    acc_type='continuous',\n",
    "    acc_mask_size=500,\n",
    ")\n",
    "out = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([524288, 6])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([524288, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "random_pred = torch.rand(out[1][0][:,:-1].shape)\n",
    "random_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([124427.,  90194.,  88400., 110544., 110723.,      0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1][0].sum(0) #no masks, this is fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's \n",
    "\n",
    "import torch.nn.functional as F\n",
    "def ce_loss_mask_seq(x, y):\n",
    "    \"\"\"\n",
    "    Cross entropy loss for sequence classification. Note that if nothing is masked, it checks everything\n",
    "    \n",
    "    x: tuple (seq, dummy)\n",
    "         - seq: (batch_size, seq_len, vocab_size)\n",
    "    y: tuple (seq_unmask, dummy)\n",
    "         - seq_unmask: (batch_size, seq_len, vocab_size+1)  (last channel is the mask)\n",
    "    \"\"\"\n",
    "    seq = x[0]\n",
    "    seq_unmask = y[0]\n",
    "    \n",
    "    # Create mask from last column of seq_unmask\n",
    "    mask = seq_unmask[:, :, -1] == 1\n",
    "    \n",
    "    seq_pred = seq[mask]\n",
    "    # Remove mask channel from target; resulting shape is (N, vocab_size)\n",
    "    seq_target = seq_unmask[mask][:, :-1]\n",
    "    \n",
    "    loss = F.cross_entropy(seq_pred, seq_target)\n",
    "    return loss\n",
    "ce_loss_mask_seq((random_pred.unsqueeze(0),None), (out[1][0].unsqueeze(0),None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask  = out[1][0][:,-1] == 1\n",
    "mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6422)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ce_loss_mask_seq(x, y):\n",
    "    \"\"\"\n",
    "    Cross entropy loss for sequence classification. Note that if nothing is masked, it checks everything\n",
    "    \n",
    "    x: tuple (seq, dummy)\n",
    "         - seq: (batch_size, seq_len, vocab_size)\n",
    "    y: tuple (seq_unmask, dummy)\n",
    "         - seq_unmask: (batch_size, seq_len, vocab_size+1)  (last channel is the mask)\n",
    "    \"\"\"\n",
    "    seq = x[0]\n",
    "    seq_unmask = y[0]\n",
    "    \n",
    "    # Create mask from last column of seq_unmask\n",
    "    mask = seq_unmask[:, :, -1] == 1\n",
    "    \n",
    "    if mask.sum().item() == 0:\n",
    "        # If no mask is present, just calculate it on everything\n",
    "        mask = torch.ones_like(seq_unmask[:, :, -1], dtype=torch.bool)\n",
    "        \n",
    "    seq_pred = seq[mask]\n",
    "    # Remove mask channel from target; resulting shape is (N, vocab_size)\n",
    "    seq_target = seq_unmask[mask][:, :-1]\n",
    "    \n",
    "    loss = F.cross_entropy(seq_pred, seq_target)\n",
    "    return loss\n",
    "ce_loss_mask_seq((random_pred.unsqueeze(0),None), (out[1][0].unsqueeze(0),None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6422)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and let's see if we do class indices if it's more efficient\n",
    "def ce_loss_mask_seq(x, y):\n",
    "    \"\"\"\n",
    "    Cross entropy loss for sequence classification. Note that if nothing is masked, it checks everything\n",
    "    \n",
    "    x: tuple (seq, dummy)\n",
    "         - seq: (batch_size, seq_len, vocab_size)\n",
    "    y: tuple (seq_unmask, dummy)\n",
    "         - seq_unmask: (batch_size, seq_len, vocab_size+1)  (last channel is the mask)\n",
    "    \"\"\"\n",
    "    seq = x[0]\n",
    "    seq_unmask = y[0]\n",
    "    \n",
    "    # Create mask from last column of seq_unmask\n",
    "    mask = seq_unmask[:, :, -1] == 1\n",
    "    \n",
    "    if mask.sum().item() == 0:\n",
    "        # If no mask is present, just calculate it on everything\n",
    "        mask = torch.ones_like(seq_unmask[:, :, -1], dtype=torch.bool)\n",
    "        \n",
    "    seq_pred = seq[mask]\n",
    "    # Remove mask channel from target; resulting shape is (N, vocab_size)\n",
    "    seq_target = seq_unmask[mask][:, :-1]\n",
    "    \n",
    "    loss = F.cross_entropy(seq_pred, seq_target.argmax(dim=-1))\n",
    "    return loss\n",
    "ce_loss_mask_seq((random_pred.unsqueeze(0),None), (out[1][0].unsqueeze(0),None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([524288, 5])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_unmask = out[1][0].unsqueeze(0)\n",
    "mask = torch.ones_like(seq_unmask[:, :, -1], dtype=torch.bool)\n",
    "seq_target = seq_unmask[mask][:, :-1]\n",
    "seq_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4,  ..., 3, 3, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_target.argmax(dim=-1) #yeah works as expecteed!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for indices: 5.562175750732422 seconds\n",
      "Time taken for one hot: 3.487555980682373 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    F.cross_entropy(random_pred, seq_target.argmax(dim=-1))\n",
    "print(f'Time taken for indices: {time.time()-start} seconds')\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    F.cross_entropy(random_pred, seq_target)\n",
    "print(f'Time taken for one hot: {time.time()-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for indices: 6.6588006019592285 seconds\n",
      "Time taken for one hot: 3.4974451065063477 seconds\n"
     ]
    }
   ],
   "source": [
    "#let's test this on the GPU, we've been doing it on the cpu\n",
    "random_pred = random_pred.cuda()\n",
    "seq_target = seq_target.cuda()\n",
    "start = time.time() \n",
    "for i in range(1000):\n",
    "    F.cross_entropy(random_pred, seq_target.argmax(dim=-1))\n",
    "print(f'Time taken for indices: {time.time()-start} seconds')\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    F.cross_entropy(random_pred, seq_target)\n",
    "print(f'Time taken for one hot: {time.time()-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for indices: 14.083431959152222 seconds\n"
     ]
    }
   ],
   "source": [
    "#let's test it more rigorously, set a torch random seed\n",
    "torch.manual_seed(0)\n",
    "vals_indices = []\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    random_pred = torch.rand(out[1][0][:,:-1].shape).cuda()\n",
    "    seq_target = seq_target.cuda()\n",
    "    vals_indices.append(F.cross_entropy(random_pred, seq_target.argmax(dim=-1)))\n",
    "print(f'Time taken for indices: {time.time()-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for one hot: 12.698261737823486 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "vals_onehot = []\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    random_pred = torch.rand(out[1][0][:,:-1].shape).cuda()\n",
    "    seq_target = seq_target.cuda()\n",
    "    vals_onehot.append(F.cross_entropy(random_pred, seq_target))\n",
    "print(f'Time taken for one hot: {time.time()-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(torch.tensor(vals_indices),torch.tensor(vals_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([524288, 5])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 2,  ..., 3, 4, 1], device='cuda:0')\n",
      "tensor([[0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "random_pred = torch.rand((32000,5)).cuda()\n",
    "random_target = torch.randint(0,5,(32000,)).cuda()\n",
    "random_target_onehot = torch.nn.functional.one_hot(random_target, num_classes=5).float()\n",
    "print(random_target)\n",
    "print(random_target_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32000, 5]), torch.Size([32000]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_target_onehot.shape, random_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for one hot: 0.03280234336853027 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    F.cross_entropy(random_pred, random_target_onehot)\n",
    "print(f'Time taken for one hot: {time.time()-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for indices: 0.2142198085784912 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    F.cross_entropy(random_pred, random_target)\n",
    "print(f'Time taken for indices: {time.time()-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for indices: 0.31087613105773926 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    F.cross_entropy(random_pred, random_target_onehot.argmax(dim=-1))\n",
    "print(f'Time taken for indices: {time.time()-start} seconds')\n",
    "#why is this the slowest, I don't get it? let's stick to one hot labels I guess"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
