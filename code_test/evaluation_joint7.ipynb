{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "015f7cc9",
   "metadata": {},
   "source": [
    "# we will look at 2 files, TF prediction and the pooled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ff2c88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JointMaskingDecoder: d_model=1024, d_output1=5, d_output2=1, upsample=4\n",
      "JointMaskingEncoder: d_model=1024, d_input1=6, d_input2=2, joint=False, kernel_size=15, combine=True, acc_type=continuous\n"
     ]
    }
   ],
   "source": [
    "# first the pooled model, it should be identical, so let's see if our default code works\n",
    "\n",
    "import sys\n",
    "sys.path.append('/data1/lesliec/sarthak/caduceus/evals')\n",
    "from evals_utils_joint import Evals\n",
    "\n",
    "ckpt_path = '/data1/lesliec/sarthak/caduceus/outputs/2025-07-09/12-35-55-535137/checkpoints/01-val_loss=0.27462.ckpt'\n",
    "evals = Evals(ckpt_path,load_data=False, device=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44730ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1937"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evals.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7db36175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 524288]) torch.Size([2, 524288]) torch.Size([524288, 6]) torch.Size([524288, 2])\n"
     ]
    }
   ],
   "source": [
    "a,b = evals.dataset[0]\n",
    "print(a[0].shape, a[1].shape, b[0].shape, b[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3b50d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just one cell type so it makes sense. let's see the outputs of each of the things\n",
    "(seq,acc),(seq_unmask,acc_unmask) = evals.dataset[0]\n",
    "x = seq.unsqueeze(0)\n",
    "y = acc.unsqueeze(0)\n",
    "x,y = x.to(evals.device), y.to(evals.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab93e6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024, 131072])\n",
      "bin_size_1 torch.Size([1, 512, 524288])\n",
      "bin_size_2 torch.Size([1, 1024, 262144])\n",
      "torch.Size([1, 131072, 1024])\n",
      "torch.Size([1, 524288, 5]) torch.Size([1, 524288, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "with torch.no_grad():\n",
    "    x1,intermediates = evals.encoder(x,y)\n",
    "    print(x1.shape)\n",
    "    for k,v in intermediates.items():\n",
    "        print(k, v.shape)\n",
    "    x1,_ = evals.backbone(x1)\n",
    "    print(x1.shape)\n",
    "    x1 = evals.decoder(x1, intermediates)\n",
    "    seq,acc = x1\n",
    "    print(seq.shape, acc.shape)\n",
    "\n",
    "#yeah, it looks good! clearly still downsampled!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7d6292",
   "metadata": {},
   "source": [
    "# now do it for the TF prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6228e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JointMaskingEncoder: d_model=256, d_input1=6, d_input2=2, joint=False, kernel_size=15, combine=True, acc_type=continuous\n"
     ]
    }
   ],
   "source": [
    "# can't use the base evals since it  can't use that evals, but it should be fine to load the model still?\n",
    "# no, it's a separate decoder and stuff\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/data1/lesliec/sarthak/caduceus/')\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from src.dataloaders.datasets.general_dataset import GeneralDataset\n",
    "from src.models.sequence.dna_embedding import DNAEmbeddingModelCaduceus\n",
    "from src.tasks.decoders import EnformerDecoder\n",
    "from src.tasks.encoders import JointCNN\n",
    "from caduceus.configuration_caduceus import CaduceusConfig\n",
    "import yaml\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "import itertools\n",
    "import inspect\n",
    "import zarr\n",
    "from numcodecs import Blosc\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "\n",
    "try:\n",
    "    OmegaConf.register_new_resolver('eval', eval)\n",
    "    OmegaConf.register_new_resolver('div_up', lambda x, y: (x + y - 1) // y)\n",
    "except ValueError as e:\n",
    "    if \"Resolver already registered\" in str(e):\n",
    "            print(\"Resolver already exists, skipping registration.\")\n",
    "\n",
    "class Evals():\n",
    "    def __init__(self,\n",
    "                 ckpt_path,\n",
    "                 dataset=None,\n",
    "                 split = 'test',\n",
    "                 device = None,\n",
    "                 load_data=False,\n",
    "                 **dataset_overrides #Don't pass None into overrides unless you intentionally want it to be None! Pass in items only that you need\n",
    "                 ) -> None:\n",
    "        \n",
    "        #now load the cfg from the checkpoint path\n",
    "        model_cfg_path = os.path.join(os.path.dirname(os.path.dirname(ckpt_path)), '.hydra', 'config.yaml')\n",
    "        cfg = yaml.load(open(model_cfg_path, 'r'), Loader=yaml.FullLoader)\n",
    "        cfg = OmegaConf.create(cfg)\n",
    "        self.cfg = OmegaConf.to_container(cfg, resolve=True)\n",
    "        \n",
    "        state_dict = torch.load(ckpt_path, map_location='cpu')\n",
    "        if device is not None:\n",
    "            #if we are given a device, we will use that device\n",
    "            self.device = torch.device(device)\n",
    "        else:\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.split = split\n",
    "\n",
    "        #now set up dataset\n",
    "        if dataset is None:\n",
    "            dataset_args = self.cfg['dataset']\n",
    "            # assert dataset_args['mlm'] == 0 and dataset_args['acc_mlm'] == 0, \"MLM and acc_mlm should be 0 for the training\"\n",
    "            sig = inspect.signature(GeneralDataset.__init__)\n",
    "            sig = {k: v for k, v in sig.parameters.items() if k != 'self'}\n",
    "            to_remove = []\n",
    "            for k, v in dataset_args.items():\n",
    "                if k not in sig:\n",
    "                    # del dataset_args[k]\n",
    "                    to_remove.append(k)\n",
    "            for k in to_remove:\n",
    "                del dataset_args[k]\n",
    "            dataset_args['split'] = split\n",
    "            dataset_args['evaluating'] = True #this tells it to not do things like random shifting and rc aug, still does random masking tho, can get og sequence easily\n",
    "            dataset_args['load_in'] = load_data\n",
    "            \n",
    "            for k, v in dataset_overrides.items():\n",
    "                if k in sig:\n",
    "                    dataset_args[k] = v\n",
    "                    print(f\"Overriding {k} with {v}\")\n",
    "                else:\n",
    "                    print(f\"Warning: {k} not in dataset args, skipping\")\n",
    "            \n",
    "            # dataset_args['rc_aug'] = False #we don't want to do rc aug in our evaluation class!!!\n",
    "            self.dataset_args = dataset_args\n",
    "            # self.dataset_args['rc_aug'] = False #we don't want to do rc aug in our evaluation class!!!\n",
    "            self.dataset = GeneralDataset(**dataset_args)\n",
    "            \n",
    "            # self.kmer_len = dataset_args['kmer_len']\n",
    "            # self.dataset = enformer_dataset.EnformerDataset(split, dataset_args['max_length'], rc_aug = dataset_args['rc_aug'],\n",
    "            #                                                 return_CAGE=dataset_args['return_CAGE'], cell_type=dataset_args.get('cell_type', None),\n",
    "            #                                                 kmer_len=dataset_args['kmer_len']) #could use dataloader instead, but again kinda complex\n",
    "        else:\n",
    "            self.dataset = dataset\n",
    "         \n",
    "        torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            state_dict[\"state_dict\"], \"model.\"\n",
    "        )\n",
    "        model_state_dict = state_dict[\"state_dict\"]\n",
    "        # need to remove torchmetrics. to remove keys, need to convert to list first\n",
    "        for key in list(model_state_dict.keys()):\n",
    "            if \"torchmetrics\" in key:\n",
    "                model_state_dict.pop(key)\n",
    "        # the state_dict keys slightly mismatch from Lightning..., so we fix it here\n",
    "        decoder_state_dict = {}\n",
    "        for key in list(model_state_dict.keys()):\n",
    "            if \"decoder\" in key:\n",
    "                decoder_state_dict[key[10:]] = model_state_dict.pop(key)\n",
    "        encoder_state_dict = {}\n",
    "        for key in list(model_state_dict.keys()):\n",
    "            if \"encoder\" in key:\n",
    "                encoder_state_dict[key[10:]] = model_state_dict.pop(key)\n",
    "        \n",
    "        cfg['model']['config'].pop('_target_')\n",
    "        # cfg['model']['config']['complement_map'] = self.dataset.tokenizer.complement_map\n",
    "        caduceus_cfg = CaduceusConfig(**cfg['model']['config'])\n",
    "        \n",
    "        self.backbone = DNAEmbeddingModelCaduceus(config=caduceus_cfg)\n",
    "        self.backbone.load_state_dict(model_state_dict, strict=True)\n",
    "        \n",
    "        #remove self.cfg['decoder']['_name_']\n",
    "        del self.cfg['decoder']['_name_']\n",
    "        self.cfg['decoder']['d_model'] = self.cfg['model']['config']['d_model']\n",
    "        self.decoder = EnformerDecoder(**self.cfg['decoder']) #could do with instantiating, but that is rather complex\n",
    "        self.decoder.load_state_dict(decoder_state_dict, strict=True)\n",
    "        \n",
    "        del self.cfg['encoder']['_name_']\n",
    "        self.cfg['encoder']['d_model'] = self.cfg['model']['config']['d_model']\n",
    "        self.encoder = JointCNN(**self.cfg['encoder'])\n",
    "        self.encoder.load_state_dict(encoder_state_dict, strict=True)\n",
    "        \n",
    "        self.encoder.to(self.device).eval()\n",
    "        self.backbone.to(self.device).eval()\n",
    "        self.decoder.to(self.device).eval()\n",
    "        \n",
    "    def __call__(self, idx=None, data=None):\n",
    "        #now evaluate the model on one example\n",
    "        if data is None:\n",
    "            (seq,acc),(seq_unmask,acc_unmask, exp) = self.dataset[idx]\n",
    "            \n",
    "            x = seq.unsqueeze(0)\n",
    "            y = acc.unsqueeze(0)\n",
    "        else:\n",
    "            (x,y),(seq_unmask,acc_unmask, exp) = data\n",
    "\n",
    "            if x.dim() == 2:\n",
    "                x = x.unsqueeze(0) #add batch dim\n",
    "                y = y.unsqueeze(0) #add batch dim\n",
    "        \n",
    "        x,y = x.to(self.device), y.to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x1,_ = self.encoder(x,y)\n",
    "            x1,_ = self.backbone(x1)\n",
    "            x1 = self.decoder(x1)\n",
    "        \n",
    "        return x1\n",
    "\n",
    "ckpt_path = '/data1/lesliec/sarthak/caduceus/outputs/2025-07-07/15-25-26-980519/checkpoints/05-val_loss=0.75187.ckpt'\n",
    "evals = Evals(ckpt_path,load_data=False, device=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72f26290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1937"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evals.dataset) #again just one cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9a2c538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnformerDecoder(\n",
       "  (final_pointwise): Sequential(\n",
       "    (0): Rearrange('b n d -> b d n')\n",
       "    (1): Sequential(\n",
       "      (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): GELU()\n",
       "      (2): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (2): Rearrange('b d n -> b n d')\n",
       "    (3): Dropout(p=0.05, inplace=False)\n",
       "    (4): GELU()\n",
       "  )\n",
       "  (output_transform): Linear(in_features=512, out_features=162, bias=True)\n",
       "  (pool): AvgPool1d(kernel_size=(1,), stride=(1,), padding=(0,))\n",
       "  (softplus): Softplus(beta=1, threshold=20)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals.decoder #clearly seems correct, let's try it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "604f0523",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = evals(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a15298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 524288, 162])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape #looks about right! Good to see!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65637277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
