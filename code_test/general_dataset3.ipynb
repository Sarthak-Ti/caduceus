{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General dataset 3\n",
    "\n",
    "I need this to work on multiple cell types, idea is it can load in the values for diffeerrent cell types based on the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacing cell type number with data indices\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/data1/lesliec/sarthak/caduceus')\n",
    "from src.dataloaders.datasets.general_dataset import GeneralDataset\n",
    "dataset = GeneralDataset(\n",
    "    split='train',\n",
    "    data_path='/data1/lesliec/sarthak/data/DK_zarr/zarr_arrays/test_chrom_dnase_chunkchrom.zarr',\n",
    "    length=524288,\n",
    "    mlm=0.25,\n",
    "    acc_mlm=0.25,\n",
    "    data_idxs='/data1/lesliec/sarthak/data/DK_zarr/idx_lists/all_matched_immune.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>0</td>\n",
       "      <td>524288</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>262144</td>\n",
       "      <td>786432</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>524288</td>\n",
       "      <td>1048576</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>786432</td>\n",
       "      <td>1310720</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1048576</td>\n",
       "      <td>1572864</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8879</th>\n",
       "      <td>chrX</td>\n",
       "      <td>154402816</td>\n",
       "      <td>154927104</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8880</th>\n",
       "      <td>chrX</td>\n",
       "      <td>154664960</td>\n",
       "      <td>155189248</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8881</th>\n",
       "      <td>chrX</td>\n",
       "      <td>154927104</td>\n",
       "      <td>155451392</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8882</th>\n",
       "      <td>chrX</td>\n",
       "      <td>155189248</td>\n",
       "      <td>155713536</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8883</th>\n",
       "      <td>chrX</td>\n",
       "      <td>155451392</td>\n",
       "      <td>155975680</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8884 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2      3\n",
       "0     chr1          0     524288  train\n",
       "1     chr1     262144     786432  train\n",
       "2     chr1     524288    1048576  train\n",
       "3     chr1     786432    1310720  train\n",
       "4     chr1    1048576    1572864  train\n",
       "...    ...        ...        ...    ...\n",
       "8879  chrX  154402816  154927104  train\n",
       "8880  chrX  154664960  155189248  train\n",
       "8881  chrX  154927104  155451392  train\n",
       "8882  chrX  155189248  155713536  train\n",
       "8883  chrX  155451392  155975680  train\n",
       "\n",
       "[8884 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's test an output\n",
    "dataset.sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1 = dataset[0]\n",
    "out1[0][1][:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.allclose(out1[0][1], dataset.data['chr1'][0,0:524288]) #not cell ty pe 0, want the first one of the list we defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celltype_idx = dataset.data_idxs[0]\n",
    "np.allclose(out1[0][1], dataset.data['chr1'][celltype_idx,0:524288])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 524288]), (524288,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1[0][1].shape, dataset.data['chr1'][celltype_idx,0:524288].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(out1[1][1][:,0], dataset.data['chr1'][celltype_idx,0:524288])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2277, 4262, 1087, 8842, 8870]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's choose 5 indices at random between 0 and 8883\n",
    "import random\n",
    "rand_idxs = random.sample(range(0, 8883), 5)\n",
    "rand_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for idx in rand_idxs:\n",
    "    out = dataset[idx]\n",
    "    chrom, start, end, split = dataset.sequences.iloc[idx]\n",
    "    print(np.allclose(out[1][1][:,0], dataset.data[chrom][celltype_idx,start:end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([524288])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][1][0][:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with idx 17754\n",
      "done with idx 26638\n",
      "done with idx 35522\n",
      "done with idx 44406\n",
      "done with idx 53290\n",
      "done with idx 62174\n",
      "done with idx 71058\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#works for celltype 0, now let's see if it makes seure all sequences are the same\n",
    "seqs = []\n",
    "i = rand_idxs[-1]\n",
    "while i < len(dataset):\n",
    "    seqs.append(dataset[i][1][0][:,0]) #seocnd one is the mask, that might differ, seq should be identical\n",
    "    # print(seqs[0].shape)\n",
    "    # break\n",
    "    i = i + len(dataset.sequences)\n",
    "    print('done with idx', i)\n",
    "for i in range(len(seqs)-1):\n",
    "    print(np.allclose(seqs[i], seqs[i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "tensor([0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.])\n",
      "tensor([0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "print(len(seqs))\n",
    "print(seqs[0][233333:233333+30])\n",
    "print(seqs[1][233333:233333+30]) #why just A and C?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "print(seqs[0][s:s+30])\n",
    "print(seqs[1][s:s+30])\n",
    "#something is almost definitely wrong??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([524288, 6])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = dataset[i]\n",
    "out[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with idx 17754\n",
      "done with idx 26638\n",
      "done with idx 35522\n",
      "done with idx 44406\n",
      "done with idx 53290\n",
      "done with idx 62174\n",
      "done with idx 71058\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#oh, because it's one hot encoded lmfao!!!!\n",
    "\n",
    "seqs = []\n",
    "i = rand_idxs[-1]\n",
    "while i < len(dataset):\n",
    "    seqs.append(dataset[i][1][0][:,:-1]) #last is the mask!\n",
    "    # print(seqs[0].shape)\n",
    "    # break\n",
    "    i = i + len(dataset.sequences)\n",
    "    print('done with idx', i)\n",
    "for i in range(len(seqs)-1):\n",
    "    print(np.allclose(seqs[i], seqs[i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "tensor([[0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.]])\n",
      "tensor([[0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(len(seqs))\n",
    "print(seqs[0][233333:233333+10])\n",
    "print(seqs[1][233333:233333+10])\n",
    "#this is more like what you would expect!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47493, 57010, 38327, 46623, 30170, 24573, 47601, 4079, 16506, 18139, 22511, 7821, 8241, 61689, 58275]\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#now let's find some truly random regions!\n",
    "\n",
    "rand_idxs = random.sample(range(0, len(dataset)), 15)\n",
    "print(rand_idxs)\n",
    "for idx in rand_idxs:\n",
    "    out = dataset[idx]\n",
    "    celltype_idx = dataset.data_idxs[idx//len(dataset.sequences)] #takes into account\n",
    "    seq_idx = idx % len(dataset.sequences)\n",
    "    chrom, start, end, split = dataset.sequences.iloc[seq_idx]\n",
    "    print(np.allclose(out[1][1][:,0], dataset.data[chrom][celltype_idx,start:end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so it does as we think, finding the right sequence and cell type and then simply grabs those values and then does masking but we looking at true values here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now testing it\n",
    "\n",
    "Added a lot of features like load expression data and can multitask or find the right index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacing cell type number with data indices\n",
      "[4759 4760 4831 4764 4758]\n",
      "[457 177 120 522 392]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('/data1/lesliec/sarthak/caduceus')\n",
    "from src.dataloaders.datasets.general_dataset import GeneralDataset\n",
    "\n",
    "#to finetune on Enformer CAGE\n",
    "dataset = GeneralDataset(\n",
    "    split='train',\n",
    "    data_path='/data1/lesliec/sarthak/data/DK_zarr/zarr_arrays/dnase_chunkchrom_processed.zarr',\n",
    "    sequences_bed_file='/data1/lesliec/sarthak/data/DK_zarr/sequences_enformer.bed',\n",
    "    length=524288,\n",
    "    mlm=0,\n",
    "    acc_mlm=0,\n",
    "    additional_data='/data1/lesliec/sarthak/data/enformer/data/labels.zarr',\n",
    "    additional_data_idxs='/data1/lesliec/sarthak/data/DK_zarr/idx_lists/nob_immune_CAGE.json',\n",
    "    data_idxs='/data1/lesliec/sarthak/data/DK_zarr/idx_lists/nob_immune.json',\n",
    ")\n",
    "\n",
    "#tells it to get train split, then uses base pair DNase for input, then predicts the pooled values from the Enformer CAGE data\n",
    "#data_idxs tells it to subset to thoe indices\n",
    "\n",
    "print(dataset.additional_data_idxs) #CAGE values\n",
    "print(dataset.data_idxs) #DNase values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170105\n",
      "34021\n",
      "5\n",
      "170105\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "print(len(dataset.sequences))\n",
    "print(len(dataset.additional_data_idxs))\n",
    "print(len(dataset.additional_data_idxs)* len(dataset.sequences)) #it's cell types times sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40003\n"
     ]
    }
   ],
   "source": [
    "#so let's get a random index between 0 and 170105\n",
    "import random\n",
    "rand_idx = random.sample(range(0, 170105), 1)[0]\n",
    "print(rand_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 524288]) torch.Size([2, 524288]) torch.Size([524288, 6]) torch.Size([524288, 2]) (896, 1)\n"
     ]
    }
   ],
   "source": [
    "out = dataset[rand_idx]\n",
    "print(out[0][0].shape, out[0][1].shape, out[1][0].shape, out[1][1].shape, out[1][2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5982\n"
     ]
    }
   ],
   "source": [
    "#so based on our approach we would do this. First get cell type information by doing //34021 th eoriginal amount of sequences\n",
    "\n",
    "celltype_idx = rand_idx // 34021\n",
    "print(celltype_idx)\n",
    "\n",
    "#then get the sequence info by doing % 34021\n",
    "seq_idx = rand_idx % 34021\n",
    "print(seq_idx)\n",
    "\n",
    "#also it won't be that actual index sicne we're using a subset of the indices. Just logically looking it will be index 177 for Dnase and 4760 for CAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        chr11\n",
       "1    133564200\n",
       "2    133695272\n",
       "3        train\n",
       "Name: 5982, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sequences.iloc[seq_idx] #this is the sequence info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr11 133367592 133891880 train 524288\n"
     ]
    }
   ],
   "source": [
    "#let's grab chrom, start, end, split\n",
    "chrom, start, end, split = dataset.sequences.iloc[seq_idx]\n",
    "#now have to adjust start and end to be length 524288\n",
    "length = end - start\n",
    "if length < 524288:\n",
    "    start = start - (524288 - length) // 2\n",
    "    end = end + (524288 - length) // 2\n",
    "\n",
    "print(chrom, start, end, split, end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524288,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now let's grab these values\n",
    "seq = dataset.genome[chrom][start:end]\n",
    "seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  9, 10, ...,  7,  8,  8], dtype=int8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][0] #seems to allign, but let's check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11 in seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([524288])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(seq-7, dtype=torch.int64).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([524288, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so let's do torch.nn.onehot\n",
    "seq_onehot = torch.nn.functional.one_hot(torch.tensor(seq-7, dtype=torch.int64), num_classes=4)\n",
    "seq_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 524288])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(out[0][0][:4].t().to(torch.int64), seq_onehot) #so this is the one hot encoded version of the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(674, 135086622)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sequence is the easy part, the hard part is DNase then CAGE\n",
    "dataset.data[chrom].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524288,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset.data[chrom][celltype_idx, start:end]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now let's see if this matches?\n",
    "torch.allclose(out[0][1][0], torch.tensor(data, dtype=torch.float32)) #so this is the DNase data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n"
     ]
    }
   ],
   "source": [
    "#hmmm, let's see\n",
    "#ahh celltype idx is 1, we want the 177 or whatever\n",
    "true_celltype_idx = dataset.data_idxs[celltype_idx]\n",
    "print(true_celltype_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset.data[chrom][true_celltype_idx, start:end]\n",
    "torch.allclose(out[0][1][0], torch.tensor(data, dtype=torch.float32)) #so this is the DNase data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4760\n",
      "(896, 5313)\n"
     ]
    }
   ],
   "source": [
    "#perfect! This all matches as we expect!!\n",
    "#final thing is CAGE, not too bad, similar concept\n",
    "true_celltype_idx = dataset.additional_data_idxs[celltype_idx]\n",
    "print(true_celltype_idx)\n",
    "extra_data = dataset.additional_data[split][seq_idx]\n",
    "print(extra_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(896,)\n"
     ]
    }
   ],
   "source": [
    "extra_data = extra_data[:,true_celltype_idx]\n",
    "print(extra_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(896, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now let's compare\n",
    "np.allclose(out[1][2][:,0], extra_data) #so this is the CAGE data\n",
    "#this matches as well, because the key is to use the sequence index!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I'm now quite confident this is good. Just some housekeeping\n",
    "np.allclose(out[0][0][:5], out[1][0][:,:5].T) #so this is the one hot encoded version of the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(0.))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][0][5].max(), out[0][0][5].min() #all zeros for the mask column!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 524288])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(out[0][1][0,:], out[1][1][:,0]) #so this is the DNase data, all data matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(0.))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][1][1].max(), out[0][1][1].min() #all zeros for the mask column!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so the data looks good then!!! I am happy with the dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how to train for RNA seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the idea is we have models training to predict RNA seq\n",
    "#but we are only inputting DNAse seq for one?\n",
    "\n",
    "#wait yeah it's fine because accessibility input of DNase and then predict all DM12878 tracks, that's fine, only need the one input!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training on enformer task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 45\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataloaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneral_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GeneralDataset\n\u001b[1;32m     34\u001b[0m dataset \u001b[38;5;241m=\u001b[39m GeneralDataset(\n\u001b[1;32m     35\u001b[0m     split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     36\u001b[0m     data_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data1/lesliec/sarthak/data/DK_zarr/zarr_arrays/cell_type_arrays/GM12878_DNase.npz\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     additional_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data1/lesliec/sarthak/data/enformer/data/labels.zarr\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     43\u001b[0m )\n\u001b[0;32m---> 45\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mdatset\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     46\u001b[0m out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, out[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, out[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, out[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datset' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "├── dataset\n",
    "│   └── _name_: GeneralLoader                                                                                                                                                                                                                                                                                                                                                           \n",
    "│       dataset_name: GeneralLoader                                                                                                                                                                                                                                                                                                                                                     \n",
    "│       batch_size_eval: 2                                                                                                                                                                                                                                                                                                                                                              \n",
    "│       shuffle: true                                                                                                                                                                                                                                                                                                                                                                   \n",
    "│       pin_memory: true                                                                                                                                                                                                                                                                                                                                                                \n",
    "│       batch_size: 1                                                                                                                                                                                                                                                                                                                                                                   \n",
    "│       num_workers: 1                                                                                                                                                                                                                                                                                                                                                                  \n",
    "│       data_path: /data1/lesliec/sarthak/data/DK_zarr/zarr_arrays/cell_type_arrays/GM12878_DNase.npz                                                                                                                                                                                                                                                                                   \n",
    "│       length: 524288                                                                                                                                                                                                                                                                                                                                                                  \n",
    "│       shift_sequences: 0                                                                                                                                                                                                                                                                                                                                                              \n",
    "│       load_in: false                                                                                                                                                                                                                                                                                                                                                                  \n",
    "│       rc_aug: false                                                                                                                                                                                                                                                                                                                                                                   \n",
    "│       mlm: 0                                                                                                                                                                                                                                                                                                                                                                          \n",
    "│       acc_mlm: 1                                                                                                                                                                                                                                                                                                                                                                      \n",
    "│       acc_type: continuous                                                                                                                                                                                                                                                                                                                                                            \n",
    "│       acc_mask_size: 500                                                                                                                                                                                                                                                                                                                                                              \n",
    "│       weight_peaks: false                                                                                                                                                                                                                                                                                                                                                             \n",
    "│       additional_data: /data1/lesliec/sarthak/data/enformer/data/labels.zarr                                                                                                                                                                                                                                                                                                          \n",
    "│       sequences_bed_file: /data1/lesliec/sarthak/data/DK_zarr/sequences_enformer.bed  \n",
    "\n",
    "'''\n",
    "\n",
    "#these are the options, let's do it\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('/data1/lesliec/sarthak/caduceus')\n",
    "from src.dataloaders.datasets.general_dataset import GeneralDataset\n",
    "\n",
    "dataset = GeneralDataset(\n",
    "    split='train',\n",
    "    data_path='/data1/lesliec/sarthak/data/DK_zarr/zarr_arrays/cell_type_arrays/GM12878_DNase.npz',\n",
    "    sequences_bed_file='/data1/lesliec/sarthak/data/DK_zarr/sequences_enformer.bed',\n",
    "    length=524288,\n",
    "    shift_sequences=0,\n",
    "    mlm=0,\n",
    "    acc_mlm=1,\n",
    "    additional_data='/data1/lesliec/sarthak/data/enformer/data/labels.zarr',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 524288]),\n",
       " torch.Size([2, 524288]),\n",
       " torch.Size([524288, 6]),\n",
       " torch.Size([524288, 2]),\n",
       " (896, 5313))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = dataset[0]\n",
    "out[0][0].shape, out[0][1].shape, out[1][0].shape, out[1][1].shape, out[1][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(427990.1875)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looks like the right sized output!\n",
    "out[0][1].sum() #wait, there should be no data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  8702.2129, 419288.0000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][1].sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 524288]),\n",
       " torch.Size([2, 524288]),\n",
       " torch.Size([524288, 6]),\n",
       " torch.Size([524288, 2]),\n",
       " (896, 5313))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's do mask only!\n",
    "\n",
    "dataset = GeneralDataset(\n",
    "    split='train',\n",
    "    data_path='/data1/lesliec/sarthak/data/DK_zarr/zarr_arrays/cell_type_arrays/GM12878_DNase.npz',\n",
    "    sequences_bed_file='/data1/lesliec/sarthak/data/DK_zarr/sequences_enformer.bed',\n",
    "    length=524288,\n",
    "    shift_sequences=0,\n",
    "    mlm=0,\n",
    "    acc_mlm=1,\n",
    "    additional_data='/data1/lesliec/sarthak/data/enformer/data/labels.zarr',\n",
    "    mask_only=True,\n",
    ")\n",
    "\n",
    "out = dataset[0]\n",
    "out[0][0].shape, out[0][1].shape, out[1][0].shape, out[1][1].shape, out[1][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(524288.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][1].sum() #yup, just the mask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0., 524288.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][1].sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10839844, 0.10760498, 0.04425049, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.10162354, 0.09332275, 0.0094986 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.10272217, 0.15600586, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.07714844, 0.07678223, 0.03509521, ..., 0.        , 0.01934814,\n",
       "        0.        ],\n",
       "       [0.07666016, 0.03826904, 0.05648804, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.08319092, 0.06051636, 0.02156067, ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's look at the other data\n",
    "out[1][2] #the coveratge, I believe this is fine? Uses t index, so it's all good!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# verifying the fine tuning of multiple cell type models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacing cell type number with data indices, 7\n"
     ]
    }
   ],
   "source": [
    "#we need to both load the proper DNase and exxpression data. Let's make sure it works and that it makes sense\n",
    "#let's see what the config says\n",
    "\n",
    "'''\n",
    "dataset:\n",
    "  _name_: GeneralLoader\n",
    "  dataset_name: GeneralLoader\n",
    "  batch_size_eval: ${eval:${.batch_size} * 2}\n",
    "  shuffle: true\n",
    "  pin_memory: true\n",
    "  batch_size: 1\n",
    "  num_workers: 7\n",
    "  data_path: /data1/lesliec/sarthak/data/DK_zarr/zarr_arrays/dnase_chunkchrom_processed.zarr\n",
    "  length: 524288\n",
    "  shift_sequences: 0\n",
    "  load_in: false\n",
    "  rc_aug: false\n",
    "  mlm: 0\n",
    "  acc_mlm: 0\n",
    "  acc_type: continuous\n",
    "  acc_mask_size: 500\n",
    "  weight_peaks: false\n",
    "  additional_data: /data1/lesliec/sarthak/data/enformer/data/labels.zarr\n",
    "  sequences_bed_file: /data1/lesliec/sarthak/data/DK_zarr/sequences_enformer.bed\n",
    "  additional_data_idxs: /data1/lesliec/sarthak/data/DK_zarr/idx_lists/all_matched_immune_CAGE.json\n",
    "  data_idxs: /data1/lesliec/sarthak/data/DK_zarr/idx_lists/all_matched_immune.json\n",
    "\n",
    "'''\n",
    "\n",
    "#I assume it's correct since the benchmarks seem quite decent?\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/data1/lesliec/sarthak/caduceus')\n",
    "from src.dataloaders.datasets.general_dataset import GeneralDataset\n",
    "\n",
    "dataset = GeneralDataset(\n",
    "    split='train',\n",
    "    data_path='/data1/lesliec/sarthak/data/DK_zarr/zarr_arrays/dnase_chunkchrom_processed.zarr',\n",
    "    sequences_bed_file='/data1/lesliec/sarthak/data/DK_zarr/sequences_enformer.bed',\n",
    "    length=524288,\n",
    "    shift_sequences=0,\n",
    "    mlm=0,\n",
    "    acc_mlm=0,\n",
    "    additional_data='/data1/lesliec/sarthak/data/enformer/data/labels.zarr',\n",
    "    additional_data_idxs='/data1/lesliec/sarthak/data/DK_zarr/idx_lists/all_matched_immune_CAGE.json',\n",
    "    data_idxs='/data1/lesliec/sarthak/data/DK_zarr/idx_lists/all_matched_immune.json',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4759, 4760, 5117, 4831, 4764, 4758, 5110])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.additional_data_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([457, 177, 354, 120, 522, 392,  12])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>genome</th>\n",
       "      <th>identifier</th>\n",
       "      <th>file</th>\n",
       "      <th>clip</th>\n",
       "      <th>scale</th>\n",
       "      <th>sum_stat</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF833POA</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:cerebellum male adult (27 years) and mal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF110QGM</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:frontal cortex male adult (27 years) and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF880MKD</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:chorion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF463ZLQ</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:Ishikawa treated with 0.02% dimethyl sul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF890OGQ</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:GM03348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>5308</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs14239</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:epithelioid sarcoma cell line:HS-ES-2R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>5309</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs14240</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:squamous cell lung carcinoma cell line:RE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5310</th>\n",
       "      <td>5310</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs14241</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:gastric cancer cell line:GSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>5311</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs14244</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:carcinoid cell line:NCI-H727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312</th>\n",
       "      <td>5312</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs14245</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:lung adenocarcinoma, papillary cell line:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5313 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  genome   identifier  \\\n",
       "0         0       0  ENCFF833POA   \n",
       "1         1       0  ENCFF110QGM   \n",
       "2         2       0  ENCFF880MKD   \n",
       "3         3       0  ENCFF463ZLQ   \n",
       "4         4       0  ENCFF890OGQ   \n",
       "...     ...     ...          ...   \n",
       "5308   5308       0    CNhs14239   \n",
       "5309   5309       0    CNhs14240   \n",
       "5310   5310       0    CNhs14241   \n",
       "5311   5311       0    CNhs14244   \n",
       "5312   5312       0    CNhs14245   \n",
       "\n",
       "                                                   file  clip  scale sum_stat  \\\n",
       "0     /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "1     /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "2     /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "3     /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "4     /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "...                                                 ...   ...    ...      ...   \n",
       "5308  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "5309  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "5310  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "5311  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "5312  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "\n",
       "                                            description  \n",
       "0     DNASE:cerebellum male adult (27 years) and mal...  \n",
       "1     DNASE:frontal cortex male adult (27 years) and...  \n",
       "2                                         DNASE:chorion  \n",
       "3     DNASE:Ishikawa treated with 0.02% dimethyl sul...  \n",
       "4                                         DNASE:GM03348  \n",
       "...                                                 ...  \n",
       "5308        CAGE:epithelioid sarcoma cell line:HS-ES-2R  \n",
       "5309  CAGE:squamous cell lung carcinoma cell line:RE...  \n",
       "5310                  CAGE:gastric cancer cell line:GSS  \n",
       "5311                  CAGE:carcinoid cell line:NCI-H727  \n",
       "5312  CAGE:lung adenocarcinoma, papillary cell line:...  \n",
       "\n",
       "[5313 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's just manually verify some things\n",
    "import pandas as pd\n",
    "targets_file = '/data1/lesliec/sarthak/data/enformer/data/targets.txt'\n",
    "df = pd.read_csv(targets_file,sep=\"\\t\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNASE:CD4-positive, alpha-beta T cell male adult (21 year)\n",
      "CAGE:CD4+ T Cells,\n",
      "---\n",
      "DNASE:CD8-positive, alpha-beta T cell male adult (21 year)\n",
      "CAGE:CD8+ T Cells,\n",
      "---\n",
      "DNASE:B cell male adult (21 year)\n",
      "CAGE:CD19+ B Cells,\n",
      "---\n",
      "DNASE:Jurkat clone E61\n",
      "CAGE:acute lymphoblastic leukemia (T-ALL) cell line:Jurkat\n",
      "---\n",
      "DNASE:natural killer cell male adult (21 year)\n",
      "CAGE:Natural Killer Cells,\n",
      "---\n",
      "DNASE:CD14-positive monocyte male adult (21 year)\n",
      "CAGE:CD14+ Monocytes,\n",
      "---\n",
      "DNASE:GM12878\n",
      "CAGE:B lymphoblastoid cell line: GM12878 ENCODE, biol_\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for i in range(dataset.data_idxs.shape[0]):\n",
    "    print(df.iloc[dataset.data_idxs[i]]['description'])\n",
    "    print(df.iloc[dataset.additional_data_idxs[i]]['description'])\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr18</td>\n",
       "      <td>928386</td>\n",
       "      <td>1059458</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr4</td>\n",
       "      <td>113630947</td>\n",
       "      <td>113762019</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr11</td>\n",
       "      <td>18427720</td>\n",
       "      <td>18558792</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr16</td>\n",
       "      <td>85805681</td>\n",
       "      <td>85936753</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr3</td>\n",
       "      <td>158386188</td>\n",
       "      <td>158517260</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34016</th>\n",
       "      <td>chr7</td>\n",
       "      <td>50515122</td>\n",
       "      <td>50646194</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34017</th>\n",
       "      <td>chr7</td>\n",
       "      <td>135602769</td>\n",
       "      <td>135733841</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34018</th>\n",
       "      <td>chr4</td>\n",
       "      <td>189004198</td>\n",
       "      <td>189135270</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34019</th>\n",
       "      <td>chr4</td>\n",
       "      <td>10438099</td>\n",
       "      <td>10569171</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34020</th>\n",
       "      <td>chr1</td>\n",
       "      <td>185730272</td>\n",
       "      <td>185861344</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34021 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2      3\n",
       "0      chr18     928386    1059458  train\n",
       "1       chr4  113630947  113762019  train\n",
       "2      chr11   18427720   18558792  train\n",
       "3      chr16   85805681   85936753  train\n",
       "4       chr3  158386188  158517260  train\n",
       "...      ...        ...        ...    ...\n",
       "34016   chr7   50515122   50646194  train\n",
       "34017   chr7  135602769  135733841  train\n",
       "34018   chr4  189004198  189135270  train\n",
       "34019   chr4   10438099   10569171  train\n",
       "34020   chr1  185730272  185861344  train\n",
       "\n",
       "[34021 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seems like it is correct in how they're paired, now let's see an example\n",
    "sequences_bed_file = '/data1/lesliec/sarthak/data/DK_zarr/sequences_enformer.bed'\n",
    "sequences_bed = pd.read_csv(sequences_bed_file, sep=\"\\t\", header=None)\n",
    "sequences_bed = sequences_bed[sequences_bed[3] == 'train']\n",
    "sequences_bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238147, 238147)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset), 34021*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 524288]),\n",
       " torch.Size([2, 524288]),\n",
       " torch.Size([524288, 6]),\n",
       " torch.Size([524288, 2]),\n",
       " (896, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's look at sequence 1\n",
    "out = dataset[1]\n",
    "out[0][0].shape, out[0][1].shape, out[1][0].shape, out[1][1].shape, out[1][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrom = sequences_bed.iloc[1][0]\n",
    "start = sequences_bed.iloc[1][1]\n",
    "end = sequences_bed.iloc[1][2]\n",
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr4 113434339 113958627\n"
     ]
    }
   ],
   "source": [
    "#have to extend it to 524288\n",
    "length = end - start\n",
    "if length < 524288:\n",
    "    start = start - (524288 - length) // 2\n",
    "    end = end + (524288 - length) // 2\n",
    "print(chrom, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524288,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = dataset.genome[chrom][start:end]\n",
    "seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 7, 9, ..., 8, 9, 7], dtype=int8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7, 9,  ..., 8, 9, 7], dtype=torch.int8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7, 9,  ..., 8, 9, 7])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1][0].argmax(1)+7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(out[1][0].argmax(1).to(torch.int8)+7, torch.tensor(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524288,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so the sequence seems right, let's make sure we get the right data for accessibility\n",
    "acc = dataset.data[chrom][dataset.data_idxs[0], start:end]\n",
    "acc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([524288, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(out[1][1][:,0], torch.tensor(acc, dtype=torch.float32)) #so we are loading the right accessibility data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">/</span>\n",
       "├── <span style=\"font-weight: bold\">test</span> (1937, 896, 5313) float32\n",
       "├── <span style=\"font-weight: bold\">train</span> (34021, 896, 5313) float32\n",
       "└── <span style=\"font-weight: bold\">val</span> (2213, 896, 5313) float32\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m/\u001b[0m\n",
       "├── \u001b[1mtest\u001b[0m (1937, 896, 5313) float32\n",
       "├── \u001b[1mtrain\u001b[0m (34021, 896, 5313) float32\n",
       "└── \u001b[1mval\u001b[0m (2213, 896, 5313) float32\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now let's do the expression from CAGE\n",
    "dataset.additional_data.tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = dataset.additional_data['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we have to get the right sub value\n",
    "exp_data = exp[:,dataset.additional_data_idxs[0]]\n",
    "np.allclose(out[1][2][:,0], exp_data) #so this is the CAGE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok so we loaded the right expression data as well\n",
    "\n",
    "#now to verify, let's look at a different cell type\n",
    "out = dataset[1+34021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(out[1][0].argmax(1).to(torch.int8)+7, torch.tensor(seq)) #so sequence is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need to get a new accessibility value\n",
    "acc = dataset.data[chrom][dataset.data_idxs[1], start:end]\n",
    "torch.allclose(out[1][1][:,0], torch.tensor(acc, dtype=torch.float32)) #so we are loading the right accessibility data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and finally expression\n",
    "exp_data = exp[:,dataset.additional_data_idxs[1]]\n",
    "np.allclose(out[1][2][:,0], exp_data) #so this is the CAGE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23675, 16069, 31029, 14471, 30114,  2220,  5239,  4780, 18921,\n",
       "       21299])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's make a loop that chooses 10 random indices and then checks all the celltypes\n",
    "\n",
    "random_idxs = np.random.randint(0, 34021, 10)\n",
    "random_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with idx 23675\n",
      "done with idx 57696\n",
      "done with idx 91717\n",
      "done with idx 125738\n",
      "done with idx 159759\n",
      "done with idx 193780\n",
      "done with idx 227801\n",
      "done with idx 16069\n",
      "done with idx 50090\n",
      "done with idx 84111\n",
      "done with idx 118132\n",
      "done with idx 152153\n",
      "done with idx 186174\n",
      "done with idx 220195\n",
      "done with idx 31029\n",
      "done with idx 65050\n",
      "done with idx 99071\n",
      "done with idx 133092\n",
      "done with idx 167113\n",
      "done with idx 201134\n",
      "done with idx 235155\n",
      "done with idx 14471\n",
      "done with idx 48492\n",
      "done with idx 82513\n",
      "done with idx 116534\n",
      "done with idx 150555\n",
      "done with idx 184576\n",
      "done with idx 218597\n",
      "done with idx 30114\n",
      "done with idx 64135\n",
      "done with idx 98156\n",
      "done with idx 132177\n",
      "done with idx 166198\n",
      "done with idx 200219\n",
      "done with idx 234240\n",
      "done with idx 2220\n",
      "done with idx 36241\n",
      "done with idx 70262\n",
      "done with idx 104283\n",
      "done with idx 138304\n",
      "done with idx 172325\n",
      "done with idx 206346\n",
      "done with idx 5239\n",
      "done with idx 39260\n",
      "done with idx 73281\n",
      "done with idx 107302\n",
      "done with idx 141323\n",
      "done with idx 175344\n",
      "done with idx 209365\n",
      "done with idx 4780\n",
      "done with idx 38801\n",
      "done with idx 72822\n",
      "done with idx 106843\n",
      "done with idx 140864\n",
      "done with idx 174885\n",
      "done with idx 208906\n",
      "done with idx 18921\n",
      "done with idx 52942\n",
      "done with idx 86963\n",
      "done with idx 120984\n",
      "done with idx 155005\n",
      "done with idx 189026\n",
      "done with idx 223047\n",
      "done with idx 21299\n",
      "done with idx 55320\n",
      "done with idx 89341\n",
      "done with idx 123362\n",
      "done with idx 157383\n",
      "done with idx 191404\n",
      "done with idx 225425\n"
     ]
    }
   ],
   "source": [
    "for idx in random_idxs:\n",
    "    \n",
    "    chrom = sequences_bed.iloc[idx][0]\n",
    "    start = sequences_bed.iloc[idx][1]\n",
    "    end = sequences_bed.iloc[idx][2]\n",
    "    length = end - start\n",
    "    if length < 524288:\n",
    "        start = start - (524288 - length) // 2\n",
    "        end = end + (524288 - length) // 2\n",
    "    # print(chrom, start, end)\n",
    "    \n",
    "    seq = dataset.genome[chrom][start:end]\n",
    "    \n",
    "    exp = dataset.additional_data['train'][idx]\n",
    "    \n",
    "    for i in range(7):\n",
    "        out = dataset[idx + i*34021]\n",
    "        #first assert the sequence\n",
    "        assert torch.allclose(out[1][0].argmax(1).to(torch.int8)+7, torch.tensor(seq))\n",
    "        #then assert the accessibility\n",
    "        acc = dataset.data[chrom][dataset.data_idxs[i], start:end]\n",
    "        assert torch.allclose(out[1][1][:,0], torch.tensor(acc, dtype=torch.float32))\n",
    "        #finally assert the expression\n",
    "        exp_data = exp[:,dataset.additional_data_idxs[i]]\n",
    "        assert np.allclose(out[1][2][:,0], exp_data)\n",
    "        print('done with idx', idx + i*34021)\n",
    "    \n",
    "    # print('done with idx', idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacing cell type number with data indices, 7\n"
     ]
    }
   ],
   "source": [
    "#and let's just quickly check this with the validation set too\n",
    "\n",
    "dataset = GeneralDataset(\n",
    "    split='val',\n",
    "    data_path='/data1/lesliec/sarthak/data/DK_zarr/zarr_arrays/dnase_chunkchrom_processed.zarr',\n",
    "    sequences_bed_file='/data1/lesliec/sarthak/data/DK_zarr/sequences_enformer.bed',\n",
    "    length=524288,\n",
    "    shift_sequences=0,\n",
    "    mlm=0,\n",
    "    acc_mlm=0,\n",
    "    additional_data='/data1/lesliec/sarthak/data/enformer/data/labels.zarr',\n",
    "    additional_data_idxs='/data1/lesliec/sarthak/data/DK_zarr/idx_lists/all_matched_immune_CAGE.json',\n",
    "    data_idxs='/data1/lesliec/sarthak/data/DK_zarr/idx_lists/all_matched_immune.json',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34021</th>\n",
       "      <td>chr6</td>\n",
       "      <td>165740202</td>\n",
       "      <td>165871274</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34022</th>\n",
       "      <td>chrX</td>\n",
       "      <td>55044496</td>\n",
       "      <td>55175568</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34023</th>\n",
       "      <td>chrX</td>\n",
       "      <td>84489673</td>\n",
       "      <td>84620745</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34024</th>\n",
       "      <td>chrX</td>\n",
       "      <td>26382093</td>\n",
       "      <td>26513165</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34025</th>\n",
       "      <td>chr7</td>\n",
       "      <td>2304644</td>\n",
       "      <td>2435716</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36229</th>\n",
       "      <td>chrX</td>\n",
       "      <td>16977595</td>\n",
       "      <td>17108667</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36230</th>\n",
       "      <td>chr20</td>\n",
       "      <td>45038994</td>\n",
       "      <td>45170066</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36231</th>\n",
       "      <td>chrX</td>\n",
       "      <td>24547069</td>\n",
       "      <td>24678141</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36232</th>\n",
       "      <td>chr2</td>\n",
       "      <td>235793611</td>\n",
       "      <td>235924683</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36233</th>\n",
       "      <td>chrX</td>\n",
       "      <td>88274410</td>\n",
       "      <td>88405482</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2213 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2      3\n",
       "34021   chr6  165740202  165871274  valid\n",
       "34022   chrX   55044496   55175568  valid\n",
       "34023   chrX   84489673   84620745  valid\n",
       "34024   chrX   26382093   26513165  valid\n",
       "34025   chr7    2304644    2435716  valid\n",
       "...      ...        ...        ...    ...\n",
       "36229   chrX   16977595   17108667  valid\n",
       "36230  chr20   45038994   45170066  valid\n",
       "36231   chrX   24547069   24678141  valid\n",
       "36232   chr2  235793611  235924683  valid\n",
       "36233   chrX   88274410   88405482  valid\n",
       "\n",
       "[2213 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_bed_file = '/data1/lesliec/sarthak/data/DK_zarr/sequences_enformer.bed'\n",
    "sequences_bed = pd.read_csv(sequences_bed_file, sep=\"\\t\", header=None)\n",
    "sequences_bed = sequences_bed[sequences_bed[3] == 'valid']\n",
    "sequences_bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1391, 1316, 1715,  212, 2207, 1777, 2046,  914, 2062, 1146])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_idxs = np.random.randint(0, len(sequences_bed), 10)\n",
    "random_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with idx 1391\n",
      "done with idx 3604\n",
      "done with idx 5817\n",
      "done with idx 8030\n",
      "done with idx 10243\n",
      "done with idx 12456\n",
      "done with idx 14669\n",
      "done with idx 1316\n",
      "done with idx 3529\n",
      "done with idx 5742\n",
      "done with idx 7955\n",
      "done with idx 10168\n",
      "done with idx 12381\n",
      "done with idx 14594\n",
      "done with idx 1715\n",
      "done with idx 3928\n",
      "done with idx 6141\n",
      "done with idx 8354\n",
      "done with idx 10567\n",
      "done with idx 12780\n",
      "done with idx 14993\n",
      "done with idx 212\n",
      "done with idx 2425\n",
      "done with idx 4638\n",
      "done with idx 6851\n",
      "done with idx 9064\n",
      "done with idx 11277\n",
      "done with idx 13490\n",
      "done with idx 2207\n",
      "done with idx 4420\n",
      "done with idx 6633\n",
      "done with idx 8846\n",
      "done with idx 11059\n",
      "done with idx 13272\n",
      "done with idx 15485\n",
      "done with idx 1777\n",
      "done with idx 3990\n",
      "done with idx 6203\n",
      "done with idx 8416\n",
      "done with idx 10629\n",
      "done with idx 12842\n",
      "done with idx 15055\n",
      "done with idx 2046\n",
      "done with idx 4259\n",
      "done with idx 6472\n",
      "done with idx 8685\n",
      "done with idx 10898\n",
      "done with idx 13111\n",
      "done with idx 15324\n",
      "done with idx 914\n",
      "done with idx 3127\n",
      "done with idx 5340\n",
      "done with idx 7553\n",
      "done with idx 9766\n",
      "done with idx 11979\n",
      "done with idx 14192\n",
      "done with idx 2062\n",
      "done with idx 4275\n",
      "done with idx 6488\n",
      "done with idx 8701\n",
      "done with idx 10914\n",
      "done with idx 13127\n",
      "done with idx 15340\n",
      "done with idx 1146\n",
      "done with idx 3359\n",
      "done with idx 5572\n",
      "done with idx 7785\n",
      "done with idx 9998\n",
      "done with idx 12211\n"
     ]
    }
   ],
   "source": [
    "#so have to adjust it not to be 34021, but whatever the validation set length is\n",
    "for idx in random_idxs:\n",
    "    \n",
    "    chrom = sequences_bed.iloc[idx][0]\n",
    "    start = sequences_bed.iloc[idx][1]\n",
    "    end = sequences_bed.iloc[idx][2]\n",
    "    length = end - start\n",
    "    if length < 524288:\n",
    "        start = start - (524288 - length) // 2\n",
    "        end = end + (524288 - length) // 2\n",
    "    # print(chrom, start, end)\n",
    "    \n",
    "    seq = dataset.genome[chrom][start:end]\n",
    "    \n",
    "    exp = dataset.additional_data['val'][idx]\n",
    "    \n",
    "    for i in range(7):\n",
    "        out = dataset[idx + i*len(sequences_bed)]\n",
    "        #first assert the sequence\n",
    "        assert torch.allclose(out[1][0].argmax(1).to(torch.int8)+7, torch.tensor(seq))\n",
    "        #then assert the accessibility\n",
    "        acc = dataset.data[chrom][dataset.data_idxs[i], start:end]\n",
    "        assert torch.allclose(out[1][1][:,0], torch.tensor(acc, dtype=torch.float32))\n",
    "        #finally assert the expression\n",
    "        exp_data = exp[:,dataset.additional_data_idxs[i]]\n",
    "        assert np.allclose(out[1][2][:,0], exp_data)\n",
    "        print('done with idx', idx + i*len(sequences_bed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To be clear tho, this only works because the enformer targets starts with DNase. It means that we can simply input enformer index into it when normally we'd have to change it.\n",
    "#we can use the targets dnase too? But here it's the same lol\n",
    "#regardless, it shows what we're loading in is working, so validation loss being so strange just shows it's very tough to actually do this task..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
