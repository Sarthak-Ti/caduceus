{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ec2390",
   "metadata": {},
   "source": [
    "# modifying mask to have independent samples\n",
    "\n",
    "IDea is can now stack multiple cell types and mask\n",
    "\n",
    "Currently masks across all categories, enable masking across categories indepdnedently by adjusting this mask tie parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02992d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here's the current function\n",
    "\n",
    "import torch\n",
    "\n",
    "def mask_seq(seq, mask_pct=0.15, replace_with_N=True, span=1, stype='category', weights=None, mask_only=False):\n",
    "    \"\"\"This function will mask the sequence data, it does the BERT masking where you do 80% truly masked, 10% random, 10% unchanged\n",
    "    Note that for random replacement, it cannot be the N token, sicne it's very rare anyways, always random nucleotide!\n",
    "    Args:\n",
    "        seq: the sequence to mask, this is a tensor of shape (length, N) if categorical, or (length,1) if continuous, N is the number of classes (5 for ohe nucleotide data)\n",
    "        mask_pct: the percentage of the sequence to mask, default is 0.15 or 15%\n",
    "        replace_with_N: whether to allow random replacement of values with N (for one hot encoded data). Keep True for other categorical data\n",
    "        span: the size of the span to mask, default is 1, so it masks every element independently, but can be larger to mask chunks of size span\n",
    "        stype: the type of sequence, 'category' for categorical like ohe nucleotide data and 'continuous' for continuous like raw accessibility data, default is 'category'\n",
    "        weights: the weights to use for weighting regions like peaks. default is None, must be a tensor of shape (length,) to weight the peaks higher for masking. can be the same as the seq itself\n",
    "        mask_only: whether to do the 10% unchanged and 10% random replacement, default is False. If True, will only do the 100% truly masked and leave the rest unchanged\n",
    "    Returns:\n",
    "        seq: the masked sequence, this is a tensor of shape (length, N+1) if categorical or (length, 2) if continuous, where the last column is the mask track (only tells if masked, some are random or unchanged)\n",
    "        seq_unmask: the unmasked sequence, this is a tensor of shape (length, N+1) if categorical or (length, 2), where the last column is the mask track (tells all elements that have been changed or goign to evaluate)\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(seq.shape) == 1: #if it's just a 1D tensor, we need to add a dimension for the mask track\n",
    "        seq = seq.unsqueeze(1) #so now it's shape length x 1, so we can concatenate other things\n",
    "    \n",
    "    extra_append = 0\n",
    "    if seq.shape[0]%span != 0:\n",
    "        #we append on values\n",
    "        remainder = seq.shape[0] % span\n",
    "        extra_append = span - remainder\n",
    "        seq = torch.cat([seq, torch.zeros((extra_append,seq.shape[1]), dtype=torch.float)]) #so now we can have a mask for every element in the span, so size length again\n",
    "    \n",
    "    num_elements = seq.shape[0]//span #chunks into chunks of size span\n",
    "\n",
    "    # Create a probability vector (one per token) and sample which tokens to mask\n",
    "    probability_matrix = torch.full((num_elements,), mask_pct) #size of length, defines for each element if we mask it or not\n",
    "    \n",
    "    #we can also weight peak regions more\n",
    "    if weights is not None:\n",
    "        weights = weights.squeeze()\n",
    "        assert weights.ndim == 1, f\"weights must be a 1D tensor, got {weights.shape}\"\n",
    "\n",
    "        #Trim weights to match the required size\n",
    "        if weights.shape[0] % span != 0:\n",
    "            #remove values until it is the right size\n",
    "            weights = weights[:num_elements*span]\n",
    "        \n",
    "        #compute mean over spans\n",
    "        weights = weights.view(num_elements, span).mean(1) #average the weights over the span, so now it's size length\n",
    "        \n",
    "        #normalize weights to have range 0.5 to 1.5\n",
    "        weights = torch.log(weights + 1) #log transform to reduce the scale of values\n",
    "        weights = (weights - weights.min()) / (weights.max() - weights.min()) + .5 #normalize to have different range, downweights small values, upweights large ones to almost 3x\n",
    "\n",
    "        #scale probability matrix by weights\n",
    "        probability_matrix = probability_matrix * weights #so now we have a weighted probability matrix, so we can mask more in peak regions\n",
    "        #and scale up probability matrix so that the mean is mask_pct\n",
    "        probability_matrix = probability_matrix / probability_matrix.mean() * mask_pct #so now we have a weighted probability matrix, so we can mask more in peak regions\n",
    "        \n",
    "        #clip to make sure between 0 and 1\n",
    "        probability_matrix = torch.clamp(probability_matrix, min=0, max=1) #clip to make sure between 0 and 1     \n",
    "    \n",
    "    masked_indices = torch.bernoulli(probability_matrix.float()).bool() #finds which indices to mask, so shape is length, and is True or False for each index\n",
    "\n",
    "    # Get positions that were chosen to be masked\n",
    "    all_mask_positions = torch.nonzero(masked_indices).squeeze()*span #squeeze to remove the extra dimension, and multiply by span to get the actual positions in the original sequence\n",
    "    num_masked = all_mask_positions.numel()\n",
    "    \n",
    "    # Determine counts for the three groups: 80% truly masked, 10% random, 10% unchanged\n",
    "    num_mask = int(0.8 * num_masked)\n",
    "    num_random = int(0.1 * num_masked)\n",
    "    # To avoid rounding issues, let the remaining be unchanged\n",
    "    # num_unchanged = num_masked - num_mask - num_random\n",
    "    \n",
    "    # Shuffle the masked positions to randomly assign each to a category\n",
    "    permuted = all_mask_positions[torch.randperm(num_masked)]\n",
    "    mask_positions = permuted[:num_mask]  # 80%: replace with mask token\n",
    "    random_positions = permuted[num_mask:num_mask+num_random]  # 10%: random token\n",
    "    unchanged_positions = permuted[num_mask+num_random:]  # 10%: leave as is\n",
    "\n",
    "    if span > 1:\n",
    "        masked_indices = masked_indices.repeat_interleave(span) #so now we have a mask for every element in the span, so size length again\n",
    "        #and append zeros until the size of seq\n",
    "        extra = seq.shape[0] % span\n",
    "        if extra > 0:\n",
    "            masked_indices = torch.cat([masked_indices, torch.zeros(extra, dtype=torch.bool)]) #so now we have a mask for every element in the span, so size length again\n",
    "        \n",
    "        #now for each of the positions, we need to expand and then make masking apply per index\n",
    "        mask_positions = (mask_positions.unsqueeze(1) + torch.arange(span)).flatten()\n",
    "        random_positions = (random_positions.unsqueeze(1) + torch.arange(span)).flatten()\n",
    "        unchanged_positions = (unchanged_positions.unsqueeze(1) + torch.arange(span)).flatten()\n",
    "        #and now they are grouped and we can just deal with them\n",
    "\n",
    "    # Append the mask track to the sequence, resulting in a tensor of shape [seq_len, 6], or [seq_len, 2] if acc data\n",
    "    # where the last column is the mask track\n",
    "    seq_unmask = torch.cat([seq, masked_indices.unsqueeze(1).float()], dim=1) #so now seq_unmask is shape length x 6, where 6 is the 5 one hot classes and the mask\n",
    "    \n",
    "    seq_masked = seq_unmask.clone()  # Create a copy to modify, note that the mask track should be 0 for ones where it's not masked but is random or unchanged\n",
    "    seq_masked[mask_positions, :-1] = 0  # Set to zero for every class but the last (tells it it's masked)\n",
    "    \n",
    "    if mask_only:\n",
    "        #now forcibly mask the rest\n",
    "        seq_masked[unchanged_positions, :-1] = 0  # Set to zero for every class but the last (tells it it's masked)\n",
    "        seq_masked[random_positions, :-1] = 0  # Set to zero for every class but the last (tells it it's masked)\n",
    "        if span > 1 and extra_append > 0:\n",
    "            seq_masked = seq_masked[:-extra_append]\n",
    "            seq_unmask = seq_unmask[:-extra_append]\n",
    "        # print(seq_masked.shape)\n",
    "        return seq_masked, seq_unmask #return the masked sequence and the unmasked sequence, so we can use it for the rest of the processing\n",
    "    \n",
    "    if stype == 'category':\n",
    "        # print(f'random_positions shape: {random_positions.shape}, seq shape: {seq.shape}')\n",
    "        if replace_with_N:\n",
    "            random_max = seq.shape[1]\n",
    "        else:\n",
    "            random_max = seq.shape[1] - 1\n",
    "        random_tokens = torch.randint(0, random_max, (random_positions.numel()//span,)) #generate random values for each position\n",
    "        random_one_hot = torch.zeros((random_positions.numel()//span, seq.shape[1])) #one hot encode them\n",
    "        random_one_hot.scatter_(1, random_tokens.unsqueeze(1), 1.0)\n",
    "        #now repeat with the span\n",
    "        random_one_hot = random_one_hot.repeat_interleave(span, dim=0) #so now we have a one hot for each position in the span\n",
    "        seq_masked[random_positions, :seq.shape[1]] = random_one_hot #assign them to the set positions\n",
    "        \n",
    "    elif stype == 'continuous':\n",
    "        #for accessibility, we will select random values from somewhere else in the sequence and then slightly shift and noise them\n",
    "        #get a random value between 0 and len(seq)-span\n",
    "        rand_start = torch.randint(0, seq.shape[0]-span, (random_positions.numel()//span,)) #definitely divisble by span since it was extended by size span\n",
    "        rand_idx = (rand_start.unsqueeze(1) + torch.arange(span)) #so now we have a random index for each of the random positions, and we can just select from there\n",
    "        rand_vals = seq.squeeze(1)[rand_idx] #get the values from the sequence at those random positions, so now we have a random value for each of the random positions\n",
    "        #and we can add some noise to it, so we can just add a small random value to it. Noise will be values between -0.1 and 0.1\n",
    "        rand_vals_mean = rand_vals.mean(1, keepdim=True) #get the mean of the random values for each position, keeps the dim so we can broadcast it\n",
    "        noise = torch.randn(rand_vals.shape) * rand_vals_mean * 0.1 #gaussian noise with std of 0.1 times the mean of the random values, so we can add some larger nosie to larger values\n",
    "        rand_vals = torch.clamp((rand_vals + noise).flatten(), min = 0) #make sure values are at least 0, else obvious there's noise in the region\n",
    "        #and now set the values\n",
    "        seq_masked[random_positions, 0] = rand_vals #set the values to the random values with noise, so now we have a random value for each of the random positions\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"stype must be either 'category' or 'continuous'\")\n",
    "    \n",
    "    #and remove the masked value, it doesn't know it's masked\n",
    "    seq_masked[random_positions, -1] = 0\n",
    "    \n",
    "    #and we remove the mask token from the unchanged value\n",
    "    seq_masked[unchanged_positions, -1] = 0\n",
    "    # seq = seq_masked #now we have the masked sequence, so we can use this for the rest of the processing\n",
    "\n",
    "    if span > 1 and extra_append > 0:\n",
    "        seq_masked = seq_masked[:-extra_append]\n",
    "        seq_unmask = seq_unmask[:-extra_append]\n",
    "    \n",
    "    return seq_masked, seq_unmask #return the masked sequence and the unmasked sequence, so we can use it for the rest of the processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c97b905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones((20,5))\n",
    "b,c = mask_seq(a, mask_pct=0.4, span=2, mask_only=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab1cc334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c68de70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c2e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I think that it works quite logically, but now let's make this the base case where mask_tie = 1. True 100% for DNA OHE data and if N is 1, but when N is greater than 1, like if we have multiple cell types, then doesn't have to be the same\n",
    "\n",
    "#now the easiest drop in replacement is that we return a matrix telling you what was masked. But here we just have the 1 vector. So the idea is for that, we would need to actually modify all the downstream code in the loss to work with this matrix and compute per matrix element instead...\n",
    "\n",
    "#so let's do that. SHouldn't actually affect too much since this matrix would just be \n",
    "\n",
    "#ok here's the plan, to keep backward compatibility, basically, if mask_tie = 1, then the code returns the same. Otherwise, it will return a matrix. And then in the loss we would need to separate it... let's look at the loss and how it works\n",
    "#ok won't be too bad, just update poisson loss mask to take into account that it might be a matrix that you take values of instead\n",
    "\n",
    "#here's old function\n",
    "# def poisson_loss_mask(x, y):\n",
    "#     \"\"\"\n",
    "#     Poisson loss for accessibility regression.\n",
    "    \n",
    "#     x: tuple (dummy, acc)\n",
    "#          - acc: (batch_size, seq_len, 1)\n",
    "#     y: tuple (dummy, acc_unmask)\n",
    "#          - acc_unmask: (batch_size, seq_len, 2)   (last channel is the mask)\n",
    "#     \"\"\"\n",
    "#     # We only use the accessibility part.\n",
    "#     acc = x[1]      # shape: (batch_size, seq_len, 1)\n",
    "#     acc_unmask = y[1]  # shape: (batch_size, seq_len, 2)\n",
    "    \n",
    "#     # Squeeze the last channel\n",
    "#     acc = acc.squeeze(-1)\n",
    "#     # Create mask from second channel (index 1)\n",
    "#     mask = acc_unmask[:, :, 1] == 1\n",
    "#     acc = acc[mask]\n",
    "#     # Use the first channel (index 0) as the target, remove mask dim\n",
    "#     acc_target = acc_unmask[mask][:, 0]\n",
    "    \n",
    "#     # Make sure predictions are positive.\n",
    "#     acc = F.softplus(acc)\n",
    "    \n",
    "#     loss = F.poisson_nll_loss(acc, acc_target, log_input=False, full=False)\n",
    "#     return loss\n",
    "\n",
    "#just modify to something like this\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def poisson_loss_mask(x, y):\n",
    "    \"\"\"\n",
    "    Poisson loss for accessibility regression.\n",
    "    \n",
    "    x: tuple (dummy, acc)\n",
    "         - acc: (batch_size, seq_len, num_categories)\n",
    "    y: tuple (dummy, acc_unmask)\n",
    "         - acc_unmask: (batch_size, seq_len, 2*num_categoreies)   (last half channel is the mask)\n",
    "    \"\"\"\n",
    "\n",
    "    # We only use the accessibility part.\n",
    "    acc = x[1]      # shape: (batch_size, seq_len, num_categories)\n",
    "    acc_unmask = y[1]  # shape: (batch_size, seq_len, 2*num_categories)\n",
    "    \n",
    "    num_categories = acc.shape[2]\n",
    "    \n",
    "    # Squeeze the last channel\n",
    "    # Create mask from second half channels\n",
    "    mask = acc_unmask[:, :, num_categories:] == 1  # shape: (batch_size, seq_len, num_categories)\n",
    "    \n",
    "    # Use the first half channels as the target\n",
    "    acc_target = acc_unmask[:, :, :num_categories]  # shape: (batch_size, seq_len, num_categories)\n",
    "    \n",
    "    # Make sure predictions are positive.\n",
    "    acc = F.softplus(acc)\n",
    "    \n",
    "    # Apply mask\n",
    "    acc = acc[mask]\n",
    "    acc_target = acc_target[mask]\n",
    "    \n",
    "    loss = F.poisson_nll_loss(acc, acc_target, log_input=False, full=False)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46ef2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 6])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.unsqueeze(0).shape #this is the correct shape now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa594fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 6])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.unsqueeze(0).shape #this is wrong, because it should be 1,20,10 now. But I will test this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06fc5648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 5])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so let's go section by section\n",
    "import torch\n",
    "seq = torch.ones((20,5))\n",
    "mask_pct=0.3\n",
    "replace_with_N=True\n",
    "span=2\n",
    "mask_only=True\n",
    "stype='category'\n",
    "weights=None\n",
    "mask_tie=0.9\n",
    "seq.shape #5 categories, 20 length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "efd953e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now let's go step by step\n",
    "len(seq.shape) #not 1, so we don't unsqueeze\n",
    "seq.shape[0]%span #it is 0 so nothing again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1742e81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_elements = seq.shape[0]//span #chunks into chunks of size span\n",
    "num_elements #10 because we have span 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8aeac6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000,\n",
       "        0.3000])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_matrix = torch.full((num_elements,), mask_pct)\n",
    "probability_matrix #yup exactly as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d5c15fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([False, False,  True, False, False, False, False,  True,  True,  True]),\n",
       " torch.Size([10]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ignore the weights thing\n",
    "masked_indices = torch.bernoulli(probability_matrix.float()).bool()\n",
    "masked_indices, masked_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a8981603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_indices.unsqueeze(1).repeat(1, seq.shape[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c6f87ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we need to replicate this, here mask_tie is less than 1\n",
    "if mask_tie < 1:\n",
    "    #first replicate masked_indices to be of shape length x num_categories\n",
    "    masked_indices = masked_indices.unsqueeze(1).repeat(1, seq.shape[1])\n",
    "    #now per row we need to randomly change some of the true and falses at the 1-mask_tie proportion\n",
    "    \n",
    "    #let's just loop over it. Not the best, I know, but it is the easiest\n",
    "    base_mask = masked_indices[:,0]\n",
    "    q = 1-mask_tie\n",
    "    for i in range(masked_indices.shape[1]):\n",
    "        #now we find 10% of the true values and turn them to false, and then get the same amount and turn them from false to true\n",
    "        num_true = base_mask.sum().item()\n",
    "        num_change = int(num_true * q)\n",
    "        true_indices = torch.nonzero(base_mask).squeeze()\n",
    "        false_indices = torch.nonzero(~base_mask).squeeze()\n",
    "        #randomly select num_change indices from true_indices and false_indices\n",
    "        true_change_indices = true_indices[torch.randperm(true_indices.numel())[:num_change]]\n",
    "        false_change_indices = false_indices[torch.randperm(false_indices.numel())[:num_change]]\n",
    "        #now set them\n",
    "        masked_indices[true_change_indices, i] = False\n",
    "        masked_indices[false_change_indices, i] = True\n",
    "masked_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d155afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 2])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now let's se eif the upcoming thigns will work\n",
    "(torch.nonzero(masked_indices).squeeze()*span).shape #ok this absolutely doesn't work, let's check with base mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5113e4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "tensor([False, False,  True, False, False, False, False,  True,  True,  True])\n",
      "tensor([ 4, 14, 16, 18])\n"
     ]
    }
   ],
   "source": [
    "print(base_mask.shape)\n",
    "print(base_mask)\n",
    "print(torch.nonzero(base_mask).squeeze()*span) #ok clearly finds the things just fine, but we need to preserve the shape of our thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676eb2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_indices.shape\n",
    "#ok so there's a few issues here, one this only works with vectors\n",
    "#2 this will have different shapes depending on how many flips, we should maintain similarish number, but you never know...\n",
    "#ok it's best I think to do this step later, let's leave masked_indices alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3524dde7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False,  True,  True,  True, False,  True])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "seq = torch.ones((20,5))\n",
    "mask_pct=0.3\n",
    "replace_with_N=True\n",
    "span=2\n",
    "mask_only=True\n",
    "stype='category'\n",
    "weights=None\n",
    "mask_tie=0.5\n",
    "\n",
    "#main setup again but without my changes\n",
    "num_elements = seq.shape[0]//span\n",
    "probability_matrix = torch.full((num_elements,), mask_pct)\n",
    "masked_indices = torch.bernoulli(probability_matrix.float()).bool()\n",
    "masked_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0cc8764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 12, 14, 18])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mask_positions = torch.nonzero(masked_indices).squeeze()*span\n",
    "all_mask_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df941ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         True,  True,  True,  True,  True,  True, False, False,  True,  True])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_indices = masked_indices.repeat_interleave(span)\n",
    "masked_indices\n",
    "#no so we need to do changes before we repeat interleave this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7bb8cd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ True,  True,  True, False, False, False, False, False, False, False]) torch.Size([10])\n",
      "tensor([ True,  True, False, False,  True,  True, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True,  True]) torch.Size([20])\n",
      "tensor([ 0,  4, 18]) torch.Size([3])\n",
      "tensor([ 0,  1,  4,  5, 18, 19]) torch.Size([6])\n",
      "tensor([False, False,  True,  True,  True,  True, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False]) torch.Size([20])\n",
      "tensor([2, 4]) torch.Size([2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (6) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [6].  Tensor sizes: [4]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m         all_mask_positions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnonzero(masked_indices[:,i])\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m*\u001b[39mspan\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28mprint\u001b[39m(all_mask_positions, all_mask_positions\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 37\u001b[0m         \u001b[43mmask_positions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m (all_mask_positions\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(span))\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28mprint\u001b[39m(mask_positions[i], mask_positions[i]\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;66;03m#was a dict because the size changes depending on how many elements are masked. Although it should be a set value..., yeah don't need dict\u001b[39;00m\n\u001b[1;32m     41\u001b[0m masked_indices, masked_indices\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (6) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [6].  Tensor sizes: [4]"
     ]
    }
   ],
   "source": [
    "#what if we instead do all masked indices we do more steps in my loop\n",
    "\n",
    "masked_indices = torch.bernoulli(probability_matrix.float()).bool()\n",
    "print(masked_indices, masked_indices.shape)\n",
    "extra = seq.shape[0] % span\n",
    "if mask_tie < 1:\n",
    "    assert mask_only, \"Not implemented for mask_only = False yet\"\n",
    "    #first replicate masked_indices to be of shape length x num_categories\n",
    "    masked_indices = masked_indices.unsqueeze(1).repeat(1, seq.shape[1])\n",
    "    #now per row we need to randomly change some of the true and falses at the 1-mask_tie proportion\n",
    "    \n",
    "    #let's just loop over it. Not the best, I know, but it is the easiest\n",
    "    base_mask = masked_indices[:,0]\n",
    "    num_masked = base_mask.sum().item()\n",
    "    mask_positions = torch.zeros((masked_indices.shape[1], num_masked*span), dtype=torch.long) #preallocate max size\n",
    "    q = 1-mask_tie\n",
    "    for i in range(masked_indices.shape[1]):\n",
    "        #now we find 10% of the true values and turn them to false, and then get the same amount and turn them from false to true\n",
    "        num_change = int(num_masked * q)\n",
    "        true_indices = torch.nonzero(base_mask).squeeze()\n",
    "        false_indices = torch.nonzero(~base_mask).squeeze()\n",
    "        #randomly select num_change indices from true_indices and false_indices\n",
    "        true_change_indices = true_indices[torch.randperm(true_indices.numel())[:num_change]]\n",
    "        false_change_indices = false_indices[torch.randperm(false_indices.numel())[:num_change]]\n",
    "        #now set them\n",
    "        masked_indices[true_change_indices, i] = False\n",
    "        masked_indices[false_change_indices, i] = True\n",
    "        #also just do the steps to get all mask positions. This metric keeps the amount of true and false at least? then we also need to decide which ones are true mask which ones are random?\n",
    "        #for now we can make it work with mask_only = True, this way we ignore the other things\n",
    "        expanded_masked_indices = masked_indices[:,i].repeat_interleave(span)\n",
    "        print(expanded_masked_indices, expanded_masked_indices.shape)\n",
    "        if extra > 0:\n",
    "            expanded_masked_indices = torch.cat([expanded_masked_indices, torch.zeros(extra, dtype=torch.bool)]) #so now we have a mask for every element in the span, so size length again\n",
    "        \n",
    "        all_mask_positions = torch.nonzero(masked_indices[:,i]).squeeze()*span\n",
    "        print(all_mask_positions, all_mask_positions.shape)\n",
    "        mask_positions[i] = (all_mask_positions.unsqueeze(1) + torch.arange(span)).flatten()\n",
    "        print(mask_positions[i], mask_positions[i].shape) #was a dict because the size changes depending on how many elements are masked. Although it should be a set value..., yeah don't need dict\n",
    "        \n",
    "        \n",
    "masked_indices, masked_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6cbb45bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a99a30da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mask_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b3f73d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 4, 5])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all_mask_positions.unsqueeze(1) + torch.arange(span)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68dcf06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  4,  5, 18, 19],\n",
       "        [ 0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_positions #how is it 4 instead of the proper amount??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "237a835d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False,  True, False, False, False, False, False, False,  True])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3e7f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2, 3, 3, 3])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_indices.sum(0) #ok so the number is indeed different... this should be ok tbh, but why is it able to be different, should be a set amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "14052529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False,  True, False, False, False, False, False, False,  True])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c4cc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 2, 9]), tensor([1, 3, 4, 5, 6, 7, 8]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_indices, false_indices #seems good to me, is 3 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcac604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_indices[:,1] #now is only 2...\n",
    "#wait we need to make sure base_mask is a clone lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7a5ed383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ True, False, False,  True,  True, False, False, False, False, False]) torch.Size([10])\n",
      "tensor([ True,  True, False, False,  True,  True,  True,  True, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False]) torch.Size([20])\n",
      "tensor([0, 4, 6]) torch.Size([3])\n",
      "tensor([0, 1, 4, 5, 6, 7]) torch.Size([6])\n",
      "tensor([False, False, False, False, False, False,  True,  True,  True,  True,\n",
      "        False, False, False, False,  True,  True, False, False, False, False]) torch.Size([20])\n",
      "tensor([ 6,  8, 14]) torch.Size([3])\n",
      "tensor([ 6,  7,  8,  9, 14, 15]) torch.Size([6])\n",
      "tensor([ True,  True, False, False,  True,  True, False, False,  True,  True,\n",
      "        False, False, False, False, False, False, False, False, False, False]) torch.Size([20])\n",
      "tensor([0, 4, 8]) torch.Size([3])\n",
      "tensor([0, 1, 4, 5, 8, 9]) torch.Size([6])\n",
      "tensor([ True,  True, False, False, False, False, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False, False, False, False]) torch.Size([20])\n",
      "tensor([ 0,  8, 12]) torch.Size([3])\n",
      "tensor([ 0,  1,  8,  9, 12, 13]) torch.Size([6])\n",
      "tensor([ True,  True, False, False, False, False,  True,  True, False, False,\n",
      "         True,  True, False, False, False, False, False, False, False, False]) torch.Size([20])\n",
      "tensor([ 0,  6, 10]) torch.Size([3])\n",
      "tensor([ 0,  1,  6,  7, 10, 11]) torch.Size([6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ True, False,  True,  True,  True],\n",
       "         [False, False, False, False, False],\n",
       "         [ True, False,  True, False, False],\n",
       "         [ True,  True, False, False,  True],\n",
       "         [False,  True,  True,  True, False],\n",
       "         [False, False, False, False,  True],\n",
       "         [False, False, False,  True, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False]]),\n",
       " torch.Size([10, 5]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_indices = torch.bernoulli(probability_matrix.float()).bool()\n",
    "print(masked_indices, masked_indices.shape)\n",
    "extra = seq.shape[0] % span\n",
    "if mask_tie < 1:\n",
    "    assert mask_only, \"Not implemented for mask_only = False yet\"\n",
    "    #first replicate masked_indices to be of shape length x num_categories\n",
    "    masked_indices = masked_indices.unsqueeze(1).repeat(1, seq.shape[1])\n",
    "    #now per row we need to randomly change some of the true and falses at the 1-mask_tie proportion\n",
    "    \n",
    "    #let's just loop over it. Not the best, I know, but it is the easiest\n",
    "    base_mask = masked_indices[:,0].clone()\n",
    "    num_masked = base_mask.sum().item()\n",
    "    mask_positions = torch.zeros((masked_indices.shape[1], num_masked*span), dtype=torch.long) #preallocate max size\n",
    "    q = 1-mask_tie\n",
    "    for i in range(masked_indices.shape[1]):\n",
    "        #now we find 10% of the true values and turn them to false, and then get the same amount and turn them from false to true\n",
    "        num_change = int(num_masked * q)\n",
    "        true_indices = torch.nonzero(base_mask).squeeze()\n",
    "        false_indices = torch.nonzero(~base_mask).squeeze()\n",
    "        #randomly select num_change indices from true_indices and false_indices\n",
    "        true_change_indices = true_indices[torch.randperm(true_indices.numel())[:num_change]]\n",
    "        false_change_indices = false_indices[torch.randperm(false_indices.numel())[:num_change]]\n",
    "        #now set them\n",
    "        masked_indices[true_change_indices, i] = False\n",
    "        masked_indices[false_change_indices, i] = True\n",
    "        #also just do the steps to get all mask positions. This metric keeps the amount of true and false at least? then we also need to decide which ones are true mask which ones are random?\n",
    "        #for now we can make it work with mask_only = True, this way we ignore the other things\n",
    "        expanded_masked_indices = masked_indices[:,i].repeat_interleave(span)\n",
    "        print(expanded_masked_indices, expanded_masked_indices.shape)\n",
    "        if extra > 0:\n",
    "            expanded_masked_indices = torch.cat([expanded_masked_indices, torch.zeros(extra, dtype=torch.bool)]) #so now we have a mask for every element in the span, so size length again\n",
    "        \n",
    "        all_mask_positions = torch.nonzero(masked_indices[:,i]).squeeze()*span\n",
    "        print(all_mask_positions, all_mask_positions.shape)\n",
    "        mask_positions[i] = (all_mask_positions.unsqueeze(1) + torch.arange(span)).flatten()\n",
    "        print(mask_positions[i], mask_positions[i].shape) #was a dict because the size changes depending on how many elements are masked. Although it should be a set value..., yeah don't need dict\n",
    "        \n",
    "        \n",
    "masked_indices, masked_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "47fb51a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 5]) torch.Size([10, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  4,  5,  6,  7],\n",
       "         [ 6,  7,  8,  9, 14, 15],\n",
       "         [ 0,  1,  4,  5,  8,  9],\n",
       "         [ 0,  1,  8,  9, 12, 13],\n",
       "         [ 0,  1,  6,  7, 10, 11]]),\n",
       " torch.Size([5, 6]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we have masked_indices which is correct, let's append it and do the rest of the logic\n",
    "print(seq.shape, masked_indices.shape) #uhhh was this not expanded?\n",
    "#wait no it's mask_positions\n",
    "mask_positions, mask_positions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "97c90898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False, False, False, False,  True, False, False,  True]) torch.Size([10])\n",
      "tensor([ True,  True, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True,  True]) torch.Size([20])\n",
      "tensor([ 0, 18]) torch.Size([2])\n",
      "tensor([ 0,  1, 18, 19]) torch.Size([4])\n",
      "tensor([False, False, False, False,  True,  True, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True,  True]) torch.Size([20])\n",
      "tensor([ 4, 18]) torch.Size([2])\n",
      "tensor([ 4,  5, 18, 19]) torch.Size([4])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True,  True, False, False,  True,  True]) torch.Size([20])\n",
      "tensor([14, 18]) torch.Size([2])\n",
      "tensor([14, 15, 18, 19]) torch.Size([4])\n",
      "tensor([False, False,  True,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True,  True]) torch.Size([20])\n",
      "tensor([ 2, 18]) torch.Size([2])\n",
      "tensor([ 2,  3, 18, 19]) torch.Size([4])\n",
      "tensor([False, False, False, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True, False, False, False, False, False, False]) torch.Size([20])\n",
      "tensor([ 4, 12]) torch.Size([2])\n",
      "tensor([ 4,  5, 12, 13]) torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ True, False, False, False, False],\n",
       "         [False, False, False,  True, False],\n",
       "         [False,  True, False, False,  True],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False,  True],\n",
       "         [False, False,  True, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [ True,  True,  True,  True, False]]),\n",
       " torch.Size([10, 5]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#oh we need to save out the expanded masked indices\n",
    "masked_indices = torch.bernoulli(probability_matrix.float()).bool()\n",
    "print(masked_indices, masked_indices.shape)\n",
    "extra = seq.shape[0] % span\n",
    "if mask_tie < 1:\n",
    "    assert mask_only, \"Not implemented for mask_only = False yet\"\n",
    "    #first replicate masked_indices to be of shape length x num_categories\n",
    "    masked_indices = masked_indices.unsqueeze(1).repeat(1, seq.shape[1])\n",
    "    all_expanded_masked_indices = torch.zeros((seq.shape[0], seq.shape[1]), dtype=torch.bool)\n",
    "    #now per row we need to randomly change some of the true and falses at the 1-mask_tie proportion\n",
    "    \n",
    "    #let's just loop over it. Not the best, I know, but it is the easiest\n",
    "    base_mask = masked_indices[:,0].clone()\n",
    "    num_masked = base_mask.sum().item()\n",
    "    mask_positions = torch.zeros((masked_indices.shape[1], num_masked*span), dtype=torch.long) #preallocate max size\n",
    "    q = 1-mask_tie\n",
    "    for i in range(masked_indices.shape[1]):\n",
    "        #now we find 10% of the true values and turn them to false, and then get the same amount and turn them from false to true\n",
    "        num_change = int(num_masked * q)\n",
    "        true_indices = torch.nonzero(base_mask).squeeze()\n",
    "        false_indices = torch.nonzero(~base_mask).squeeze()\n",
    "        #randomly select num_change indices from true_indices and false_indices\n",
    "        true_change_indices = true_indices[torch.randperm(true_indices.numel())[:num_change]]\n",
    "        false_change_indices = false_indices[torch.randperm(false_indices.numel())[:num_change]]\n",
    "        #now set them\n",
    "        masked_indices[true_change_indices, i] = False\n",
    "        masked_indices[false_change_indices, i] = True\n",
    "        #also just do the steps to get all mask positions. This metric keeps the amount of true and false at least? then we also need to decide which ones are true mask which ones are random?\n",
    "        #for now we can make it work with mask_only = True, this way we ignore the other things\n",
    "        expanded_masked_indices = masked_indices[:,i].repeat_interleave(span)\n",
    "        print(expanded_masked_indices, expanded_masked_indices.shape)\n",
    "        if extra > 0:\n",
    "            expanded_masked_indices = torch.cat([expanded_masked_indices, torch.zeros(extra, dtype=torch.bool)]) #so now we have a mask for every element in the span, so size length again\n",
    "        all_expanded_masked_indices[:,i] = expanded_masked_indices\n",
    "        \n",
    "        all_mask_positions = torch.nonzero(masked_indices[:,i]).squeeze()*span\n",
    "        print(all_mask_positions, all_mask_positions.shape)\n",
    "        mask_positions[i] = (all_mask_positions.unsqueeze(1) + torch.arange(span)).flatten()\n",
    "        print(mask_positions[i], mask_positions[i].shape) #was a dict because the size changes depending on how many elements are masked. Although it should be a set value..., yeah don't need dict\n",
    "        \n",
    "        \n",
    "masked_indices, masked_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0139e3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False, False,  True, False],\n",
       "         [False, False, False,  True, False],\n",
       "         [False,  True, False, False,  True],\n",
       "         [False,  True, False, False,  True],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False,  True],\n",
       "         [False, False, False, False,  True],\n",
       "         [False, False,  True, False, False],\n",
       "         [False, False,  True, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [ True,  True,  True,  True, False],\n",
       "         [ True,  True,  True,  True, False]]),\n",
       " torch.Size([20, 5]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_expanded_masked_indices, all_expanded_masked_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c5213084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 1., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 1., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 1., 0., 0., 1.],\n",
       "         [1., 1., 1., 1., 1., 0., 1., 0., 0., 1.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 1.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 1.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 1., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 1., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.]]),\n",
       " torch.Size([20, 10]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now this we can append onto the seq\n",
    "seq_unmask = torch.cat([seq, all_expanded_masked_indices.float()], dim=1)\n",
    "seq_unmask, seq_unmask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0e69a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 1., 0., 0., 0., 1., 0.],\n",
       "         [1., 1., 1., 0., 1., 0., 0., 0., 1., 0.],\n",
       "         [1., 0., 1., 1., 0., 0., 1., 0., 0., 1.],\n",
       "         [1., 0., 1., 1., 0., 0., 1., 0., 0., 1.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 0., 0., 1.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 0., 0., 1.],\n",
       "         [1., 1., 0., 1., 1., 0., 0., 1., 0., 0.],\n",
       "         [1., 1., 0., 1., 1., 0., 0., 1., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 1., 1., 1., 1., 0.],\n",
       "         [0., 0., 0., 0., 1., 1., 1., 1., 1., 0.]]),\n",
       " torch.Size([20, 10]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#then for the actual sequence, we can go ahead and just multiply it by the inverse of the expanded masked indices and then append on the expanded mask indices\n",
    "seq_masked = seq_unmask.clone()\n",
    "num_channels = seq.shape[1]\n",
    "seq_masked[:, :num_channels] = seq_masked[:, :num_channels] * (~all_expanded_masked_indices).float()\n",
    "seq_masked, seq_masked.shape\n",
    "\n",
    "#matches exactly as you'd expect!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9e3d29d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]]) torch.Size([20, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00, 8658.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 1., 1., 0., 1., 1., 0., 0.],\n",
      "        [1., 0., 0., 1., 1., 0., 1., 1., 0., 0.],\n",
      "        [0., 1., 1., 0., 0., 1., 0., 0., 1., 1.],\n",
      "        [0., 1., 1., 0., 0., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 1., 1., 0., 1., 1.],\n",
      "        [0., 0., 1., 0., 0., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 1., 1., 0., 0.],\n",
      "        [1., 0., 0., 1., 1., 0., 1., 1., 0., 0.],\n",
      "        [1., 0., 0., 1., 1., 0., 1., 1., 0., 0.],\n",
      "        [1., 0., 0., 1., 1., 0., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0., 1., 0., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 1., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 1., 1., 1.]]) torch.Size([20, 10])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 0., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 1., 1., 1.]]) torch.Size([20, 10])\n"
     ]
    }
   ],
   "source": [
    "#now let's implement the actual main logic in our function\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def mask_seq(seq, mask_pct=0.15, replace_with_N=True, span=1, stype='category', weights=None, mask_only=False, mask_tie=1):\n",
    "    \"\"\"This function will mask the sequence data, it does the BERT masking where you do 80% truly masked, 10% random, 10% unchanged\n",
    "    Note that for random replacement, it cannot be the N token, sicne it's very rare anyways, always random nucleotide!\n",
    "    Args:\n",
    "        seq: the sequence to mask, this is a tensor of shape (length, N) if categorical, or (length,1) if continuous, N is the number of classes (5 for ohe nucleotide data)\n",
    "        mask_pct: the percentage of the sequence to mask, default is 0.15 or 15%\n",
    "        replace_with_N: whether to allow random replacement of values with N (for one hot encoded data). Keep True for other categorical data\n",
    "        span: the size of the span to mask, default is 1, so it masks every element independently, but can be larger to mask chunks of size span\n",
    "        stype: the type of sequence, 'category' for categorical like ohe nucleotide data and 'continuous' for continuous like raw accessibility data, default is 'category'\n",
    "        weights: the weights to use for weighting regions like peaks. default is None, must be a tensor of shape (length,) to weight the peaks higher for masking. can be the same as the seq itself\n",
    "        mask_only: whether to do the 10% unchanged and 10% random replacement, default is False. If True, will only do the 100% truly masked and leave the rest unchanged\n",
    "        mask_tie: how much masking is tied across categories. 1 means fully tied, so all tracks are masked the same, 0 means fully indepdendent masking across categories. If true, returns slightlly different values\n",
    "    Returns:\n",
    "        seq: the masked sequence, this is a tensor of shape (length, N+1) or N*2 if mask_tie is less than 1 if categorical or (length, 2) if continuous, where the last column is the mask track (only tells if masked, some are random or unchanged)\n",
    "        seq_unmask: the unmasked sequence, this is a tensor of shape (length, N+1) or N*2 if categorical or (length, 2), where the last column is the mask track (tells all elements that have been changed or goign to evaluate)\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(seq.shape) == 1: #if it's just a 1D tensor, we need to add a dimension for the mask track\n",
    "        seq = seq.unsqueeze(1) #so now it's shape length x 1, so we can concatenate other things\n",
    "    \n",
    "    extra_append = 0\n",
    "    if seq.shape[0]%span != 0:\n",
    "        #we append on values\n",
    "        remainder = seq.shape[0] % span\n",
    "        extra_append = span - remainder\n",
    "        seq = torch.cat([seq, torch.zeros((extra_append,seq.shape[1]), dtype=torch.float)]) #so now we can have a mask for every element in the span, so size length again\n",
    "    \n",
    "    num_elements = seq.shape[0]//span #chunks into chunks of size span\n",
    "\n",
    "    # Create a probability vector (one per token) and sample which tokens to mask\n",
    "    probability_matrix = torch.full((num_elements,), mask_pct) #size of length, defines for each element if we mask it or not\n",
    "    \n",
    "    #we can also weight peak regions more\n",
    "    if weights is not None:\n",
    "        assert mask_tie == 1, \"Weighting with weights is only supported for mask_tie=1 currently\"\n",
    "        weights = weights.squeeze()\n",
    "        assert weights.ndim == 1, f\"weights must be a 1D tensor, got {weights.shape}\"\n",
    "\n",
    "        #Trim weights to match the required size\n",
    "        if weights.shape[0] % span != 0:\n",
    "            #remove values until it is the right size\n",
    "            weights = weights[:num_elements*span]\n",
    "        \n",
    "        #compute mean over spans\n",
    "        weights = weights.view(num_elements, span).mean(1) #average the weights over the span, so now it's size length\n",
    "        \n",
    "        #normalize weights to have range 0.5 to 1.5\n",
    "        weights = torch.log(weights + 1) #log transform to reduce the scale of values\n",
    "        weights = (weights - weights.min()) / (weights.max() - weights.min()) + .5 #normalize to have different range, downweights small values, upweights large ones to almost 3x\n",
    "\n",
    "        #scale probability matrix by weights\n",
    "        probability_matrix = probability_matrix * weights #so now we have a weighted probability matrix, so we can mask more in peak regions\n",
    "        #and scale up probability matrix so that the mean is mask_pct\n",
    "        probability_matrix = probability_matrix / probability_matrix.mean() * mask_pct #so now we have a weighted probability matrix, so we can mask more in peak regions\n",
    "        \n",
    "        #clip to make sure between 0 and 1\n",
    "        probability_matrix = torch.clamp(probability_matrix, min=0, max=1) #clip to make sure between 0 and 1     \n",
    "    \n",
    "    masked_indices = torch.bernoulli(probability_matrix.float()).bool() #finds which indices to mask, so shape is length, and is True or False for each index\n",
    "\n",
    "    if mask_tie < 1: #have to implement own logic and loop\n",
    "        assert mask_only, \"Not implemented for mask_only = False yet\"\n",
    "        extra = seq.shape[0] % span\n",
    "        #first replicate masked_indices to be of shape length x num_categories\n",
    "        masked_indices = masked_indices.unsqueeze(1).repeat(1, seq.shape[1])\n",
    "        all_expanded_masked_indices = torch.zeros((seq.shape[0], seq.shape[1]), dtype=torch.bool)\n",
    "        #now per row we need to randomly change some of the true and falses at the 1-mask_tie proportion\n",
    "        \n",
    "        #let's just loop over it. Not the best, I know, but it is the easiest\n",
    "        base_mask = masked_indices[:,0].clone()\n",
    "        num_masked = base_mask.sum().item()\n",
    "        # mask_positions = torch.zeros((masked_indices.shape[1], num_masked*span), dtype=torch.long) #preallocate max size\n",
    "        q = 1-mask_tie\n",
    "        for i in tqdm(range(masked_indices.shape[1])):\n",
    "            #now we find 10% of the true values and turn them to false, and then get the same amount and turn them from false to true\n",
    "            num_change = int(num_masked * q)\n",
    "            true_indices = torch.nonzero(base_mask).squeeze()\n",
    "            false_indices = torch.nonzero(~base_mask).squeeze()\n",
    "            #randomly select num_change indices from true_indices and false_indices\n",
    "            true_change_indices = true_indices[torch.randperm(true_indices.numel())[:num_change]]\n",
    "            false_change_indices = false_indices[torch.randperm(false_indices.numel())[:num_change]]\n",
    "            #now set them\n",
    "            masked_indices[true_change_indices, i] = False\n",
    "            masked_indices[false_change_indices, i] = True\n",
    "            #also just do the steps to get all mask positions. This metric keeps the amount of true and false at least? then we also need to decide which ones are true mask which ones are random?\n",
    "            #for now we can make it work with mask_only = True, this way we ignore the other things\n",
    "            expanded_masked_indices = masked_indices[:,i].repeat_interleave(span)\n",
    "            # print(expanded_masked_indices, expanded_masked_indices.shape)\n",
    "            if extra > 0:\n",
    "                expanded_masked_indices = torch.cat([expanded_masked_indices, torch.zeros(extra, dtype=torch.bool)]) #so now we have a mask for every element in the span, so size length again\n",
    "            all_expanded_masked_indices[:,i] = expanded_masked_indices\n",
    "            \n",
    "            all_mask_positions = torch.nonzero(masked_indices[:,i]).squeeze()*span\n",
    "            # print(all_mask_positions, all_mask_positions.shape)\n",
    "            # mask_positions[i] = (all_mask_positions.unsqueeze(1) + torch.arange(span)).flatten()\n",
    "            # print(mask_positions[i], mask_positions[i].shape) #was a dict because the size changes depending on how many elements are masked. Although it should be a set value..., yeah don't need dict\n",
    "        \n",
    "        seq_unmask = torch.cat([seq, all_expanded_masked_indices.float()], dim=1)\n",
    "        seq_masked = seq_unmask.clone()\n",
    "        num_channels = seq.shape[1]\n",
    "        seq_masked[:, :num_channels] = seq_masked[:, :num_channels] * (~all_expanded_masked_indices).float()\n",
    "        if span > 1 and extra_append > 0:\n",
    "            seq_masked = seq_masked[:-extra_append]\n",
    "            seq_unmask = seq_unmask[:-extra_append]\n",
    "        return seq_masked, seq_unmask #return the masked sequence and the unmasked sequence\n",
    "    \n",
    "\n",
    "    # Get positions that were chosen to be masked\n",
    "    all_mask_positions = torch.nonzero(masked_indices).squeeze()*span #squeeze to remove the extra dimension, and multiply by span to get the actual positions in the original sequence\n",
    "    num_masked = all_mask_positions.numel()\n",
    "    \n",
    "    # Determine counts for the three groups: 80% truly masked, 10% random, 10% unchanged\n",
    "    num_mask = int(0.8 * num_masked)\n",
    "    num_random = int(0.1 * num_masked)\n",
    "    # To avoid rounding issues, let the remaining be unchanged\n",
    "    # num_unchanged = num_masked - num_mask - num_random\n",
    "    \n",
    "    # Shuffle the masked positions to randomly assign each to a category\n",
    "    permuted = all_mask_positions[torch.randperm(num_masked)]\n",
    "    mask_positions = permuted[:num_mask]  # 80%: replace with mask token\n",
    "    random_positions = permuted[num_mask:num_mask+num_random]  # 10%: random token\n",
    "    unchanged_positions = permuted[num_mask+num_random:]  # 10%: leave as is\n",
    "\n",
    "    if span > 1:\n",
    "        masked_indices = masked_indices.repeat_interleave(span) #so now we have a mask for every element in the span, so size length again\n",
    "        #and append zeros until the size of seq\n",
    "        extra = seq.shape[0] % span\n",
    "        if extra > 0:\n",
    "            masked_indices = torch.cat([masked_indices, torch.zeros(extra, dtype=torch.bool)]) #so now we have a mask for every element in the span, so size length again\n",
    "        \n",
    "        #now for each of the positions, we need to expand and then make masking apply per index\n",
    "        mask_positions = (mask_positions.unsqueeze(1) + torch.arange(span)).flatten()\n",
    "        random_positions = (random_positions.unsqueeze(1) + torch.arange(span)).flatten()\n",
    "        unchanged_positions = (unchanged_positions.unsqueeze(1) + torch.arange(span)).flatten()\n",
    "        #and now they are grouped and we can just deal with them\n",
    "\n",
    "    # Append the mask track to the sequence, resulting in a tensor of shape [seq_len, 6], or [seq_len, 2] if acc data\n",
    "    # where the last column is the mask track\n",
    "    seq_unmask = torch.cat([seq, masked_indices.unsqueeze(1).float()], dim=1) #so now seq_unmask is shape length x 6, where 6 is the 5 one hot classes and the mask\n",
    "    \n",
    "    seq_masked = seq_unmask.clone()  # Create a copy to modify, note that the mask track should be 0 for ones where it's not masked but is random or unchanged\n",
    "    seq_masked[mask_positions, :-1] = 0  # Set to zero for every class but the last (tells it it's masked)\n",
    "    \n",
    "    if mask_only:\n",
    "        #now forcibly mask the rest\n",
    "        seq_masked[unchanged_positions, :-1] = 0  # Set to zero for every class but the last (tells it it's masked)\n",
    "        seq_masked[random_positions, :-1] = 0  # Set to zero for every class but the last (tells it it's masked)\n",
    "        if span > 1 and extra_append > 0:\n",
    "            seq_masked = seq_masked[:-extra_append]\n",
    "            seq_unmask = seq_unmask[:-extra_append]\n",
    "        # print(seq_masked.shape)\n",
    "        return seq_masked, seq_unmask #return the masked sequence and the unmasked sequence, so we can use it for the rest of the processing\n",
    "    \n",
    "    if stype == 'category':\n",
    "        # print(f'random_positions shape: {random_positions.shape}, seq shape: {seq.shape}')\n",
    "        if replace_with_N:\n",
    "            random_max = seq.shape[1]\n",
    "        else:\n",
    "            random_max = seq.shape[1] - 1\n",
    "        random_tokens = torch.randint(0, random_max, (random_positions.numel()//span,)) #generate random values for each position\n",
    "        random_one_hot = torch.zeros((random_positions.numel()//span, seq.shape[1])) #one hot encode them\n",
    "        random_one_hot.scatter_(1, random_tokens.unsqueeze(1), 1.0)\n",
    "        #now repeat with the span\n",
    "        random_one_hot = random_one_hot.repeat_interleave(span, dim=0) #so now we have a one hot for each position in the span\n",
    "        seq_masked[random_positions, :seq.shape[1]] = random_one_hot #assign them to the set positions\n",
    "        \n",
    "    elif stype == 'continuous':\n",
    "        #for accessibility, we will select random values from somewhere else in the sequence and then slightly shift and noise them\n",
    "        #get a random value between 0 and len(seq)-span\n",
    "        rand_start = torch.randint(0, seq.shape[0]-span, (random_positions.numel()//span,)) #definitely divisble by span since it was extended by size span\n",
    "        rand_idx = (rand_start.unsqueeze(1) + torch.arange(span)) #so now we have a random index for each of the random positions, and we can just select from there\n",
    "        rand_vals = seq.squeeze(1)[rand_idx] #get the values from the sequence at those random positions, so now we have a random value for each of the random positions\n",
    "        #and we can add some noise to it, so we can just add a small random value to it. Noise will be values between -0.1 and 0.1\n",
    "        rand_vals_mean = rand_vals.mean(1, keepdim=True) #get the mean of the random values for each position, keeps the dim so we can broadcast it\n",
    "        noise = torch.randn(rand_vals.shape) * rand_vals_mean * 0.1 #gaussian noise with std of 0.1 times the mean of the random values, so we can add some larger nosie to larger values\n",
    "        rand_vals = torch.clamp((rand_vals + noise).flatten(), min = 0) #make sure values are at least 0, else obvious there's noise in the region\n",
    "        #and now set the values\n",
    "        seq_masked[random_positions, 0] = rand_vals #set the values to the random values with noise, so now we have a random value for each of the random positions\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"stype must be either 'category' or 'continuous'\")\n",
    "    \n",
    "    #and remove the masked value, it doesn't know it's masked\n",
    "    seq_masked[random_positions, -1] = 0\n",
    "    \n",
    "    #and we remove the mask token from the unchanged value\n",
    "    seq_masked[unchanged_positions, -1] = 0\n",
    "    # seq = seq_masked #now we have the masked sequence, so we can use this for the rest of the processing\n",
    "\n",
    "    if span > 1 and extra_append > 0:\n",
    "        seq_masked = seq_masked[:-extra_append]\n",
    "        seq_unmask = seq_unmask[:-extra_append]\n",
    "    \n",
    "    return seq_masked, seq_unmask #return the masked sequence and the unmasked sequence, so we can use it for the rest of the processing\n",
    "\n",
    "\n",
    "import torch\n",
    "seq = torch.ones((20,5))\n",
    "mask_pct=0.3\n",
    "replace_with_N=True\n",
    "span=2\n",
    "mask_only=True\n",
    "stype='category'\n",
    "weights=None\n",
    "mask_tie=0.5\n",
    "\n",
    "print(seq, seq.shape)\n",
    "seq_masked, seq_unmask = mask_seq(seq, mask_pct=mask_pct, replace_with_N=replace_with_N, span=span, stype=stype, weights=weights, mask_only=mask_only, mask_tie=mask_tie)\n",
    "print(seq_masked, seq_masked.shape)\n",
    "print(seq_unmask, seq_unmask.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f1e62ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just from visual inspection, it looks quite good, let's check some things\n",
    "torch.allclose(seq_masked[:, 5:], seq_unmask[:, 5:]) #should be true, since this part is just the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83c1789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we should see that only when masked is it zewro, so sum with mask\n",
    "torch.allclose(seq_masked[:, :5] + seq_masked[:, 5:], seq_unmask[:, :5]) #should be true, and since it is, I think we can comfortably say that this seems to be fine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "feb67231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([524288, 700])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 700/700 [00:03<00:00, 213.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([524288, 1400])\n",
      "torch.Size([524288, 1400])\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#let's test the speed with the actual values I want\n",
    "num_categories = 700\n",
    "seq = torch.ones((524288,num_categories))\n",
    "mask_pct=0.3\n",
    "replace_with_N=True\n",
    "span=500\n",
    "mask_only=True\n",
    "stype='category'\n",
    "weights=None\n",
    "mask_tie=0.5\n",
    "\n",
    "print(seq.shape)\n",
    "seq_masked, seq_unmask = mask_seq(seq, mask_pct=mask_pct, replace_with_N=replace_with_N, span=span, stype=stype, weights=weights, mask_only=mask_only, mask_tie=mask_tie)\n",
    "print(seq_masked.shape)\n",
    "print(seq_unmask.shape)\n",
    "\n",
    "#and do my checks\n",
    "print(torch.allclose(seq_masked[:, num_categories:], seq_unmask[:, num_categories:])) #should be true, since this part is just the mask\n",
    "print(torch.allclose(seq_masked[:, :num_categories] + seq_masked[:, num_categories:], seq_unmask[:, :num_categories])) #should be true, and since it is, I think we can comfortably say that this seems to be fine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5bdc3608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([524288, 700])\n",
      "setup time: 0.22496938705444336 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 700/700 [00:02<00:00, 244.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([524288, 1400])\n",
      "torch.Size([524288, 1400])\n",
      "masking time: 5.711634635925293 seconds\n"
     ]
    }
   ],
   "source": [
    "#wait what's the slow part?\n",
    "import time\n",
    "start_time = time.time()\n",
    "num_categories = 700\n",
    "seq = torch.ones((524288,num_categories))\n",
    "mask_pct=0.3\n",
    "replace_with_N=True\n",
    "span=500\n",
    "mask_only=True\n",
    "stype='category'\n",
    "weights=None\n",
    "mask_tie=0.5\n",
    "\n",
    "print(seq.shape)\n",
    "print(f'setup time: {time.time() - start_time} seconds')\n",
    "start_time = time.time()\n",
    "\n",
    "seq_masked, seq_unmask = mask_seq(seq, mask_pct=mask_pct, replace_with_N=replace_with_N, span=span, stype=stype, weights=weights, mask_only=mask_only, mask_tie=mask_tie)\n",
    "print(seq_masked.shape)\n",
    "print(seq_unmask.shape)\n",
    "print(f'masking time: {time.time() - start_time} seconds')\n",
    "#hmmm, the loop only takes 3 seconds, it's what is after the loop.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce242fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#almost 6 seconds per call, with the rest of the dataset and actually loading the data, this makes it quite slow... \n",
    "#let's go through step by step to see what's slow\n",
    "torch.cat([seq,seq], dim=1) #half a second, quite fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fa475e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat time: 0.5952975749969482 seconds\n",
      "clone time: 0.5188882350921631 seconds\n",
      "masking time: 0.04568123817443848 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#first the concat\n",
    "temp1 = torch.cat([seq,seq], dim=1)\n",
    "print(f'concat time: {time.time() - start_time} seconds')\n",
    "start_time = time.time()\n",
    "#then the cloning\n",
    "temp2 = temp1.clone()\n",
    "print(f'clone time: {time.time() - start_time} seconds')\n",
    "start_time = time.time()\n",
    "#now the masking\n",
    "temp1[:, :num_channels] = temp1[:, :num_channels] * (~temp1[:, :num_channels].bool()).float()\n",
    "print(f'masking time: {time.time() - start_time} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f18c2c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]]) tensor([[0., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#let's test if we can preallocate, first see if there's changes\n",
    "\n",
    "a = torch.ones((3,3))\n",
    "b = torch.zeros((3,3))\n",
    "b[1,1] = a[1,1]\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a36c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 5., 1.],\n",
      "        [1., 1., 1.]]) tensor([[0., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "a[1,1] = 5\n",
    "print(a,b) #no changes, to b, so we can preallocate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f1cd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so what if we did something like this\n",
    "\n",
    "def mask_seq(seq, mask_pct=0.15, replace_with_N=True, span=1, stype='category', weights=None, mask_only=False, mask_tie=1):\n",
    "    \"\"\"This function will mask the sequence data, it does the BERT masking where you do 80% truly masked, 10% random, 10% unchanged\n",
    "    Note that for random replacement, it cannot be the N token, sicne it's very rare anyways, always random nucleotide!\n",
    "    Args:\n",
    "        seq: the sequence to mask, this is a tensor of shape (length, N) if categorical, or (length,1) if continuous, N is the number of classes (5 for ohe nucleotide data)\n",
    "        mask_pct: the percentage of the sequence to mask, default is 0.15 or 15%\n",
    "        replace_with_N: whether to allow random replacement of values with N (for one hot encoded data). Keep True for other categorical data\n",
    "        span: the size of the span to mask, default is 1, so it masks every element independently, but can be larger to mask chunks of size span\n",
    "        stype: the type of sequence, 'category' for categorical like ohe nucleotide data and 'continuous' for continuous like raw accessibility data, default is 'category'\n",
    "        weights: the weights to use for weighting regions like peaks. default is None, must be a tensor of shape (length,) to weight the peaks higher for masking. can be the same as the seq itself\n",
    "        mask_only: whether to do the 10% unchanged and 10% random replacement, default is False. If True, will only do the 100% truly masked and leave the rest unchanged\n",
    "        mask_tie: how much masking is tied across categories. 1 means fully tied, so all tracks are masked the same, 0 means fully indepdendent masking across categories. If true, returns slightlly different values\n",
    "    Returns:\n",
    "        seq: the masked sequence, this is a tensor of shape (length, N+1) or N*2 if mask_tie is less than 1 if categorical or (length, 2) if continuous, where the last column is the mask track (only tells if masked, some are random or unchanged)\n",
    "        seq_unmask: the unmasked sequence, this is a tensor of shape (length, N+1) or N*2 if categorical or (length, 2), where the last column is the mask track (tells all elements that have been changed or goign to evaluate)\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(seq.shape) == 1: #if it's just a 1D tensor, we need to add a dimension for the mask track\n",
    "        seq = seq.unsqueeze(1) #so now it's shape length x 1, so we can concatenate other things\n",
    "    \n",
    "    extra_append = 0\n",
    "    if seq.shape[0]%span != 0:\n",
    "        #we append on values\n",
    "        remainder = seq.shape[0] % span\n",
    "        extra_append = span - remainder\n",
    "        seq = torch.cat([seq, torch.zeros((extra_append,seq.shape[1]), dtype=torch.float)]) #so now we can have a mask for every element in the span, so size length again\n",
    "    \n",
    "    num_elements = seq.shape[0]//span #chunks into chunks of size span\n",
    "\n",
    "    # Create a probability vector (one per token) and sample which tokens to mask\n",
    "    probability_matrix = torch.full((num_elements,), mask_pct) #size of length, defines for each element if we mask it or not\n",
    "    \n",
    "    #we can also weight peak regions more\n",
    "    if weights is not None:\n",
    "        assert mask_tie == 1, \"Weighting with weights is only supported for mask_tie=1 currently\"\n",
    "        weights = weights.squeeze()\n",
    "        assert weights.ndim == 1, f\"weights must be a 1D tensor, got {weights.shape}\"\n",
    "\n",
    "        #Trim weights to match the required size\n",
    "        if weights.shape[0] % span != 0:\n",
    "            #remove values until it is the right size\n",
    "            weights = weights[:num_elements*span]\n",
    "        \n",
    "        #compute mean over spans\n",
    "        weights = weights.view(num_elements, span).mean(1) #average the weights over the span, so now it's size length\n",
    "        \n",
    "        #normalize weights to have range 0.5 to 1.5\n",
    "        weights = torch.log(weights + 1) #log transform to reduce the scale of values\n",
    "        weights = (weights - weights.min()) / (weights.max() - weights.min()) + .5 #normalize to have different range, downweights small values, upweights large ones to almost 3x\n",
    "\n",
    "        #scale probability matrix by weights\n",
    "        probability_matrix = probability_matrix * weights #so now we have a weighted probability matrix, so we can mask more in peak regions\n",
    "        #and scale up probability matrix so that the mean is mask_pct\n",
    "        probability_matrix = probability_matrix / probability_matrix.mean() * mask_pct #so now we have a weighted probability matrix, so we can mask more in peak regions\n",
    "        \n",
    "        #clip to make sure between 0 and 1\n",
    "        probability_matrix = torch.clamp(probability_matrix, min=0, max=1) #clip to make sure between 0 and 1     \n",
    "    \n",
    "    masked_indices = torch.bernoulli(probability_matrix.float()).bool() #finds which indices to mask, so shape is length, and is True or False for each index\n",
    "\n",
    "    if mask_tie < 1: #have to implement own logic and loop\n",
    "        assert mask_only, \"Not implemented for mask_only = False yet\"\n",
    "        extra = seq.shape[0] % span\n",
    "        #first replicate masked_indices to be of shape length x num_categories\n",
    "        masked_indices = masked_indices.unsqueeze(1).repeat(1, seq.shape[1])\n",
    "        all_expanded_masked_indices = torch.zeros((seq.shape[0], seq.shape[1]), dtype=torch.bool)\n",
    "        #now per row we need to randomly change some of the true and falses at the 1-mask_tie proportion\n",
    "        \n",
    "        #let's just loop over it. Not the best, I know, but it is the easiest\n",
    "        base_mask = masked_indices[:,0].clone()\n",
    "        num_masked = base_mask.sum().item()\n",
    "        true_indices = torch.nonzero(base_mask).squeeze()\n",
    "        false_indices = torch.nonzero(~base_mask).squeeze()\n",
    "        # mask_positions = torch.zeros((masked_indices.shape[1], num_masked*span), dtype=torch.long) #preallocate max size\n",
    "        q = 1-mask_tie\n",
    "        for i in range(masked_indices.shape[1]):\n",
    "            #now we find 10% of the true values and turn them to false, and then get the same amount and turn them from false to true\n",
    "            num_change = int(num_masked * q)\n",
    "            #randomly select num_change indices from true_indices and false_indices\n",
    "            true_change_indices = true_indices[torch.randperm(true_indices.numel())[:num_change]]\n",
    "            false_change_indices = false_indices[torch.randperm(false_indices.numel())[:num_change]]\n",
    "            #now set them\n",
    "            masked_indices[true_change_indices, i] = False\n",
    "            masked_indices[false_change_indices, i] = True\n",
    "            #also just do the steps to get all mask positions. This metric keeps the amount of true and false at least? then we also need to decide which ones are true mask which ones are random?\n",
    "            #for now we can make it work with mask_only = True, this way we ignore the other things\n",
    "            expanded_masked_indices = masked_indices[:,i].repeat_interleave(span)\n",
    "            # print(expanded_masked_indices, expanded_masked_indices.shape)\n",
    "            if extra > 0:\n",
    "                expanded_masked_indices = torch.cat([expanded_masked_indices, torch.zeros(extra, dtype=torch.bool)]) #so now we have a mask for every element in the span, so size length again\n",
    "            all_expanded_masked_indices[:,i] = expanded_masked_indices\n",
    "            \n",
    "            all_mask_positions = torch.nonzero(masked_indices[:,i]).squeeze()*span\n",
    "            # print(all_mask_positions, all_mask_positions.shape)\n",
    "            # mask_positions[i] = (all_mask_positions.unsqueeze(1) + torch.arange(span)).flatten()\n",
    "            # print(mask_positions[i], mask_positions[i].shape) #was a dict because the size changes depending on how many elements are masked. Although it should be a set value..., yeah don't need dict\n",
    "        \n",
    "        seq_unmask = torch.zeros((seq.shape[0], seq.shape[1]*2), dtype=torch.float)\n",
    "        seq_unmask[:, :seq.shape[1]] = seq\n",
    "        seq_unmask[:, seq.shape[1]:] = all_expanded_masked_indices.float()\n",
    "        seq_masked = seq_unmask.clone()\n",
    "        # seq_masked = torch.zeros((seq.shape[0], seq.shape[1]*2), dtype=torch.float) #this should be a faster way to clone\n",
    "        # seq_masked[:, :seq.shape[1]] = seq\n",
    "        # seq_masked[:, seq.shape[1]:] = all_expanded_masked_indices.float()\n",
    "        \n",
    "        # seq_unmask = torch.cat([seq, all_expanded_masked_indices.float()], dim=1)\n",
    "        # seq_masked = seq_unmask.clone()\n",
    "        num_channels = seq.shape[1]\n",
    "        seq_masked[:, :num_channels] = seq_masked[:, :num_channels] * (~all_expanded_masked_indices).float()\n",
    "        if span > 1 and extra_append > 0:\n",
    "            seq_masked = seq_masked[:-extra_append]\n",
    "            seq_unmask = seq_unmask[:-extra_append]\n",
    "        return seq_masked, seq_unmask #return the masked sequence and the unmasked sequence\n",
    "    \n",
    "\n",
    "    # Get positions that were chosen to be masked\n",
    "    all_mask_positions = torch.nonzero(masked_indices).squeeze()*span #squeeze to remove the extra dimension, and multiply by span to get the actual positions in the original sequence\n",
    "    num_masked = all_mask_positions.numel()\n",
    "    \n",
    "    # Determine counts for the three groups: 80% truly masked, 10% random, 10% unchanged\n",
    "    num_mask = int(0.8 * num_masked)\n",
    "    num_random = int(0.1 * num_masked)\n",
    "    # To avoid rounding issues, let the remaining be unchanged\n",
    "    # num_unchanged = num_masked - num_mask - num_random\n",
    "    \n",
    "    # Shuffle the masked positions to randomly assign each to a category\n",
    "    permuted = all_mask_positions[torch.randperm(num_masked)]\n",
    "    mask_positions = permuted[:num_mask]  # 80%: replace with mask token\n",
    "    random_positions = permuted[num_mask:num_mask+num_random]  # 10%: random token\n",
    "    unchanged_positions = permuted[num_mask+num_random:]  # 10%: leave as is\n",
    "\n",
    "    if span > 1:\n",
    "        masked_indices = masked_indices.repeat_interleave(span) #so now we have a mask for every element in the span, so size length again\n",
    "        #and append zeros until the size of seq\n",
    "        extra = seq.shape[0] % span\n",
    "        if extra > 0:\n",
    "            masked_indices = torch.cat([masked_indices, torch.zeros(extra, dtype=torch.bool)]) #so now we have a mask for every element in the span, so size length again\n",
    "        \n",
    "        #now for each of the positions, we need to expand and then make masking apply per index\n",
    "        mask_positions = (mask_positions.unsqueeze(1) + torch.arange(span)).flatten()\n",
    "        random_positions = (random_positions.unsqueeze(1) + torch.arange(span)).flatten()\n",
    "        unchanged_positions = (unchanged_positions.unsqueeze(1) + torch.arange(span)).flatten()\n",
    "        #and now they are grouped and we can just deal with them\n",
    "\n",
    "    # Append the mask track to the sequence, resulting in a tensor of shape [seq_len, 6], or [seq_len, 2] if acc data\n",
    "    # where the last column is the mask track\n",
    "    seq_unmask = torch.cat([seq, masked_indices.unsqueeze(1).float()], dim=1) #so now seq_unmask is shape length x 6, where 6 is the 5 one hot classes and the mask\n",
    "    \n",
    "    seq_masked = seq_unmask.clone()  # Create a copy to modify, note that the mask track should be 0 for ones where it's not masked but is random or unchanged\n",
    "    seq_masked[mask_positions, :-1] = 0  # Set to zero for every class but the last (tells it it's masked)\n",
    "    \n",
    "    if mask_only:\n",
    "        #now forcibly mask the rest\n",
    "        seq_masked[unchanged_positions, :-1] = 0  # Set to zero for every class but the last (tells it it's masked)\n",
    "        seq_masked[random_positions, :-1] = 0  # Set to zero for every class but the last (tells it it's masked)\n",
    "        if span > 1 and extra_append > 0:\n",
    "            seq_masked = seq_masked[:-extra_append]\n",
    "            seq_unmask = seq_unmask[:-extra_append]\n",
    "        # print(seq_masked.shape)\n",
    "        return seq_masked, seq_unmask #return the masked sequence and the unmasked sequence, so we can use it for the rest of the processing\n",
    "    \n",
    "    if stype == 'category':\n",
    "        # print(f'random_positions shape: {random_positions.shape}, seq shape: {seq.shape}')\n",
    "        if replace_with_N:\n",
    "            random_max = seq.shape[1]\n",
    "        else:\n",
    "            random_max = seq.shape[1] - 1\n",
    "        random_tokens = torch.randint(0, random_max, (random_positions.numel()//span,)) #generate random values for each position\n",
    "        random_one_hot = torch.zeros((random_positions.numel()//span, seq.shape[1])) #one hot encode them\n",
    "        random_one_hot.scatter_(1, random_tokens.unsqueeze(1), 1.0)\n",
    "        #now repeat with the span\n",
    "        random_one_hot = random_one_hot.repeat_interleave(span, dim=0) #so now we have a one hot for each position in the span\n",
    "        seq_masked[random_positions, :seq.shape[1]] = random_one_hot #assign them to the set positions\n",
    "        \n",
    "    elif stype == 'continuous':\n",
    "        #for accessibility, we will select random values from somewhere else in the sequence and then slightly shift and noise them\n",
    "        #get a random value between 0 and len(seq)-span\n",
    "        rand_start = torch.randint(0, seq.shape[0]-span, (random_positions.numel()//span,)) #definitely divisble by span since it was extended by size span\n",
    "        rand_idx = (rand_start.unsqueeze(1) + torch.arange(span)) #so now we have a random index for each of the random positions, and we can just select from there\n",
    "        rand_vals = seq.squeeze(1)[rand_idx] #get the values from the sequence at those random positions, so now we have a random value for each of the random positions\n",
    "        #and we can add some noise to it, so we can just add a small random value to it. Noise will be values between -0.1 and 0.1\n",
    "        rand_vals_mean = rand_vals.mean(1, keepdim=True) #get the mean of the random values for each position, keeps the dim so we can broadcast it\n",
    "        noise = torch.randn(rand_vals.shape) * rand_vals_mean * 0.1 #gaussian noise with std of 0.1 times the mean of the random values, so we can add some larger nosie to larger values\n",
    "        rand_vals = torch.clamp((rand_vals + noise).flatten(), min = 0) #make sure values are at least 0, else obvious there's noise in the region\n",
    "        #and now set the values\n",
    "        seq_masked[random_positions, 0] = rand_vals #set the values to the random values with noise, so now we have a random value for each of the random positions\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"stype must be either 'category' or 'continuous'\")\n",
    "    \n",
    "    #and remove the masked value, it doesn't know it's masked\n",
    "    seq_masked[random_positions, -1] = 0\n",
    "    \n",
    "    #and we remove the mask token from the unchanged value\n",
    "    seq_masked[unchanged_positions, -1] = 0\n",
    "    # seq = seq_masked #now we have the masked sequence, so we can use this for the rest of the processing\n",
    "\n",
    "    if span > 1 and extra_append > 0:\n",
    "        seq_masked = seq_masked[:-extra_append]\n",
    "        seq_unmask = seq_unmask[:-extra_append]\n",
    "    \n",
    "    return seq_masked, seq_unmask #return the masked sequence and the unmasked sequence, so we can use it for the rest of the processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd25bb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([524288, 700])\n",
      "setup time: 0.1466984748840332 seconds\n",
      "torch.Size([524288, 1400])\n",
      "torch.Size([524288, 1400])\n",
      "masking time: 3.3837931156158447 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "start_time = time.time()\n",
    "num_categories = 700\n",
    "seq = torch.ones((524288,num_categories))\n",
    "mask_pct=0.3\n",
    "replace_with_N=True\n",
    "span=500\n",
    "mask_only=True\n",
    "stype='category'\n",
    "weights=None\n",
    "mask_tie=0.5\n",
    "\n",
    "print(seq.shape)\n",
    "print(f'setup time: {time.time() - start_time} seconds')\n",
    "start_time = time.time()\n",
    "\n",
    "seq_masked, seq_unmask = mask_seq(seq, mask_pct=mask_pct, replace_with_N=replace_with_N, span=span, stype=stype, weights=weights, mask_only=mask_only, mask_tie=mask_tie)\n",
    "print(seq_masked.shape)\n",
    "print(seq_unmask.shape)\n",
    "print(f'masking time: {time.time() - start_time} seconds')\n",
    "#yeah this is notably faster lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dccf4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok updated masking function seems pretty decent. Now we just need to actually integrate it in my dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a48e55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([524288, 2]) torch.Size([524288, 2])\n",
      "torch.Size([524288, 1400]) torch.Size([524288, 1400])\n"
     ]
    }
   ],
   "source": [
    "#wait there's one more step, to see if this works with the loss function, let's first test it\n",
    "\n",
    "seq_1 = torch.ones((524288))\n",
    "seq2 = torch.ones((524288,700))\n",
    "\n",
    "seq_mask1, seq_unmask1 = mask_seq(seq_1, mask_pct=0.3, replace_with_N=True, span=500, stype='continuous', weights=None, mask_only=True, mask_tie=1)\n",
    "seq_mask2, seq_unmask2 = mask_seq(seq2, mask_pct=0.3, replace_with_N=True, span=500, stype='category', weights=None, mask_only=True, mask_tie=0.9)\n",
    "print(seq_mask1.shape, seq_unmask1.shape)\n",
    "print(seq_mask2.shape, seq_unmask2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9375c9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9360128"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def poisson_loss_mask(x, y):\n",
    "    \"\"\"\n",
    "    Poisson loss for accessibility regression.\n",
    "    \n",
    "    x: tuple (dummy, acc)\n",
    "         - acc: (batch_size, seq_len, 1)\n",
    "    y: tuple (dummy, acc_unmask)\n",
    "         - acc_unmask: (batch_size, seq_len, 2)   (last channel is the mask)\n",
    "    \"\"\"\n",
    "    # We only use the accessibility part.\n",
    "    acc = x[1]      # shape: (batch_size, seq_len, 1)\n",
    "    acc_unmask = y[1]  # shape: (batch_size, seq_len, 2)\n",
    "    \n",
    "    # Squeeze the last channel\n",
    "    acc = acc.squeeze(-1)\n",
    "    # Create mask from second channel (index 1)\n",
    "    mask = acc_unmask[:, :, 1] == 1\n",
    "    acc = acc[mask]\n",
    "    # Use the first channel (index 0) as the target, remove mask dim\n",
    "    acc_target = acc_unmask[mask][:, 0]\n",
    "    \n",
    "    # Make sure predictions are positive.\n",
    "    acc = F.softplus(acc)\n",
    "    \n",
    "    loss = F.poisson_nll_loss(acc, acc_target, log_input=False, full=False)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def poisson_loss_mask(x, y):\n",
    "    \"\"\"\n",
    "    Poisson loss for accessibility regression.\n",
    "    \n",
    "    x: tuple (dummy, acc)\n",
    "         - acc: (batch_size, seq_len, num_categories)\n",
    "    y: tuple (dummy, acc_unmask)\n",
    "         - acc_unmask: (batch_size, seq_len, 2*num_categoreies)   (last half channel is the mask)\n",
    "    \"\"\"\n",
    "\n",
    "    # We only use the accessibility part.\n",
    "    acc = x[1]      # shape: (batch_size, seq_len, num_categories)\n",
    "    acc_unmask = y[1]  # shape: (batch_size, seq_len, 2*num_categories)\n",
    "    \n",
    "    num_categories = acc.shape[2]\n",
    "    \n",
    "    # Squeeze the last channel\n",
    "    # Create mask from second half channels\n",
    "    mask = acc_unmask[:, :, num_categories:] == 1  # shape: (batch_size, seq_len, num_categories)\n",
    "    \n",
    "    # Use the first half channels as the target\n",
    "    acc_target = acc_unmask[:, :, :num_categories]  # shape: (batch_size, seq_len, num_categories)\n",
    "    \n",
    "    # Make sure predictions are positive.\n",
    "    acc = F.softplus(acc)\n",
    "    \n",
    "    # Apply mask\n",
    "    acc = acc[mask]\n",
    "    acc_target = acc_target[mask]\n",
    "    \n",
    "    loss = F.poisson_nll_loss(acc, acc_target, log_input=False, full=False)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ba969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok this seems good, now we just have to test putting this updated masking class in my dataset and see what happens\n",
    "#oh need to update the dataset class to take in the mask_tie parameter and to have some way to get all cell types\n",
    "#first testing if it works and shapes are right in python\n",
    "\n",
    "'''\n",
    "from src.dataloaders.datasets.general_dataset import GeneralDataset\n",
    "import torch\n",
    "dataset = GeneralDataset(\n",
    "    split='train',\n",
    "    data_path='/data1/lesliec/sarthak/data/DK_zarr/zarr_arrays/test_chrom_dnase_chunkchrom.zarr',\n",
    "    length=524288,\n",
    "    mlm=0.25,\n",
    "    acc_mlm=0.25,\n",
    "    data_idxs='/data1/lesliec/sarthak/data/DK_zarr/idx_lists/all_matched_immune.json',\n",
    "    multitasking=True,\n",
    "    # mask_tie = 0.99999, #if set this to 1, it will not mask independently and will only add 1 column for mask. Won't work in my loss function\n",
    "    mask_only=True #must be true for multiple cell types\n",
    ")\n",
    "out = dataset[0]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7758b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so after this see some sample outputs\n",
    "\n",
    "#then ask chatgpt if ok to just stack like this or if should be in order or if that doesn't matter\n",
    "#then test it with the updated loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a8eed7",
   "metadata": {},
   "source": [
    "# testing dataseat class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28e4777d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple target tracks detected, applying tied masking across all tracks with parameter 0.99\n",
      "torch.Size([6, 524288])\n",
      "torch.Size([524288, 6])\n",
      "torch.Size([1348, 524288])\n",
      "torch.Size([524288, 1348])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#I tested it with mask_tie=1, so then it returns it masked across all cell types and gives it in size N+1. That should really be changed, but oh well dog, too much to change. Realistically weight tie should be like 0.95 or something, maybe even higher, 0.99\n",
    "#let's see it with some actual data\n",
    "import sys\n",
    "sys.path.append('/data1/lesliec/sarthak/caduceus')\n",
    "from src.dataloaders.datasets.general_dataset import GeneralDataset\n",
    "import torch\n",
    "#now let's see the output with the arguments we traditionally use\n",
    "dataset = GeneralDataset(\n",
    "    split='train',\n",
    "    data_path='/data1/lesliec/sarthak/data/DK_zarr/zarr_arrays/test_chrom_dnase_chunkchrom.zarr',\n",
    "    length=524288,\n",
    "    mlm=0.25,\n",
    "    acc_mlm=0.25,\n",
    "    multitasking=True,\n",
    "    mask_tie = 0.99, #if set this to 1, it will not mask independently and will only add 1 column for mask. Won't work in my loss function\n",
    "    mask_only=True #must be true for multiple cell types\n",
    ")\n",
    "out = dataset[0]\n",
    "print(out[0][0].shape) #sequence shape\n",
    "print(out[1][0].shape) #unmasked sequence shape\n",
    "print(out[0][1].shape) #accessibility shape\n",
    "print(out[1][1].shape) #unmasked accessibility shape\n",
    "print(len(out[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1405c1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8884"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d05f6cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ok now we can see if it masked properly, I'll assume sequence is fine, but let's look at it\n",
    "seq_masked, seq_unmask = out[0][0], out[1][0]\n",
    "seq_masked[:,:100].t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef37f1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_unmask[:100] #all of this is N, but it's fine sequence wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5df87729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1348, 524288]) torch.Size([524288, 1348])\n"
     ]
    }
   ],
   "source": [
    "acc_masked, acc_unmask = out[0][1], out[1][1]\n",
    "print(acc_masked.shape, acc_unmask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f349b671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1348])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxes = acc_masked.max(1)\n",
    "maxes.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22311f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([191485, 191485, 181405,  ...,   3000,   3000,   3000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxes.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122f5618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5342, 1.6250, 0.1854, 0.0595, 0.0604],\n",
       "        [0.5342, 1.6250, 0.1854, 0.0595, 0.0604],\n",
       "        [0.5342, 1.6250, 0.1854, 0.0595, 0.0604],\n",
       "        [0.5342, 1.6250, 0.1854, 0.0595, 0.0604],\n",
       "        [0.5342, 1.6250, 0.1854, 0.0595, 0.0604],\n",
       "        [0.6558, 1.7861, 0.1752, 0.0695, 0.0817],\n",
       "        [0.6558, 1.7861, 0.1752, 0.0695, 0.0817],\n",
       "        [0.6558, 1.7861, 0.1752, 0.0695, 0.0817],\n",
       "        [0.6558, 1.7861, 0.1752, 0.0695, 0.0817],\n",
       "        [0.6558, 1.7861, 0.1752, 0.0695, 0.0817],\n",
       "        [0.6558, 1.7861, 0.1752, 0.0695, 0.0817],\n",
       "        [0.6558, 1.7861, 0.1752, 0.0695, 0.0817],\n",
       "        [0.6558, 1.7861, 0.1752, 0.0695, 0.0817],\n",
       "        [0.6558, 1.7861, 0.1752, 0.0695, 0.0817],\n",
       "        [0.6558, 1.7861, 0.1752, 0.0695, 0.0817],\n",
       "        [0.6558, 1.7861, 0.1752, 0.0695, 0.0817],\n",
       "        [0.6558, 1.7861, 0.1752, 0.0695, 0.0817],\n",
       "        [0.6558, 1.7861, 0.1752, 0.0695, 0.0817],\n",
       "        [0.6558, 1.7861, 0.1752, 0.0695, 0.0817],\n",
       "        [0.6558, 1.7861, 0.1752, 0.0695, 0.0817],\n",
       "        [0.6558, 1.7861, 0.1752, 0.0695, 0.0817],\n",
       "        [0.6558, 1.7861, 0.1752, 0.0695, 0.0817],\n",
       "        [0.6558, 1.7861, 0.1752, 0.0695, 0.0817],\n",
       "        [0.6558, 1.7861, 0.1752, 0.0695, 0.0817],\n",
       "        [0.6558, 1.7861, 0.1752, 0.0695, 0.0817],\n",
       "        [0.7568, 1.5518, 0.1442, 0.0695, 0.0888],\n",
       "        [0.7568, 1.5518, 0.1442, 0.0695, 0.0888],\n",
       "        [0.7568, 1.5518, 0.1442, 0.0695, 0.0888],\n",
       "        [0.7568, 1.5518, 0.1442, 0.0695, 0.0888],\n",
       "        [0.7568, 1.5518, 0.1442, 0.0695, 0.0888],\n",
       "        [0.7568, 1.5518, 0.1442, 0.0695, 0.0888],\n",
       "        [0.7568, 1.5518, 0.1442, 0.0695, 0.0888],\n",
       "        [0.7568, 1.5518, 0.1442, 0.0695, 0.0888],\n",
       "        [0.7568, 1.5518, 0.1442, 0.0695, 0.0888],\n",
       "        [0.7568, 1.5518, 0.1442, 0.0695, 0.0888],\n",
       "        [0.7568, 1.5518, 0.1442, 0.0695, 0.0888],\n",
       "        [0.7568, 1.5518, 0.1442, 0.0695, 0.0888],\n",
       "        [0.7568, 1.5518, 0.1442, 0.0695, 0.0888],\n",
       "        [0.7568, 1.5518, 0.1442, 0.0695, 0.0888],\n",
       "        [0.7568, 1.5518, 0.1442, 0.0695, 0.0888],\n",
       "        [0.7568, 1.5518, 0.1442, 0.0695, 0.0888],\n",
       "        [0.7568, 1.5518, 0.1442, 0.0695, 0.0888],\n",
       "        [0.7568, 1.5518, 0.1442, 0.0695, 0.0888],\n",
       "        [0.7568, 1.5518, 0.1442, 0.0695, 0.0888],\n",
       "        [0.7568, 1.5518, 0.1442, 0.0695, 0.0888],\n",
       "        [0.8247, 1.6758, 0.1752, 0.0794, 0.1172],\n",
       "        [0.8247, 1.6758, 0.1752, 0.0794, 0.1172],\n",
       "        [0.8247, 1.6758, 0.1752, 0.0794, 0.1172],\n",
       "        [0.8247, 1.6758, 0.1752, 0.0794, 0.1172],\n",
       "        [0.8247, 1.6758, 0.1752, 0.0794, 0.1172],\n",
       "        [0.8247, 1.6758, 0.1752, 0.0794, 0.1172],\n",
       "        [0.8247, 1.6758, 0.1752, 0.0794, 0.1172],\n",
       "        [0.8247, 1.6758, 0.1752, 0.0794, 0.1172],\n",
       "        [0.8247, 1.6758, 0.1752, 0.0794, 0.1172],\n",
       "        [0.8247, 1.6758, 0.1752, 0.0794, 0.1172],\n",
       "        [0.8247, 1.6758, 0.1752, 0.0794, 0.1172],\n",
       "        [0.8247, 1.6758, 0.1752, 0.0794, 0.1172],\n",
       "        [0.8247, 1.6758, 0.1752, 0.0794, 0.1172],\n",
       "        [0.8247, 1.6758, 0.1752, 0.0794, 0.1172],\n",
       "        [0.8247, 1.6758, 0.1752, 0.0794, 0.1172],\n",
       "        [0.8247, 1.6758, 0.1752, 0.0794, 0.1172],\n",
       "        [0.8247, 1.6758, 0.1752, 0.0794, 0.1172],\n",
       "        [0.8247, 1.6758, 0.1752, 0.0794, 0.1172],\n",
       "        [0.8247, 1.6758, 0.1752, 0.0794, 0.1172],\n",
       "        [0.8247, 1.6758, 0.1752, 0.0794, 0.1172],\n",
       "        [1.0342, 2.0859, 0.2267, 0.1141, 0.1705],\n",
       "        [1.0342, 2.0859, 0.2267, 0.1141, 0.1705],\n",
       "        [1.0342, 2.0859, 0.2267, 0.1141, 0.1705],\n",
       "        [1.0342, 2.0859, 0.2267, 0.1141, 0.1705],\n",
       "        [1.0342, 2.0859, 0.2267, 0.1141, 0.1705],\n",
       "        [1.0342, 2.0859, 0.2267, 0.1141, 0.1705],\n",
       "        [1.0342, 2.0859, 0.2267, 0.1141, 0.1705],\n",
       "        [1.0342, 2.0859, 0.2267, 0.1141, 0.1705],\n",
       "        [1.0342, 2.0859, 0.2267, 0.1141, 0.1705],\n",
       "        [1.0342, 2.0859, 0.2267, 0.1141, 0.1705],\n",
       "        [1.0342, 2.0859, 0.2267, 0.1141, 0.1705],\n",
       "        [1.0342, 2.0859, 0.2267, 0.1141, 0.1705],\n",
       "        [1.0342, 2.0859, 0.2267, 0.1141, 0.1705],\n",
       "        [1.0342, 2.0859, 0.2267, 0.1141, 0.1705],\n",
       "        [1.0342, 2.0859, 0.2267, 0.1141, 0.1705],\n",
       "        [1.0342, 2.0859, 0.2267, 0.1141, 0.1705],\n",
       "        [1.0342, 2.0859, 0.2267, 0.1141, 0.1705],\n",
       "        [1.0342, 2.0859, 0.2267, 0.1141, 0.1705],\n",
       "        [1.0342, 2.0859, 0.2267, 0.1141, 0.1705],\n",
       "        [1.0342, 2.0859, 0.2267, 0.1141, 0.1705],\n",
       "        [1.1221, 2.5684, 0.2576, 0.1488, 0.1847],\n",
       "        [1.1221, 2.5684, 0.2576, 0.1488, 0.1847],\n",
       "        [1.1221, 2.5684, 0.2576, 0.1488, 0.1847],\n",
       "        [1.1221, 2.5684, 0.2576, 0.1488, 0.1847],\n",
       "        [1.1221, 2.5684, 0.2576, 0.1488, 0.1847],\n",
       "        [1.1221, 2.5684, 0.2576, 0.1488, 0.1847],\n",
       "        [1.1221, 2.5684, 0.2576, 0.1488, 0.1847],\n",
       "        [1.1221, 2.5684, 0.2576, 0.1488, 0.1847],\n",
       "        [1.1221, 2.5684, 0.2576, 0.1488, 0.1847],\n",
       "        [1.1221, 2.5684, 0.2576, 0.1488, 0.1847],\n",
       "        [1.1221, 2.5684, 0.2576, 0.1488, 0.1847],\n",
       "        [1.1221, 2.5684, 0.2576, 0.1488, 0.1847],\n",
       "        [1.1221, 2.5684, 0.2576, 0.1488, 0.1847],\n",
       "        [1.1221, 2.5684, 0.2576, 0.1488, 0.1847],\n",
       "        [1.1221, 2.5684, 0.2576, 0.1488, 0.1847]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's check the values around 191400-191500\n",
    "acc_masked[:5, 191400:191500].t() #see it's DNase, so repeats, but 5 separate values, each cell type is unique, perfect! None of these are masked obviously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "508424e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA2uElEQVR4nO3de3yU9Z33//fMJJkESMLJnEyAYCkg8UADVRRRiwVBbW3d1vWnYmvbvVnBU5baor3brl2Lu7e3N/WuQLWKt0Wr2wZdWllLrBy0oBQICnIQFQnGRORgJgRIMjPf3x+TXMlkJoEJmeuKuV7PfcyDmeuQ+c6VdOft53u4PMYYIwAAAId4nW4AAABwN8IIAABwFGEEAAA4ijACAAAcRRgBAACOIowAAABHEUYAAICjCCMAAMBRKU434FSEw2F9/PHHyszMlMfjcbo5AADgFBhjVF9fr4KCAnm9ndc/Phdh5OOPP1ZRUZHTzQAAAN2wf/9+FRYWdrr/cxFGMjMzJUU+TFZWlsOtAQAApyIQCKioqMj6Hu/M5yKMtHbNZGVlEUYAAPicOdkQCwawAgAARxFGAACAowgjAADAUYQRAADgKMIIAABwFGEEAAA4ijACAAAcRRgBAACOIowAAABHEUYAAICjCCMAAMBRhBEAAOCoz8WN8mCDwMfSxsel/mdIF8yWvORUAIA9CCOI2PCotOHXkedFF0iFpc62BwDgGvznLyKajrZ7Xu9cOwAArkMYQYQxTrcAAOBShBHEIpgAAGxEGEEL08lzAACSK6EwsmDBAk2cOFGZmZnKycnRtddeq927d3d5zpo1a+TxeGIeu3btOq2GAwCAviGhMLJ27VrNmTNHb7zxhioqKhQMBjVt2jQ1NDSc9Nzdu3erpqbGeowaNarbjUYStO+aoZsGAGCjhKb2vvzyy1Gvly5dqpycHG3evFlTpkzp8tycnBwNHDgw4QbCLnTTAACccVpjRurq6iRJgwcPPumx48ePV35+vqZOnarVq1d3eWxjY6MCgUDUAwAA9E3dDiPGGJWVlWny5MkqKSnp9Lj8/Hw99thjKi8v1/LlyzV69GhNnTpV69at6/ScBQsWKDs723oUFRV1t5k4VRRGAAAO8RjTvQECc+bM0UsvvaTXX39dhYWFCZ17zTXXyOPxaMWKFXH3NzY2qrGx0XodCARUVFSkuro6ZWVldae5OJkX50hbl0We3/hHadRXnW0PAOBzLxAIKDs7+6Tf392qjNx+++1asWKFVq9enXAQkaQLL7xQe/bs6XS/3+9XVlZW1APJxgBWAIAzEhrAaozR7bffrhdeeEFr1qxRcXFxt960srJS+fn53ToXAAD0LQmFkTlz5ujZZ5/Vf/3XfykzM1O1tbWSpOzsbGVkZEiS5s+fr+rqaj399NOSpIULF2rEiBEaN26cmpqatGzZMpWXl6u8vLyHPwpOi2HQCADAGQmFkcWLF0uSLrvssqjtS5cu1Xe+8x1JUk1Njaqqqqx9TU1Nmjdvnqqrq5WRkaFx48bppZde0syZM0+v5UgeumkAADbq9gBWO53qABichhdmS2/9PvL8huel0Vc62x4AwOdeUgewoq/r9fkUANCHEEYQwXLwAACHEEYQB2EEAGAfwghaEEAAAM4gjCCCbhoAgEMII4iDMAIAsA9hBC0IIAAAZxBGEItuGgCAjQgjiGA5eACAQwgjAADAUYQRtGA2DQDAGYQRxEEYAQDYhzCCCNYZAQA4hDACAAAcRRhBC2bTAACcQRhBLLppAAA2IowgggACAHAIYQQtCCMAAGcQRhCLKgkAwEaEEUQQQAAADiGMIA6CCQDAPoQRtGDRMwCAMwgjiIMwAgCwD2EEEVRDAAAOIYwgFsEEAGAjwgjiIIwAAOxDGAEAAI4ijCDCMJsGAOAMwgjiIIwAAOxDGEELAggAwBmEEUTQTQMAcAhhBHEQRgAA9iGMoAWVEQCAMwgjiPWX+wgkAADbEEYQ0T58NNVLhz9wri0AAFchjCC+cNDpFgAAXIIwghYdumXopgEA2IQwAgAAHEUYQURMJYTKCADAHoQRAADgKMIIWlAJAQA4gzCC+BjACgCwCWEEEYQPAIBDCCNowQBWAIAzCCMAAMBRhBFEdOymodsGAGATwgikpgbpg9VOtwIA4FKEEUiVy5xuAQDAxQgjkI4faXvuz2p5QjcNAMAehBG0jQ+Z8D0ptZ+zbQEAuA5hBLKqIB5Pu01URgAA9iCMoB3PyQ8BAKCHEUYQXQWxqiNURgAA9iCMQHG7aQAAsAlhBO14RFcNAMBuCYWRBQsWaOLEicrMzFROTo6uvfZa7d69+6TnrV27VqWlpUpPT9fIkSO1ZMmSbjcYSRBvsCoDWAEANkkojKxdu1Zz5szRG2+8oYqKCgWDQU2bNk0NDQ2dnrN3717NnDlTl1xyiSorK3XvvffqjjvuUHl5+Wk3Hj2lXTcNXTUAAJulJHLwyy+/HPV66dKlysnJ0ebNmzVlypS45yxZskTDhg3TwoULJUljx47Vpk2b9NBDD+m6667rXquRJO2DCJURAIA9TmvMSF1dnSRp8ODBnR6zYcMGTZs2LWrb9OnTtWnTJjU3N8c9p7GxUYFAIOqBJKJLBgDgoG6HEWOMysrKNHnyZJWUlHR6XG1trXJzc6O25ebmKhgM6uDBg3HPWbBggbKzs61HUVFRd5uJU9J+Nk1LdYSAAgCwSbfDyNy5c/X222/r97///UmP9XQYh2Bavug6bm81f/581dXVWY/9+/d3t5lICONFAAD2S2jMSKvbb79dK1as0Lp161RYWNjlsXl5eaqtrY3aduDAAaWkpGjIkCFxz/H7/fL7/d1pGroj7qJnAADYI6HKiDFGc+fO1fLly/Xqq6+quLj4pOdMmjRJFRUVUdtWrVqlCRMmKDU1NbHWIkniLXpGNw0AwB4JhZE5c+Zo2bJlevbZZ5WZmana2lrV1tbq+PHj1jHz58/XrFmzrNezZ8/Wvn37VFZWpp07d+rJJ5/UE088oXnz5vXcp0APojICALBXQmFk8eLFqqur02WXXab8/Hzr8fzzz1vH1NTUqKqqynpdXFyslStXas2aNTr//PP1i1/8Qo888gjTenuTuIue2d8MAIA7JTRmxJzCDIunnnoqZtull16qLVu2JPJWsBX3pgEAOId706AdT7teGkojAAB7EEbAmiIAAEcRRtDGw117AQD2I4wgPqolAACbEEbQLnhQFQEA2I8wgjYeT7sZNVRGAAD2IIxABA8AgJMII+jQTcNdewEA9iKMoA2LngEAHEAYgaK6aQgkAACbEUbQyWwaumkAAPYgjKANVREAgAMII1B0FYQBrAAAexFGwKJnAABHEUbQhkXPAAAOIIxABA8AgJMII6CbBgDgKMII2nhYgRUAYD/CCEQ3DQDASSlONwAOCtRIR2slE27ZwABWAID9CCNudfSA9PBYsRQ8AMBpdNO4Vd1+xa9+MGYEAGAvwohbxc0aVEYAAPYjjLiVNU6kHbIIAMABhBG3ihdGJAawAgBsRxhxrS7GiwAAYCPCiFt1VhlhACsAwGaEEbeKO2aEyggAwH6EEbeKW/loH0aojAAA7EEYcauTDmAFAMAehBG3Olk3DWNGAAA2IYy4VmfdNFRGAAD2Ioy4VaezaQAAsBdhxK3idcN4uGsvAMB+hBG3OulsGgAA7EEYcat43TTZZ7bbT2UEAGAPwohbdQwjmfnSuG+K6ggAwG6EEdfqUPko+nKHNUaojAAA7EEYcauOlRFPy58ChREAgM0II24VE0Z8zrQDAOB6hBG3ajoW/bq1MmLdtdfW1gAAXIww4kbBRunF2dHbPPwpAACcwTeQGzUcjN0WE0YojQAA7EEYcaV4q6+2DmBlBCsAwF6EETfqbCn4kx0DAEASEEbcKN7qq97W2TRURgAA9iKMuFIX3TQAANiMbyA3ittNwwBWAIAzCCNuFK+bpuMA1g/W2NYcAIC7EUYQ0RpGUtIj/76xSGo+7lx7AACuQRhxo666ab56f9s2wggAwAaEETeK102Tnh35t3Bi27Zw0J72AABcLcXpBsAJLZWR9Gzpip9Lxz+TSr8T2ebxSN6USBAhjAAAbEAYcaPWbhqPT5pwa+x+wggAwEYJd9OsW7dO11xzjQoKCuTxePTiiy92efyaNWvk8XhiHrt27epum3G6WrtpOltbxNuSUQkjAAAbJFwZaWho0Hnnnafvfve7uu666075vN27dysrK8t6fcYZZyT61ugxrZWRTlZbbV2NNRyypzkAAFdLOIzMmDFDM2bMSPiNcnJyNHDgwITPQxJYA1g7CyNURgAA9rFtNs348eOVn5+vqVOnavXq1V0e29jYqEAgEPVAD7LGjJykm2bdQ/a0BwDgakkPI/n5+XrsscdUXl6u5cuXa/To0Zo6darWrVvX6TkLFixQdna29SgqKkp2M13mJN00af0j/+540ZbWAADcLemzaUaPHq3Ro0dbrydNmqT9+/froYce0pQpU+KeM3/+fJWVlVmvA4EAgaQnnayb5tu/k5ZcHJltAwBAkjmy6NmFF16oPXv2dLrf7/crKysr6oEedLJumtYF0AAAsIEjYaSyslL5+flOvDUknbSbpuNxAAAkUcLdNEePHtV7771nvd67d6+2bt2qwYMHa9iwYZo/f76qq6v19NNPS5IWLlyoESNGaNy4cWpqatKyZctUXl6u8vLynvsUSIx1b5pOwshJQwoAAD0n4TCyadMmXX755dbr1rEdt9xyi5566inV1NSoqqrK2t/U1KR58+apurpaGRkZGjdunF566SXNnDmzB5qPbrG6aTo7wBN9HAAASeQxpvd/4wQCAWVnZ6uuro7xIz1h/0bpia9Kg0ZId74Vu7+uWvo/Z0em+P70kO3NAwD0Daf6/c1de93oZLNp6KYBANiIMOJGjUcj/54sdPT+ohkAoA8gjLiNMdIzJ7unEJURAIB9CCNu077acc634h9jVUyojAAAko8w4mYXzO56P900AAAbEEZc51QCBt00AAD7EEYQi24aAICNCCMAAMBRhBG3OaVxIHTTAADsQxhxs1NZ3IxBrACAJCOMIBYrsAIAbEQYcZ0Eu2mojAAAkoww4mqnUgEhjAAAkosw4janUumgmwYAYCPCCLpGNw0AIMkII25GBQQA0AsQRlwn0W4aKiMAgOQijLga64wAAJxHGEEcdN8AAOxDGHGbhGfTUBkBACQXYcTNWA4eANALEEZchxvlAQB6F8IIYtFNAwCwEWHE1aiAAACcRxhxm1MaA8KN8gAA9iGMIBbdNAAAGxFG3Izl4AEAvQBhxHXopgEA9C6EEQAA4CjCiKt10k3DmBEAgI0II27DbBoAQC9DGHEzBrACAHoBwojrcKM8AEDvQhhBHFRMAAD2IYy4GnftBQA4jzDiNqcSLuimAQDYiDACAAAcRRhxs05n0zC1FwBgH8KI6yTaTQMAQHIRRgAAgKMII65GNw0AwHmEEbfpJFycaA7p5e212vThYbppAAC2SnG6AegdFq95X7/66x5JUsVdl2iUtYfKCAAguaiMuE67cNGuAvJJ4IT1/MDRpnaHE0YAAMlFGIEkKRRuCx1hAggAwEaEEUiSQqZ9GGm/h2ACAEguwojbRFU92rppwu0SiDFG3CwPAGAXwggkSaF2GSUqr9TX2t4WAIC7EEbczBO/MhIZM9LyevkPbG4UAMBtCCOQ1HEAq6Rzr4+8aDrmTIMAAK5BGIGkjgNYjXTB7MgLE3aoRQAAtyCMuFpnA1gleVr+NEzI5jYBANyGMOI2nawh0r4yYoyRvL6WF1RGAADJRRiBdtUGtGb3p9brsJHkaQkjYSojAIDkSjiMrFu3Ttdcc40KCgrk8Xj04osvnvSctWvXqrS0VOnp6Ro5cqSWLFnSnbaiR8QuB/+X7Z9EHRE2pl03DZURAEByJRxGGhoadN555+nXv/71KR2/d+9ezZw5U5dccokqKyt177336o477lB5eXnCjUVyhDp03YSjummojAAAkivhu/bOmDFDM2bMOOXjlyxZomHDhmnhwoWSpLFjx2rTpk166KGHdN111yX69kiGeONIrMoIy8EDAJIr6WNGNmzYoGnTpkVtmz59ujZt2qTm5uZkvz06MrHdNB3jRlQ3DWNGAABJlnBlJFG1tbXKzc2N2pabm6tgMKiDBw8qPz8/5pzGxkY1NjZarwOBQLKb6Wodix/hsOimAQDYxpbZNB5P9E3XTMu3X8ftrRYsWKDs7GzrUVRUlPQ2ulk43pgRBrACAGyS9DCSl5en2trom60dOHBAKSkpGjJkSNxz5s+fr7q6Ouuxf//+ZDfTRWLHgHTcYpjaCwCwUdLDyKRJk1RRURG1bdWqVZowYYJSU1PjnuP3+5WVlRX1QPJ07Ka5p/xthVpXZzUhqfIZ+xsFAHCNhMPI0aNHtXXrVm3dulVSZOru1q1bVVVVJSlS1Zg1a5Z1/OzZs7Vv3z6VlZVp586devLJJ/XEE09o3rx5PfMJkBgrebR1kZk41ZK9DWltLyp/l+RGAQDcLOEwsmnTJo0fP17jx4+XJJWVlWn8+PH66U9/KkmqqamxgokkFRcXa+XKlVqzZo3OP/98/eIXv9AjjzzCtN5epDWf/OCS4rZt3lTp64+2vGDcCAAgeRKeTXPZZZdZA1Djeeqpp2K2XXrppdqyZUuibwWbtP4+vR6PBvdP0+GGpkitJH1g6wFONQ0A4ALcm8Z1WoJFu5lMxtrksTpvIjNqPNHnAACQBIQRRG6Mp0j2aJ1uHQkorYNYCSMAgOQhjMAawOpRWzEkMr2XyggAIPkII24TbzZN+8pI6zaZqGMAAEgWwggsXo8nujLSim4aAEASEUZgLQfvkeRpXw2hmwYAYAPCiOt0PptGMZURBrACAJKPMAJrAKu345gRKiMAABsQRtwmTpXDmtorD1N7AQC2I4y4VvzZNNa2qEMIIwCA5CGMQIq7zki7qb1kEQBAEhFGXCc2WbRWRrzedgNYpehSCQAASUIYcat2QSPcbkxI69Te6GEilEYAAMlDGEH0CqxR40QYwAoASD7CiNvEWw7e2tL+rr1iai8AwBaEEZdrCob1x80fSWpZZ4SpvQAAmxFGXO6VnZ9Yz9NTfW2LnhkWPQMA2IMw4jrRi4ocamiy9nztvIIOs3mpjAAAko8w4nKhUFiSdPW5+RrUP61dZURURgAAtiCMuE2HKkewZS34FG8keFhjRtrPpgEAIIkII64VCRqhljDi83rbbVV0MYRuGgBAEhFG3KLxqBRqjtkcWxmJbI9egZUwAgBIHsKIG1Q+Iz1YJP3vMdKxg1G7rMqIryWMiKm9AAB7EUbcYN96yYQjQaR2e2RbS9Wj88oIU3sBAPYgjLhCuzARqLaeBkNhLVr9niTJ540erEplBABgF8KIG7QPE2v/3Xq6ce9hqzKSnZEqqf1sGlEZAQDYgjDiCvHChEf1jUHr1S2TRkiKLAkvtazAytReAIANCCNu0Ek3i2nZPnHEIA3qnyapw2yak5wPAEBPIIy4gQnHbvN41LL4qtU1I7XNpjneFKKbBgBgC8KIK8QPE6GWioevfRhpeXrbM1us8SRkEQBAMhFG3OAk3TTedn8F155/pvX8WFNrRYU0AgBIHsKIK8QfwNq64Jm3XWXk1snFVnUk2BpiGDMCAEgiwogbdBImWnthOq4xktpSKglZQ00IIwCA5CGMuEG8Aaxer8JxKiNSWzgJtWYQKiMAgCQijLhCnDBx7WJrAGvHMJLia10qPukNAwBAKU43ADZorWxM/L6UMVgq+rI06qsKv7lPkuTrEElTWzZYs2nopgEAJBGVEVdoCRM5Z0tfuU8a9VVJ6rSbpvWmeT9fsSOyob5Gqt5iT1MBAK5DGHGD1spIh9BRuf8zSZK3wwDWc87MliS9fyy9beMbi5LWPACAuxFG3MAagNoWOj7+7LiWb4ncwdffoZ/m/mtLJEmfmMFSyT9ENoaakt5MAIA7EUZcIbYy8ml9o/V81kUjoo5uWwTeSMMubHnBuBEAQHIQRtwgTmWkdSZN0eAMnV80MOpw62Z5RjFdOwAA9DTCiCu0Vkbaft2mk2m97bdF10KojAAAkoMw4gbGuj2vtclafTVOGPFYxxi1r6YAAJAMhBE3iNNN0zqtN24vTPtuGgAAkoww4gqxA1hbKyPxumk88aohJBMAQJIQRtzAxI4ZCXc5ZqTdqXTTAACSjDDiBtaN8tpXRjrvpvG020g9BACQbIQRV0i0mybmTAAAkoYw4gbxBrC2dtPE+QvwRHXTdPwZAAD0LMKIK8RWRlrXGYk7tTcqjTBmBACQXISRvi4UlPauizxvFzJC1tIj8cJI23Nj1UaojAAAkoMw0tdt+X9tz72p1tO22TSxp3i6eAUAQE8jjPR1geq25yMvtZ52tRw8s2kAAHYijLjFBf8spWdbL9e/f0jSqawz0vqEWAIASA7CSF8XJ0QETjTr6Q37JEnpab6Y/dErsNJNAwBIrm6FkUWLFqm4uFjp6ekqLS3Va6+91umxa9askcfjiXns2rWr241GImJn0hw9EbSe333FqJgz4k7tpcMGAJAkCYeR559/XnfddZfuu+8+VVZW6pJLLtGMGTNUVVXV5Xm7d+9WTU2N9Rg1KvZLEEnQxRoj/hSvxg8bdGqnAwCQJAmHkYcffljf+9739P3vf19jx47VwoULVVRUpMWLF3d5Xk5OjvLy8qyHzxfbPYAkilpjJPKvL95UGkWPI2HMCAAg2RIKI01NTdq8ebOmTZsWtX3atGlav359l+eOHz9e+fn5mjp1qlavXt3lsY2NjQoEAlEPdFdsiOjqJnlSx/vVMGYEAJBcCYWRgwcPKhQKKTc3N2p7bm6uamtr456Tn5+vxx57TOXl5Vq+fLlGjx6tqVOnat26dZ2+z4IFC5SdnW09ioqKEmkm2otT0QjHDiOJEr2ZRc8AAMmV0p2TOq7aaYyJu5KnJI0ePVqjR4+2Xk+aNEn79+/XQw89pClTpsQ9Z/78+SorK7NeBwIBAkm3xSaPUPhklZH23TRURgAAyZVQZWTo0KHy+XwxVZADBw7EVEu6cuGFF2rPnj2d7vf7/crKyop6oJviDGA1Xay+Gn0k9RAAQPIlFEbS0tJUWlqqioqKqO0VFRW66KKLTvnnVFZWKj8/P5G3xunytJ9NE/n3VMaMWFmGAawAgCRJuJumrKxMN998syZMmKBJkybpscceU1VVlWbPni0p0sVSXV2tp59+WpK0cOFCjRgxQuPGjVNTU5OWLVum8vJylZeX9+wnwSlrHcDaWdcay8EDAOyUcBi5/vrrdejQId1///2qqalRSUmJVq5cqeHDh0uSampqotYcaWpq0rx581RdXa2MjAyNGzdOL730kmbOnNlznwKd62KdEV8XdTGPJ3LqhvcPaXrkByWrhQAAl+vWANbbbrtNt912W9x9Tz31VNTre+65R/fcc0933gY9InYAazgc+bezbhqpLcNs/PBISxgBACA5uDdNX9dFZaSrMPLUdyd28nMAAOhZhBG38MSGkS6yiIb090uSQuGktgoAAMJI39f5omddVUa83tazWfQMAJBchJG+Lk43zfr3DkrqfJ2RyL7IzrBh0TMAQHIRRvq86AGsxhj974p3JXV+o7z2+1hnBACQbISRvq5DZSTcLlPcO3Nsp6e1VkZCZBAAQJIRRtyiXWWkVenwQZ0e3lo0MYwVAQAkGWGkzzOdvvJ0cRO81m6acJgBrACA5CKM9HUdumlMdBrplDWANTmtAgDAQhjp8zoMYG1X4ehqnRGvt8MYEwawAgCShDDS13VRGelq0q7PEzvgFQCAZCCMuEWcMkhnd+2V2hY9C1v9NKQSAEByEEb6vA4DWE8xU/RLS4lzNgAAPY8w0td17KZpP2aki9MG+FP0D6WFcX4OAAA9izDS57UOYG151X7MyElWep8+Lk+my8gCAMDpI4z0dTGVkTZdrTPSdgYAAMlFGHGLOCuwnqwy4uWvAwBgA75u+rzOV2A9GY/HQzcNACDpCCN9nZU+4k3t7frUqN0MYAUAJAlhpM/rsAJr1KJnXacRr8fD1F4AQNIRRvq6DgNYlcBsGm/UAcQSAEByEEbcIt69aU7hFMaMAACSLcXpBiDZjPan+PTMpxt0Yv0RDRvwBUmDJHW9HHxkf/sfQ2UEAJAchJE+zoTD+pecM7Sz7h2p7h1Jkjf9NoVPDIuqeYRNWNsObtNA/0ANzxouKTKmhMoIACDZ6Kbp415o/kQ7/WlR2/oXL5IUiqp8PLn9Sd208iZd/cLV2lu3V5LkJYcAAGxAGOnj9odPWM/nnD+nbYcnGNVNsy+wz3r+tRe/pmA4KK+XAawAgOQjjPRx4ZZ/Zw06V7eW3Nq2wxMdLhqDjVGvP6z7UB4RQQAAyUcY6ePCLXHCK09UJcTTIYzsPLwz6nXQRFdOGMAKAEgWwkhfZozC9TWSJG/L/7XbaT176YOX9GHgw6hTg+Fgy5gRBo4AAJKLMNKX7f5vhRsDkiSv1yuvp+3X3b4y8kHdB9bzjJQMSZEw4mHRMwCADQgjfdln+xRqqWx4h4zq0E3TdlgwHJQk3Xz2zcrrnydJag43y+shggAAko8w0peFmhVuCR2+jJaFzlrCSfu7zrSGkRRvilK8kaVn9tfvV9gE234WY0YAAEnComd9WbjZmk3TWhXxeLwyJhTVTWOFEU+KUr2pkqSfrf+ZzsoaqzM0LvKjjCG5AgCSgu+XvizUrHBLJcTn8UmKzKqRpLS8P+rbf/q2/vLhXxQMBzW4oUC+VcN1xYc3a0jqUEnSvvr3rB9V/dlxmxsPAHALKiN9Wbtumtf2HFJq/V55PF7JSN7+u7XzsDRv7TxJ0pTa66UDmWqS9OhtS/WPldco1K6bpjkYjvMGAACcPiojfZEx0vr/K+1ZpVDLpjffP6J//dMONYdiQ8WQhgKdfeAi63W4MdKFY2R0wwXD7GgxAMDFqIz0Rcv/Sdr2n5IkM3RI5N+W7hljddy0GXH43KjXVVvrpJbb2YStUScMYAUAJAeVkb6m/hMriHzi8+lPmf0lSSne1l91W6j4yQU/kST5THQm/XDzYfVvHBg5mjXPAABJRhjpa5qPabPfr2eyBuiWMaXW5svO+qLystKjZtH0T4sEFW848mcw5EjbkvATPrpSUqSSopZnAAAkA2Gkj6lrDOj7+Tl6cMhgVR+rlSQFj43QMP+FSk2JLnMM9A+UJHlNZKbNgECVBh3ZLUkae2CS+jcOVKg1hJBFAABJQhjpY+qbjyro8chrjKaPmK4RaZfpRPX1SvV5leaL/nVfkHeBZp09S1/IGiVJ8piQRu9+1tr/D2//UE8d/XPLK9IIACA5CCN9jAlH5s+kG+mhSx/S+Rn/QyY4SF6vRxlpvqhjU32p+uHEH2pCzkRJkTDS78RBFX60WpLkD2aoOvSpvR8AAOA6hJE+JmwiYaT1FxtqWcbd5/Ho7iu+qHSTL0nK7ZcrSar79Lh2vP5x5JyWIFP84X+3/AyfAqFjOuj1UhcBACQNU3v7mHBLoPBYryMxIsXn0dSxufrzsN9p8yebNT5nvCRp/45D1rn9Gz5WxvjxCr69w9rmC6foF0MH684jxBEAQHJQGWkvHJbCodhHb2O1M3YBM9OhMhJsCSPelnvT5PbP1cyRM5U/IFIhaW6K/IyBn+3R0MPvaNhTS5U+vND6eYV1X9SnvujuHQAAehKVkRa733hEj295RI0dOiRS5NHNo6/Xl6Y+4FDLOti/UVp2ndQYkLyp0vW/k0bPsHa3hpHWysjx5shrXyexs/5g5J4z/Y59oiE/+L68fr9GPP4b6ReRWTUX7/2mNpVsEQNYAQDJQhhpsez9F/SX/hlx9534qEKL1TvCSHDvWr3pbVKgfz9J0sAXbtEFN74kb1FkEGr7MSOVVUf00ts1kdee2NXL9m0/pG1rqyP7w03ypA2WJPkGDdKYXcu0a8xNymwaoqz6syXt77RNuw7v0t66vXH3fXHQF3XWwLO69VkBAO5AGGnR0BiQfNJVmV/UxC9+XZK0Y+8r+s/DlTpuek9XzVPV7+hXeTlR2/7PW4/ritYw0tqtZKTnNrYFiIkjBked0/BZo/7867es1zmfbpXHH/ncHr9fOZ9u0a4xN0mSzttzpVT4WNz2HDx+UDf8+QYF291Ur72MlAyt+fYa9Uvtl8CnBAC4CWFEkrb9UY2NdVK/DF0waIy+UTJLkjQwUKv/PFypoOk9XRRVJwKSVxoQ9Cks6VhKSLXvrpQ+/Js04mIdb26OHGiMnt8UCSO3Xlys84oGRv2czw4cs56f99b/1cC695U+7mxJksfn04Cxo3TW+y/q/bOuVcaJNP0947BGxmlPbUOtgiYov8+v8884P2rfxtqNOh48rkBTgDACAOgUYURSzUfrta5fpIsmLXectT3VlypJCip2oKhTWm9cd1bDAO3TUB3Lfl9NHklPzZT+5V0FjjdKkjzy6NzCbPVL8+lb5wxVoKJC5kSj/F84S5/5C7Tt+TclpSmzvkpDjuzSoBtv1ICLL7beZ8Rzv1f9Eyv0fqXkkU9vZHh1/d+fkCZ+L6o9S7cvlSQVDijUb6f/NmrfxGUTdSJ0QqFeVFkCAPQ+hBFJyxv2Wc/PGPQF63mKN3Lr2uZeNHgzbCJhJNOfpgPHhyhN76u5dTzIofcUDLeNGVkxd7IkqfaXv1T107+TJJnUNL3+lV+puTHy2VKaG5T3i/uVNWNm1Pt4UlLUPz9fqjwuoxQFJenAzqhjGpobtGrfKklSTr/oriNJ8noio2bDcWb9AADQijAiqSHcJEkq8g3QhLwJ1vZUX+QLO9gLw0iaz6ezhmZrf0iqSxsqKSAFjysUiq5C1K9ZoyMtQUSSQmGPmhsjPyO/5m/60q2XadDXL4n7Xin+VEnHFUw7QymNHikcPS6kMdRoPc/bVaj/2Plw1P7gwMj7UBkBAHSFMCIp2PJlOaP/cOu/5iUpJcUvSfrAa7TqvT9p2heucaR97WXUNeqHq0MqPP6pTnjfVL03pN9ON/quz6szqrco5B0kX8hoYMCo+ZNPdPTV1TLy6Gj/Ahlvig4OOSfyg0xYJXWvasTX/2en75UyoJ+kgIzXp3Mqr5JGRoeRYDioc2ouVUFgpCY1HJd0PGr/h4O/oteGr7QCFAAA8RBG1BZGUrzRl2NE5nDr+V83L+oVYWTErqOauMdIamx5SI/8JqS3ruunK1Y/oNSxN+uRJSGdEZD2/OYy1eZ+WTsv+3XMz0kJnlBqbmzXSnu5E0dLv6tteTVcCu+J2n/gk8O6+MNvSpI+iHP+uBppxxlbqYwAALrUrRVYFy1apOLiYqWnp6u0tFSvvfZal8evXbtWpaWlSk9P18iRI7VkyZJuNTZZgiaslFCavJ8U692Ntdbj0wOjdPuHo5QWzFBzc4PTzZQk+ZojVYaPRmRo74VXWNvPLM9SsNGjIVv/oDMCkW0Hc8/XzrG3xP05521bpKLFi7t8r5Q0n/rntIwTMT4p3By1v6HmE0mSJ9ysL777XNQjrbFOkpR7JEOhE3UJf04koOGg9PffShsWSW/+Rqr7yOkWAUBCEq6MPP/887rrrru0aNEiXXzxxfrNb36jGTNmaMeOHRo2bFjM8Xv37tXMmTP1gx/8QMuWLdPf/vY33XbbbTrjjDN03XXX9ciHOF3BoFf/X+VPFWzOVMWWHR32ztUlTZvVPOZFJ5oWwxPyqjZ3omryBmvg12/TC8279Y3NkSm8e17Il5kZ+eKvz/BowL0PSi+8L0m6/OYx8vo82vT4GmXXvK0zhnqUMnhwp+9jSY3k1fTGFDUGjsnfbte7q45LSlNK8ITGfXlI1GnVHwXU5M/W8M9G60TD4dP+3OjE8SPS/+qwqNx7r0g3/sH2poTDRm/uPazDDU0x+zweacKIQcrJTLe9XQB6v4TDyMMPP6zvfe97+v73vy9JWrhwof7yl79o8eLFWrBgQczxS5Ys0bBhw7Rw4UJJ0tixY7Vp0yY99NBDvSKMvPvpHmX//Z/UrznT2lZQGJnS+/FHkUrAqEOlqjqw25H2ddTk/ZJ2jI1ct/q/fKTszB9rzXkP6LK3InfeDdWnaPP5d6s+s0j6r0jnyTmXF+rsiwskSaPGztTx7cOUMe5Hp/R+nv6RL4+wN1UbX3lfl3w3st0Yo0BNquSRUpuPqODB6N+97zv/T5I0vH66Pj1wWPqCkAwbHpUkhYxPrTcBCB2pVpoDTVnz7gHd+tSmLo957Z7LVTSYNWcARPMYc+orejU1Nalfv376wx/+oG984xvW9jvvvFNbt27V2rVrY86ZMmWKxo8fr1/96lfWthdeeEHf/va3dezYMaWmpsac09jYqMbGtpkagUBARUVFqqurU1ZW1il/uJN5+l/uU+DoZHk8kf/e9wVPaPL6H8nXMmukKXWAXr/4363jMxpf77H37i4TKtSJfiNitg898KrSm6SDg/N1ot/YqH3TvjdOoybmduv9/vbadm195oDSGuvUr36zGjNbvuaMR8fTI+uSDH93nq5+dUvUedvu+Q+tC0RmJvU/ulHh1Nj/Wsbp86pZJ1LHK+QdaG3zmBNKb+o6FCRDWEbhsJHH41H7uw8YEwmvrVK83J8T6I1yJw3VVf90W4/+zEAgoOzs7JN+fydUGTl48KBCoZByc6O/2HJzc1VbWxv3nNra2rjHB4NBHTx4UPn5+THnLFiwQP/6r/+aSNO6pfngQHkyIkHEEw7q4g336tP0tgpJ3rEjKtn+uLaX/ECSdNw/OeltOlX9vH/VWVNu0bY1kfEBB3O+ErXfG2rQjQuuUKrfp4zM7v938sj8Qm3VATX5s9Xk/0rM/pTgMf3Ht/rr6g7bS35Zpi3feVZHBxSqYcCXu/3+SJzxpPeqv9WOmk9+CAAHHH7/Vcfeu1uzaTwdbrpmjInZdrLj421vNX/+fJWVlVmvWysjPc2fVyfPoTXymSYNS92vVx94TE0Z7ZKbMTpzwyplVv+3gop/Ez0neFJDmnrnjcopLFb/gWlqPhHSvl2b1PDeDklG3tR0jftmqbKGnn6b80Zm64JrC/T2ij9KTbHVjQP5Ad095X/FtjElRTmXHlPozTWn3QZ0zcircIpPuVnv6/BnZygcdvZvNdXnVbz/aQdDRuFedGsFANFyxgw/+UFJklAYGTp0qHw+X0wV5MCBAzHVj1Z5eXlxj09JSdGQIUPinuP3++X3++Pu60k3/fu/Rb2+PN5BV46Nt7XXKL1yhCTpQiXnzrger0cTrhyjCVf+JOFzZ/xgtvSDJDQKANCnJNR5m5aWptLSUlVUVERtr6io0EUXXRT3nEmTJsUcv2rVKk2YMCHueBEAAOAuCY8kKysr029/+1s9+eST2rlzp+6++25VVVVp9uzZkiJdLLNmzbKOnz17tvbt26eysjLt3LlTTz75pJ544gnNmzev5z4FAAD43Ep4zMj111+vQ4cO6f7771dNTY1KSkq0cuVKDR8e6WuqqalRVVWVdXxxcbFWrlypu+++W48++qgKCgr0yCOP9IppvQAAwHkJTe11yqlODQIAAL3HqX5/M+EfAAA4ijACAAAcRRgBAACOIowAAABHEUYAAICjCCMAAMBRhBEAAOAowggAAHAUYQQAADgq4eXgndC6SGwgEHC4JQAA4FS1fm+fbLH3z0UYqa+vlyQVFRU53BIAAJCo+vp6ZWdnd7r/c3FvmnA4rI8//liZmZnyeDw99nMDgYCKioq0f/9+7nmTZFxre3Cd7cF1tgfX2R7JvM7GGNXX16ugoEBeb+cjQz4XlRGv16vCwsKk/fysrCz+0G3CtbYH19keXGd7cJ3tkazr3FVFpBUDWAEAgKMIIwAAwFGuDiN+v18/+9nP5Pf7nW5Kn8e1tgfX2R5cZ3twne3RG67z52IAKwAA6LtcXRkBAADOI4wAAABHEUYAAICjCCMAAMBRrg4jixYtUnFxsdLT01VaWqrXXnvN6Sb1WgsWLNDEiROVmZmpnJwcXXvttdq9e3fUMcYY/fznP1dBQYEyMjJ02WWX6Z133ok6prGxUbfffruGDh2q/v3762tf+5o++uijqGOOHDmim2++WdnZ2crOztbNN9+szz77LNkfsVdasGCBPB6P7rrrLmsb17lnVFdX66abbtKQIUPUr18/nX/++dq8ebO1n+t8+oLBoH7yk5+ouLhYGRkZGjlypO6//36Fw2HrGK5z96xbt07XXHONCgoK5PF49OKLL0btt/O6VlVV6ZprrlH//v01dOhQ3XHHHWpqakrsAxmXeu6550xqaqp5/PHHzY4dO8ydd95p+vfvb/bt2+d003ql6dOnm6VLl5rt27ebrVu3mquuusoMGzbMHD161DrmwQcfNJmZmaa8vNxs27bNXH/99SY/P98EAgHrmNmzZ5szzzzTVFRUmC1btpjLL7/cnHfeeSYYDFrHXHnllaakpMSsX7/erF+/3pSUlJirr77a1s/bG2zcuNGMGDHCnHvuuebOO++0tnOdT9/hw4fN8OHDzXe+8x3z5ptvmr1795pXXnnFvPfee9YxXOfT92//9m9myJAh5s9//rPZu3ev+cMf/mAGDBhgFi5caB3Dde6elStXmvvuu8+Ul5cbSeaFF16I2m/XdQ0Gg6akpMRcfvnlZsuWLaaiosIUFBSYuXPnJvR5XBtGvvzlL5vZs2dHbRszZoz58Y9/7FCLPl8OHDhgJJm1a9caY4wJh8MmLy/PPPjgg9YxJ06cMNnZ2WbJkiXGGGM+++wzk5qaap577jnrmOrqauP1es3LL79sjDFmx44dRpJ54403rGM2bNhgJJldu3bZ8dF6hfr6ejNq1ChTUVFhLr30UiuMcJ17xo9+9CMzefLkTvdznXvGVVddZW699daobd/85jfNTTfdZIzhOveUjmHEzuu6cuVK4/V6TXV1tXXM73//e+P3+01dXd0pfwZXdtM0NTVp8+bNmjZtWtT2adOmaf369Q616vOlrq5OkjR48GBJ0t69e1VbWxt1Tf1+vy699FLrmm7evFnNzc1RxxQUFKikpMQ6ZsOGDcrOztYFF1xgHXPhhRcqOzvbVb+bOXPm6KqrrtIVV1wRtZ3r3DNWrFihCRMm6Fvf+pZycnI0fvx4Pf7449Z+rnPPmDx5sv7617/q3XfflSS99dZbev311zVz5kxJXOdksfO6btiwQSUlJSooKLCOmT59uhobG6O6PU/mc3GjvJ528OBBhUIh5ebmRm3Pzc1VbW2tQ636/DDGqKysTJMnT1ZJSYkkWdct3jXdt2+fdUxaWpoGDRoUc0zr+bW1tcrJyYl5z5ycHNf8bp577jlt2bJFf//732P2cZ17xgcffKDFixerrKxM9957rzZu3Kg77rhDfr9fs2bN4jr3kB/96Eeqq6vTmDFj5PP5FAqF9MADD+iGG26QxN9zsth5XWtra2PeZ9CgQUpLS0vo2rsyjLTyeDxRr40xMdsQa+7cuXr77bf1+uuvx+zrzjXteEy8493yu9m/f7/uvPNOrVq1Sunp6Z0ex3U+PeFwWBMmTNAvf/lLSdL48eP1zjvvaPHixZo1a5Z1HNf59Dz//PNatmyZnn32WY0bN05bt27VXXfdpYKCAt1yyy3WcVzn5LDruvbEtXdlN83QoUPl8/liUtuBAwdiEh6i3X777VqxYoVWr16twsJCa3teXp4kdXlN8/Ly1NTUpCNHjnR5zCeffBLzvp9++qkrfjebN2/WgQMHVFpaqpSUFKWkpGjt2rV65JFHlJKSYl0DrvPpyc/P19lnnx21bezYsaqqqpLE33NP+eEPf6gf//jH+sd//Eedc845uvnmm3X33XdrwYIFkrjOyWLndc3Ly4t5nyNHjqi5uTmha+/KMJKWlqbS0lJVVFREba+oqNBFF13kUKt6N2OM5s6dq+XLl+vVV19VcXFx1P7i4mLl5eVFXdOmpiatXbvWuqalpaVKTU2NOqampkbbt2+3jpk0aZLq6uq0ceNG65g333xTdXV1rvjdTJ06Vdu2bdPWrVutx4QJE3TjjTdq69atGjlyJNe5B1x88cUxU9PfffddDR8+XBJ/zz3l2LFj8nqjv2Z8Pp81tZfrnBx2XtdJkyZp+/btqqmpsY5ZtWqV/H6/SktLT73RpzzUtY9pndr7xBNPmB07dpi77rrL9O/f33z44YdON61X+ud//meTnZ1t1qxZY2pqaqzHsWPHrGMefPBBk52dbZYvX262bdtmbrjhhrhTyQoLC80rr7xitmzZYr7yla/EnUp27rnnmg0bNpgNGzaYc845p09P0TuZ9rNpjOE694SNGzealJQU88ADD5g9e/aYZ555xvTr188sW7bMOobrfPpuueUWc+aZZ1pTe5cvX26GDh1q7rnnHusYrnP31NfXm8rKSlNZWWkkmYcffthUVlZay1PYdV1bp/ZOnTrVbNmyxbzyyiumsLCQqb2JePTRR83w4cNNWlqa+dKXvmRNU0UsSXEfS5cutY4Jh8PmZz/7mcnLyzN+v99MmTLFbNu2LernHD9+3MydO9cMHjzYZGRkmKuvvtpUVVVFHXPo0CFz4403mszMTJOZmWluvPFGc+TIERs+Ze/UMYxwnXvGn/70J1NSUmL8fr8ZM2aMeeyxx6L2c51PXyAQMHfeeacZNmyYSU9PNyNHjjT33XefaWxstI7hOnfP6tWr4/7/5FtuucUYY+913bdvn7nqqqtMRkaGGTx4sJk7d645ceJEQp/HY4wxp15HAQAA6FmuHDMCAAB6D8IIAABwFGEEAAA4ijACAAAcRRgBAACOIowAAABHEUYAAICjCCMAAMBRhBEAAOAowggAAHAUYQQAADiKMAIAABz1/wN54kdExDHqJwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#let's find some values that may be masked, focusing on the first 5 cell types\n",
    "import matplotlib.pyplot as plt\n",
    "s = 190_000\n",
    "e = s+10_000\n",
    "#now plot the first 5 rows of the masked\n",
    "plt.figure()\n",
    "for i in range(5):\n",
    "    plt.plot(acc_masked[i, s:e].numpy(), label=f'Cell type {i}')\n",
    "    \n",
    "#now on a new plot plot the masks\n",
    "#make a new figure\n",
    "plt.figure()\n",
    "for i in range(5):\n",
    "    plt.plot(acc_masked[i+674, s:e].numpy(), label=f'Cell type {i} mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a31aed87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0103, 0.0000, 0.0071],\n",
       "        [0.0000, 0.0000, 0.0103, 0.0000, 0.0071],\n",
       "        [0.0000, 0.0000, 0.0103, 0.0000, 0.0071],\n",
       "        [0.0000, 0.0000, 0.0103, 0.0000, 0.0071],\n",
       "        [0.0000, 0.0000, 0.0103, 0.0000, 0.0071],\n",
       "        [0.0000, 0.0000, 0.0103, 0.0000, 0.0071],\n",
       "        [0.0000, 0.0000, 0.0103, 0.0000, 0.0071],\n",
       "        [0.0000, 0.0000, 0.0103, 0.0000, 0.0071],\n",
       "        [0.0000, 0.0000, 0.0103, 0.0000, 0.0071],\n",
       "        [0.0000, 0.0000, 0.0103, 0.0000, 0.0071],\n",
       "        [0.0000, 0.0000, 0.0103, 0.0000, 0.0071],\n",
       "        [0.0000, 0.0000, 0.0103, 0.0000, 0.0071],\n",
       "        [0.0000, 0.0000, 0.0103, 0.0000, 0.0071],\n",
       "        [0.0000, 0.0000, 0.0103, 0.0000, 0.0071],\n",
       "        [0.0000, 0.0000, 0.0103, 0.0000, 0.0071],\n",
       "        [0.0000, 0.0000, 0.0103, 0.0000, 0.0071],\n",
       "        [0.0000, 0.0000, 0.0103, 0.0000, 0.0071],\n",
       "        [0.0000, 0.0000, 0.0103, 0.0000, 0.0071],\n",
       "        [0.0000, 0.0000, 0.0103, 0.0000, 0.0071],\n",
       "        [0.0000, 0.0000, 0.0103, 0.0000, 0.0071],\n",
       "        [0.0000, 0.0732, 0.0618, 0.0050, 0.0142],\n",
       "        [0.0000, 0.0732, 0.0618, 0.0050, 0.0142],\n",
       "        [0.0000, 0.0732, 0.0618, 0.0050, 0.0142],\n",
       "        [0.0000, 0.0732, 0.0618, 0.0050, 0.0142],\n",
       "        [0.0000, 0.0732, 0.0618, 0.0050, 0.0142],\n",
       "        [0.0000, 0.0732, 0.0618, 0.0050, 0.0142],\n",
       "        [0.0000, 0.0732, 0.0618, 0.0050, 0.0142],\n",
       "        [0.0000, 0.0732, 0.0618, 0.0050, 0.0142],\n",
       "        [0.0000, 0.0732, 0.0618, 0.0050, 0.0142],\n",
       "        [0.0000, 0.0732, 0.0618, 0.0050, 0.0142],\n",
       "        [0.0000, 0.0732, 0.0618, 0.0050, 0.0142],\n",
       "        [0.0000, 0.0732, 0.0618, 0.0050, 0.0142],\n",
       "        [0.0000, 0.0732, 0.0618, 0.0050, 0.0142],\n",
       "        [0.0000, 0.0732, 0.0618, 0.0050, 0.0142],\n",
       "        [0.0000, 0.0732, 0.0618, 0.0050, 0.0142],\n",
       "        [0.0000, 0.0732, 0.0618, 0.0050, 0.0142],\n",
       "        [0.0000, 0.0732, 0.0618, 0.0050, 0.0142],\n",
       "        [0.0000, 0.0732, 0.0618, 0.0050, 0.0142],\n",
       "        [0.0000, 0.0732, 0.0618, 0.0050, 0.0142],\n",
       "        [0.0000, 0.0732, 0.0618, 0.0050, 0.0142],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213],\n",
       "        [0.0000, 0.0952, 0.0927, 0.0050, 0.0213]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we see around 190000, the mask differs, let's check\n",
    "acc_masked[:5, 190000:190100].t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73b8a330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_masked[674:674+5, 189999:190100].t() #ahh here we see a separate independent mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6fea6037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_masked[674:674+100,190_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "034a1f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0952, 0.0927, 0.0050, 0.0213, 0.0363, 0.0230, 0.0524, 0.0378,\n",
       "        0.0404, 0.0257, 0.0409, 0.0457, 0.1179, 0.1130, 0.0251, 0.0972, 0.0504,\n",
       "        0.0000, 0.0404, 0.0436, 0.0689, 0.1102, 0.0638, 0.0000, 0.0412, 0.0000,\n",
       "        0.1538, 0.0481, 0.0000, 0.0635, 0.0614, 0.0166, 0.0116, 0.0078, 0.0131,\n",
       "        0.0773, 0.0628, 0.0505, 0.1544, 0.0075, 0.0648, 0.0000, 0.0591, 0.0203,\n",
       "        0.0476, 0.0106, 0.0057, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0229, 0.0465, 0.0000, 0.0000, 0.0000, 0.0821, 0.0465, 0.0203, 0.0274,\n",
       "        0.0000, 0.0000, 0.0000, 0.0064, 0.0000, 0.0341, 0.0379, 0.0415, 0.0134,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0101, 0.0000, 0.0221, 0.0072, 0.0223,\n",
       "        0.0000, 0.0000, 0.0031, 0.0130, 0.0032, 0.0000, 0.0000, 0.0000, 0.0026,\n",
       "        0.0000, 0.0300, 0.0164, 0.0000, 0.0232, 0.0119, 0.0306, 0.0000, 0.0000,\n",
       "        0.0358, 0.0042, 0.0174, 0.0000, 0.0193, 0.0246, 0.0210, 0.0139, 0.0000,\n",
       "        0.0305, 0.0158, 0.0067, 0.0170, 0.0000, 0.0000, 0.0000, 0.0520, 0.0231,\n",
       "        0.0000, 0.0066, 0.0000, 0.0150, 0.0085, 0.0230, 0.0056, 0.0155, 0.0103,\n",
       "        0.0000, 0.0119, 0.0000, 0.0159, 0.0000, 0.0520, 0.0713, 0.0044, 0.0486,\n",
       "        0.0085, 0.0148, 0.1088, 0.0177, 0.0000, 0.0000, 0.0576, 0.0185, 0.0000,\n",
       "        0.0083, 0.0000, 0.0000, 0.0111, 0.0124, 0.0052, 0.0109, 0.0000, 0.0334,\n",
       "        0.0000, 0.0000, 0.0070, 0.0188, 0.0119, 0.1142, 0.0000, 0.0000, 0.0000,\n",
       "        0.0595, 0.0316, 0.0000, 0.0582, 0.0291, 0.0000, 0.0543, 0.0286, 0.0000,\n",
       "        0.0000, 0.0253, 0.0000, 0.0039, 0.0359, 0.0566, 0.0685, 0.0000, 0.0000,\n",
       "        0.0320, 0.0113, 0.0354, 0.0113, 0.0408, 0.0000, 0.0511, 0.0000, 0.0000,\n",
       "        0.0000, 0.0073, 0.0000, 0.0781, 0.1281, 0.0000, 0.0864, 0.0000, 0.0269,\n",
       "        0.0779, 0.0000, 0.0000, 0.0199, 0.0417, 0.0000, 0.0000, 0.0000, 0.0228,\n",
       "        0.0298, 0.0626, 0.0751, 0.0313, 0.0326, 0.0000, 0.0000, 0.0205, 0.0319,\n",
       "        0.0000, 0.0000, 0.0181, 0.0303, 0.0000, 0.1866, 0.0000, 0.0000, 0.1383,\n",
       "        0.0430, 0.0679, 0.0439, 0.0000, 0.0308, 0.0385, 0.0069, 0.0978, 0.0131,\n",
       "        0.0820, 0.0167, 0.0919, 0.1095, 0.0706, 0.0000, 0.0000, 0.0179, 0.0000,\n",
       "        0.0534, 0.0723, 0.2158, 0.0321, 0.0000, 0.0500, 0.0267, 0.0506, 0.0486,\n",
       "        0.0000, 0.0000, 0.0000, 0.0122, 0.0000, 0.0493, 0.0321, 0.0000, 0.0100,\n",
       "        0.0000, 0.0000, 0.0000, 0.0165, 0.0604, 0.0568, 0.0000, 0.1046, 0.0060,\n",
       "        0.0237, 0.0000, 0.0359, 0.0133, 0.0000, 0.0090, 0.0330, 0.0744, 0.0102,\n",
       "        0.0523, 0.0458, 0.0052, 0.0581, 0.1223, 0.0051, 0.1753, 0.0447, 0.0000,\n",
       "        0.0141, 0.0995, 0.0206, 0.0114, 0.0000, 0.0401, 0.0000, 0.0264, 0.0247,\n",
       "        0.0354, 0.0053, 0.0000, 0.0372, 0.0344, 0.0000, 0.0346, 0.0000, 0.0000,\n",
       "        0.0704, 0.0286, 0.0000, 0.0292, 0.0698, 0.0429, 0.0000, 0.0220, 0.0000,\n",
       "        0.0180, 0.0000, 0.0301, 0.0262, 0.0000, 0.0000, 0.0000, 0.0121, 0.0457,\n",
       "        0.0338, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0538, 0.1586, 0.0104,\n",
       "        0.1635, 0.0000, 0.0884, 0.0110, 0.0189, 0.0000, 0.0580, 0.0409, 0.0000,\n",
       "        0.0772, 0.0000, 0.0663, 0.0548, 0.0000, 0.0565, 0.0356, 0.0000, 0.0451,\n",
       "        0.0282, 0.0000, 0.0082, 0.0430, 0.0193, 0.0120, 0.0278, 0.0000, 0.0035,\n",
       "        0.1064, 0.0237, 0.0622, 0.0062, 0.0000, 0.0000, 0.0209, 0.1182, 0.0361,\n",
       "        0.0068, 0.0000, 0.0992, 0.0000, 0.0394, 0.0232, 0.0000, 0.0000, 0.0095,\n",
       "        0.0309, 0.0089, 0.0079, 0.0196, 0.1445, 0.0276, 0.0000, 0.0397, 0.0000,\n",
       "        0.0000, 0.0201, 0.0000, 0.0141, 0.0000, 0.0580, 0.0964, 0.0727, 0.0305,\n",
       "        0.0000, 0.0000, 0.0517, 0.0884, 0.0000, 0.0070, 0.0456, 0.0292, 0.0000,\n",
       "        0.0291, 0.0000, 0.0000, 0.0164, 0.1312, 0.0074, 0.0760, 0.0000, 0.0000,\n",
       "        0.0000, 0.0224, 0.0442, 0.0381, 0.0274, 0.0000, 0.0387, 0.0162, 0.0000,\n",
       "        0.0368, 0.0000, 0.0058, 0.0362, 0.0245, 0.0486, 0.0332, 0.0675, 0.0459,\n",
       "        0.0381, 0.0311, 0.0294, 0.0000, 0.0380, 0.0000, 0.0286, 0.1141, 0.0000,\n",
       "        0.0000, 0.0669, 0.0029, 0.0470, 0.0705, 0.0376, 0.0356, 0.0654, 0.0000,\n",
       "        0.0411, 0.0000, 0.1005, 0.0000, 0.0000, 0.0562, 0.0577, 0.0000, 0.0291,\n",
       "        0.0000, 0.0000, 0.0349, 0.0177, 0.0600, 0.0269, 0.0263, 0.0074, 0.0373,\n",
       "        0.0451, 0.0140, 0.0406, 0.1715, 0.0837, 0.0222, 0.0000, 0.0976, 0.0829,\n",
       "        0.0258, 0.0000, 0.0928, 0.0267, 0.0000, 0.0571, 0.0000, 0.0098, 0.1149,\n",
       "        0.0681, 0.0225, 0.0000, 0.0262, 0.0270, 0.0024, 0.0257, 0.0789, 0.0378,\n",
       "        0.0620, 0.0000, 0.0000, 0.0599, 0.0087, 0.0000, 0.0542, 0.0262, 0.0191,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0499, 0.0000, 0.0192,\n",
       "        0.0308, 0.0268, 0.0809, 0.0192, 0.0000, 0.0446, 0.0509, 0.0000, 0.0144,\n",
       "        0.0281, 0.0048, 0.0100, 0.0848, 0.0160, 0.0350, 0.0000, 0.0000, 0.0000,\n",
       "        0.0346, 0.0000, 0.0140, 0.0961, 0.0000, 0.0000, 0.0162, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0174, 0.0180, 0.0694, 0.0087, 0.0320, 0.0000, 0.0000,\n",
       "        0.0000, 0.0470, 0.0062, 0.0784, 0.0446, 0.1022, 0.0000, 0.0724, 0.1975,\n",
       "        0.1472, 0.0077, 0.1027, 0.1144, 0.0135, 0.0794, 0.0402, 0.0000, 0.1366,\n",
       "        0.0390, 0.0259, 0.0000, 0.0069, 0.0792, 0.0075, 0.0000, 0.0609, 0.0000,\n",
       "        0.0790, 0.0206, 0.0061, 0.1157, 0.1510, 0.0000, 0.0000, 0.0801, 0.0351,\n",
       "        0.0000, 0.0095, 0.0000, 0.0210, 0.0358, 0.0514, 0.0269, 0.0452, 0.0258,\n",
       "        0.1490, 0.0275, 0.1015, 0.0522, 0.0065, 0.0000, 0.0303, 0.0164, 0.0021,\n",
       "        0.0000, 0.0496, 0.0000, 0.1748, 0.0572, 0.0367, 0.0342, 0.0000, 0.0269,\n",
       "        0.0148, 0.0000, 0.0718, 0.0000, 0.0365, 0.0000, 0.0420, 0.0243, 0.0115,\n",
       "        0.0000, 0.0340, 0.0415, 0.0142, 0.0125, 0.0000, 0.0493, 0.0000, 0.0207,\n",
       "        0.0304, 0.0000, 0.0113, 0.0000, 0.0051, 0.0958, 0.0000, 0.0000, 0.0000,\n",
       "        0.0220, 0.0071, 0.0157, 0.0218, 0.0351, 0.0255, 0.0435, 0.0000, 0.0688,\n",
       "        0.0000, 0.0214, 0.0000, 0.0690, 0.0573, 0.0327, 0.0062, 0.0264, 0.0216,\n",
       "        0.0511, 0.0406, 0.0238, 0.0699, 0.0000, 0.0401, 0.0000, 0.0706, 0.0982,\n",
       "        0.0479, 0.0327, 0.0680, 0.0249, 0.0622, 0.0356, 0.0000, 0.0501])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only the first cell type is seemingly masked\n",
    "#I think this makes sense and seemds to be working as expected!!\n",
    "\n",
    "acc_masked[:674,190000:190100].max(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd398a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0473, 0.0952, 0.0927, 0.0050, 0.0213, 0.0363, 0.0230, 0.0524, 0.0378,\n",
       "        0.0404, 0.0257, 0.0409, 0.0457, 0.1179, 0.1130, 0.0251, 0.0972, 0.0504,\n",
       "        0.0000, 0.0404, 0.0436, 0.0689, 0.1102, 0.0638, 0.0000, 0.0412, 0.0000,\n",
       "        0.1538, 0.0481, 0.0000, 0.0635, 0.0614, 0.0166, 0.0116, 0.0078, 0.0131,\n",
       "        0.0773, 0.0628, 0.0505, 0.1544, 0.0075, 0.0648, 0.0000, 0.0591, 0.0203,\n",
       "        0.0476, 0.0106, 0.0057, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0229, 0.0465, 0.0000, 0.0000, 0.0000, 0.0821, 0.0465, 0.0203, 0.0274,\n",
       "        0.0000, 0.0000, 0.0000, 0.0064, 0.0000, 0.0341, 0.0379, 0.0415, 0.0134,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0101, 0.0000, 0.0221, 0.0072, 0.0223,\n",
       "        0.0000, 0.0000, 0.0031, 0.0130, 0.0032, 0.0000, 0.0000, 0.0000, 0.0026,\n",
       "        0.0000, 0.0300, 0.0164, 0.0000, 0.0232, 0.0119, 0.0306, 0.0000, 0.0000,\n",
       "        0.0358, 0.0042, 0.0174, 0.0000, 0.0193, 0.0246, 0.0210, 0.0139, 0.0000,\n",
       "        0.0305, 0.0158, 0.0067, 0.0170, 0.0000, 0.0000, 0.0000, 0.0520, 0.0231,\n",
       "        0.0000, 0.0066, 0.0000, 0.0150, 0.0085, 0.0230, 0.0056, 0.0155, 0.0103,\n",
       "        0.0000, 0.0119, 0.0000, 0.0159, 0.0000, 0.0520, 0.0713, 0.0044, 0.0486,\n",
       "        0.0085, 0.0148, 0.1088, 0.0177, 0.0000, 0.0000, 0.0576, 0.0185, 0.0000,\n",
       "        0.0083, 0.0000, 0.0000, 0.0111, 0.0124, 0.0052, 0.0109, 0.0000, 0.0334,\n",
       "        0.0000, 0.0000, 0.0070, 0.0188, 0.0119, 0.1142, 0.0000, 0.0000, 0.0000,\n",
       "        0.0595, 0.0316, 0.0000, 0.0582, 0.0291, 0.0000, 0.0543, 0.0286, 0.0000,\n",
       "        0.0000, 0.0253, 0.0000, 0.0039, 0.0359, 0.0566, 0.0685, 0.0000, 0.0000,\n",
       "        0.0320, 0.0113, 0.0354, 0.0113, 0.0408, 0.0000, 0.0511, 0.0000, 0.0000,\n",
       "        0.0000, 0.0073, 0.0000, 0.0781, 0.1281, 0.0000, 0.0864, 0.0000, 0.0269,\n",
       "        0.0779, 0.0000, 0.0000, 0.0199, 0.0417, 0.0000, 0.0000, 0.0000, 0.0228,\n",
       "        0.0298, 0.0626, 0.0751, 0.0313, 0.0326, 0.0000, 0.0000, 0.0205, 0.0319,\n",
       "        0.0000, 0.0000, 0.0181, 0.0303, 0.0000, 0.1866, 0.0000, 0.0000, 0.1383,\n",
       "        0.0430, 0.0679, 0.0439, 0.0000, 0.0308, 0.0385, 0.0069, 0.0978, 0.0131,\n",
       "        0.0820, 0.0167, 0.0919, 0.1095, 0.0706, 0.0000, 0.0000, 0.0179, 0.0000,\n",
       "        0.0534, 0.0723, 0.2158, 0.0321, 0.0000, 0.0500, 0.0267, 0.0506, 0.0486,\n",
       "        0.0000, 0.0000, 0.0000, 0.0122, 0.0000, 0.0493, 0.0321, 0.0000, 0.0100,\n",
       "        0.0000, 0.0000, 0.0000, 0.0165, 0.0604, 0.0568, 0.0000, 0.1046, 0.0060,\n",
       "        0.0237, 0.0000, 0.0359, 0.0133, 0.0000, 0.0090, 0.0330, 0.0744, 0.0102,\n",
       "        0.0523, 0.0458, 0.0052, 0.0581, 0.1223, 0.0051, 0.1753, 0.0447, 0.0000,\n",
       "        0.0141, 0.0995, 0.0206, 0.0114, 0.0000, 0.0401, 0.0000, 0.0264, 0.0247,\n",
       "        0.0354, 0.0053, 0.0000, 0.0372, 0.0344, 0.0000, 0.0346, 0.0000, 0.0000,\n",
       "        0.0704, 0.0286, 0.0000, 0.0292, 0.0698, 0.0429, 0.0000, 0.0220, 0.0000,\n",
       "        0.0180, 0.0000, 0.0301, 0.0262, 0.0000, 0.0000, 0.0000, 0.0121, 0.0457,\n",
       "        0.0338, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0538, 0.1586, 0.0104,\n",
       "        0.1635, 0.0000, 0.0884, 0.0110, 0.0189, 0.0000, 0.0580, 0.0409, 0.0000,\n",
       "        0.0772, 0.0000, 0.0663, 0.0548, 0.0000, 0.0565, 0.0356, 0.0000, 0.0451,\n",
       "        0.0282, 0.0000, 0.0082, 0.0430, 0.0193, 0.0120, 0.0278, 0.0000, 0.0035,\n",
       "        0.1064, 0.0237, 0.0622, 0.0062, 0.0000, 0.0000, 0.0209, 0.1182, 0.0361,\n",
       "        0.0068, 0.0000, 0.0992, 0.0000, 0.0394, 0.0232, 0.0360, 0.0000, 0.0095,\n",
       "        0.0309, 0.0089, 0.0079, 0.0196, 0.1445, 0.0276, 0.0000, 0.0397, 0.0000,\n",
       "        0.0000, 0.0201, 0.0000, 0.0141, 0.0000, 0.0580, 0.0964, 0.0727, 0.0305,\n",
       "        0.0000, 0.0000, 0.0517, 0.0884, 0.0000, 0.0070, 0.0456, 0.0292, 0.0000,\n",
       "        0.0291, 0.0000, 0.0000, 0.0164, 0.1312, 0.0074, 0.0760, 0.0000, 0.0000,\n",
       "        0.0000, 0.0224, 0.0442, 0.0381, 0.0274, 0.0000, 0.0387, 0.0162, 0.0000,\n",
       "        0.0368, 0.0000, 0.0058, 0.0362, 0.0245, 0.0486, 0.0332, 0.0675, 0.0459,\n",
       "        0.0381, 0.0311, 0.0294, 0.0000, 0.0380, 0.0000, 0.0286, 0.1141, 0.0000,\n",
       "        0.0000, 0.0669, 0.0029, 0.0470, 0.0705, 0.0376, 0.0356, 0.0654, 0.0000,\n",
       "        0.0411, 0.0000, 0.1005, 0.0000, 0.0000, 0.0562, 0.0577, 0.0000, 0.0291,\n",
       "        0.0000, 0.0000, 0.0349, 0.0177, 0.0600, 0.0269, 0.0263, 0.0074, 0.0373,\n",
       "        0.0451, 0.0140, 0.0406, 0.1715, 0.0837, 0.0222, 0.0000, 0.0976, 0.0829,\n",
       "        0.0258, 0.0000, 0.0928, 0.0267, 0.0000, 0.0571, 0.0000, 0.0098, 0.1149,\n",
       "        0.0681, 0.0225, 0.0000, 0.0262, 0.0270, 0.0024, 0.0257, 0.0789, 0.0378,\n",
       "        0.0620, 0.0000, 0.0000, 0.0599, 0.0087, 0.0000, 0.0542, 0.0262, 0.0191,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0499, 0.0000, 0.0192,\n",
       "        0.0308, 0.0268, 0.0809, 0.0192, 0.0000, 0.0446, 0.0509, 0.0000, 0.0144,\n",
       "        0.0281, 0.0048, 0.0100, 0.0848, 0.0160, 0.0350, 0.0000, 0.0000, 0.0000,\n",
       "        0.0346, 0.0000, 0.0140, 0.0961, 0.0000, 0.0000, 0.0162, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0174, 0.0180, 0.0694, 0.0087, 0.0320, 0.0000, 0.0000,\n",
       "        0.0000, 0.0470, 0.0062, 0.0784, 0.0446, 0.1022, 0.0000, 0.0724, 0.1975,\n",
       "        0.1472, 0.0077, 0.1027, 0.1144, 0.0135, 0.0794, 0.0402, 0.0000, 0.1366,\n",
       "        0.0390, 0.0259, 0.0000, 0.0069, 0.0792, 0.0075, 0.0000, 0.0609, 0.0000,\n",
       "        0.0790, 0.0206, 0.0061, 0.1157, 0.1510, 0.0000, 0.0000, 0.0801, 0.0351,\n",
       "        0.0000, 0.0095, 0.0000, 0.0210, 0.0358, 0.0514, 0.0269, 0.0452, 0.0258,\n",
       "        0.1490, 0.0275, 0.1015, 0.0522, 0.0065, 0.0000, 0.0303, 0.0164, 0.0021,\n",
       "        0.0000, 0.0496, 0.0000, 0.1748, 0.0572, 0.0367, 0.0342, 0.0000, 0.0269,\n",
       "        0.0148, 0.0000, 0.0718, 0.0000, 0.0365, 0.0000, 0.0420, 0.0243, 0.0115,\n",
       "        0.0000, 0.0340, 0.0415, 0.0142, 0.0125, 0.0000, 0.0493, 0.0000, 0.0207,\n",
       "        0.0304, 0.0000, 0.0113, 0.0000, 0.0051, 0.0958, 0.0000, 0.0000, 0.0000,\n",
       "        0.0220, 0.0071, 0.0157, 0.0218, 0.0351, 0.0255, 0.0435, 0.0000, 0.0688,\n",
       "        0.0000, 0.0214, 0.0000, 0.0690, 0.0573, 0.0327, 0.0062, 0.0264, 0.0216,\n",
       "        0.0511, 0.0406, 0.0238, 0.0699, 0.0000, 0.0401, 0.0000, 0.0706, 0.0982,\n",
       "        0.0479, 0.0327, 0.0680, 0.0249, 0.0622, 0.0356, 0.0000, 0.0501])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's see the unmasked\n",
    "acc_unmask.t()[:674,190000:190100].max(1).values #matches for all but the ones that are masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35da292f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see which ones are masked\n",
    "acc_unmask.t()[674:,190000:190100].max(1).values #seems to match exactly where the mask is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30579ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1348, 524288]), torch.Size([524288, 1348]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_masked.shape, acc_unmask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f0ecf87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#some are truly zero, but that's really fine! I think this is good!\n",
    "#let's double check to see that the masks match\n",
    "torch.allclose(acc_masked[674:, :].t(), acc_unmask[:, 674:]) #should be true, and it is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11524a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#definitely seems fine to me, so long as we can give the right parameters and specify mask_only=True and mask_tie less than 1, seems to work well\n",
    "#then we just have to make sure the encoder has the right number of channels, same with decoder. Should be 674*2 for encoder, 674 for decoder for accessibility. that's doutput2 for decoder and d_input2 for encoder\n",
    "#shouldnl't need to add to dataloader?\n",
    "acc_masked.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4247221c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100000, 51]) torch.Size([100000, 51])\n"
     ]
    }
   ],
   "source": [
    "#finally let's test for mask tie = 1\n",
    "def mask_seq(seq, mask_pct=0.15, replace_with_N=True, span=1, stype='category', weights=None, mask_only=False, mask_tie=1):\n",
    "    \"\"\"This function will mask the sequence data, it does the BERT masking where you do 80% truly masked, 10% random, 10% unchanged\n",
    "    Note that for random replacement, it cannot be the N token, sicne it's very rare anyways, always random nucleotide!\n",
    "    Args:\n",
    "        seq: the sequence to mask, this is a tensor of shape (length, N) if categorical, or (length,1) if continuous, N is the number of classes (5 for ohe nucleotide data)\n",
    "        mask_pct: the percentage of the sequence to mask, default is 0.15 or 15%\n",
    "        replace_with_N: whether to allow random replacement of values with N (for one hot encoded data). Keep True for other categorical data\n",
    "        span: the size of the span to mask, default is 1, so it masks every element independently, but can be larger to mask chunks of size span\n",
    "        stype: the type of sequence, 'category' for categorical like ohe nucleotide data and 'continuous' for continuous like raw accessibility data, default is 'category'\n",
    "        weights: the weights to use for weighting regions like peaks. default is None, must be a tensor of shape (length,) to weight the peaks higher for masking. can be the same as the seq itself\n",
    "        mask_only: whether to do the 10% unchanged and 10% random replacement, default is False. If True, will only do the 100% truly masked and leave the rest unchanged\n",
    "        mask_tie: how much masking is tied across categories. 1 means fully tied, so all tracks are masked the same, 0 means fully indepdendent masking across categories. If true, returns slightlly different values\n",
    "    Returns:\n",
    "        seq: the masked sequence, this is a tensor of shape (length, N+1) or N*2 if mask_tie is less than 1 if categorical or (length, 2) if continuous, where the last column is the mask track (only tells if masked, some are random or unchanged)\n",
    "        seq_unmask: the unmasked sequence, this is a tensor of shape (length, N+1) or N*2 if categorical or (length, 2), where the last column is the mask track (tells all elements that have been changed or goign to evaluate)\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(seq.shape) == 1: #if it's just a 1D tensor, we need to add a dimension for the mask track\n",
    "        seq = seq.unsqueeze(1) #so now it's shape length x 1, so we can concatenate other things\n",
    "    \n",
    "    extra_append = 0\n",
    "    if seq.shape[0]%span != 0:\n",
    "        #we append on values\n",
    "        remainder = seq.shape[0] % span\n",
    "        extra_append = span - remainder\n",
    "        seq = torch.cat([seq, torch.zeros((extra_append,seq.shape[1]), dtype=torch.float)]) #so now we can have a mask for every element in the span, so size length again\n",
    "    \n",
    "    num_elements = seq.shape[0]//span #chunks into chunks of size span\n",
    "\n",
    "    # Create a probability vector (one per token) and sample which tokens to mask\n",
    "    probability_matrix = torch.full((num_elements,), mask_pct) #size of length, defines for each element if we mask it or not\n",
    "    \n",
    "    #we can also weight peak regions more\n",
    "    if weights is not None:\n",
    "        assert mask_tie == 1, \"Weighting with weights is only supported for mask_tie=1 currently\"\n",
    "        weights = weights.squeeze()\n",
    "        assert weights.ndim == 1, f\"weights must be a 1D tensor, got {weights.shape}\"\n",
    "\n",
    "        #Trim weights to match the required size\n",
    "        if weights.shape[0] % span != 0:\n",
    "            #remove values until it is the right size\n",
    "            weights = weights[:num_elements*span]\n",
    "        \n",
    "        #compute mean over spans\n",
    "        weights = weights.view(num_elements, span).mean(1) #average the weights over the span, so now it's size length\n",
    "        \n",
    "        #normalize weights to have range 0.5 to 1.5\n",
    "        weights = torch.log(weights + 1) #log transform to reduce the scale of values\n",
    "        weights = (weights - weights.min()) / (weights.max() - weights.min()) + .5 #normalize to have different range, downweights small values, upweights large ones to almost 3x\n",
    "\n",
    "        #scale probability matrix by weights\n",
    "        probability_matrix = probability_matrix * weights #so now we have a weighted probability matrix, so we can mask more in peak regions\n",
    "        #and scale up probability matrix so that the mean is mask_pct\n",
    "        probability_matrix = probability_matrix / probability_matrix.mean() * mask_pct #so now we have a weighted probability matrix, so we can mask more in peak regions\n",
    "        \n",
    "        #clip to make sure between 0 and 1\n",
    "        probability_matrix = torch.clamp(probability_matrix, min=0, max=1) #clip to make sure between 0 and 1     \n",
    "    \n",
    "    masked_indices = torch.bernoulli(probability_matrix.float()).bool() #finds which indices to mask, so shape is length, and is True or False for each index\n",
    "\n",
    "    if mask_tie < 1: #have to implement own logic and loop, this is for the dependent tracks, otherwise unclear how to implement it, can make it like 0.999\n",
    "        assert mask_only, \"Not implemented for mask_only = False yet\"\n",
    "        extra = seq.shape[0] % span\n",
    "        #first replicate masked_indices to be of shape length x num_categories\n",
    "        masked_indices = masked_indices.unsqueeze(1).repeat(1, seq.shape[1])\n",
    "        all_expanded_masked_indices = torch.zeros((seq.shape[0], seq.shape[1]), dtype=torch.bool)\n",
    "        #now per row we need to randomly change some of the true and falses at the 1-mask_tie proportion\n",
    "        \n",
    "        #let's just loop over it. Not the best, I know, but it is the easiest\n",
    "        base_mask = masked_indices[:,0].clone()\n",
    "        num_masked = base_mask.sum().item()\n",
    "        true_indices = torch.nonzero(base_mask).squeeze()\n",
    "        false_indices = torch.nonzero(~base_mask).squeeze()\n",
    "        # mask_positions = torch.zeros((masked_indices.shape[1], num_masked*span), dtype=torch.long) #preallocate max size\n",
    "        q = 1-mask_tie\n",
    "        for i in range(masked_indices.shape[1]):\n",
    "            #now we find 10% of the true values and turn them to false, and then get the same amount and turn them from false to true\n",
    "            num_change = int(num_masked * q)\n",
    "            #randomly select num_change indices from true_indices and false_indices\n",
    "            true_change_indices = true_indices[torch.randperm(true_indices.numel())[:num_change]]\n",
    "            false_change_indices = false_indices[torch.randperm(false_indices.numel())[:num_change]]\n",
    "            #now set them\n",
    "            masked_indices[true_change_indices, i] = False\n",
    "            masked_indices[false_change_indices, i] = True\n",
    "            #also just do the steps to get all mask positions. This metric keeps the amount of true and false at least? then we also need to decide which ones are true mask which ones are random?\n",
    "            #for now we can make it work with mask_only = True, this way we ignore the other things\n",
    "            expanded_masked_indices = masked_indices[:,i].repeat_interleave(span)\n",
    "            # print(expanded_masked_indices, expanded_masked_indices.shape)\n",
    "            if extra > 0:\n",
    "                expanded_masked_indices = torch.cat([expanded_masked_indices, torch.zeros(extra, dtype=torch.bool)]) #so now we have a mask for every element in the span, so size length again\n",
    "            all_expanded_masked_indices[:,i] = expanded_masked_indices\n",
    "            \n",
    "            all_mask_positions = torch.nonzero(masked_indices[:,i]).squeeze()*span\n",
    "            # print(all_mask_positions, all_mask_positions.shape)\n",
    "            # mask_positions[i] = (all_mask_positions.unsqueeze(1) + torch.arange(span)).flatten()\n",
    "            # print(mask_positions[i], mask_positions[i].shape) #was a dict because the size changes depending on how many elements are masked. Although it should be a set value..., yeah don't need dict\n",
    "        \n",
    "        seq_unmask = torch.zeros((seq.shape[0], seq.shape[1]*2), dtype=torch.float)\n",
    "        seq_unmask[:, :seq.shape[1]] = seq\n",
    "        seq_unmask[:, seq.shape[1]:] = all_expanded_masked_indices.float()\n",
    "        seq_masked = seq_unmask.clone()\n",
    "        # seq_masked = torch.zeros((seq.shape[0], seq.shape[1]*2), dtype=torch.float) #this should be a faster way to clone\n",
    "        # seq_masked[:, :seq.shape[1]] = seq\n",
    "        # seq_masked[:, seq.shape[1]:] = all_expanded_masked_indices.float()\n",
    "        \n",
    "        # seq_unmask = torch.cat([seq, all_expanded_masked_indices.float()], dim=1)\n",
    "        # seq_masked = seq_unmask.clone()\n",
    "        num_channels = seq.shape[1]\n",
    "        seq_masked[:, :num_channels] = seq_masked[:, :num_channels] * (~all_expanded_masked_indices).float()\n",
    "        if span > 1 and extra_append > 0:\n",
    "            seq_masked = seq_masked[:-extra_append]\n",
    "            seq_unmask = seq_unmask[:-extra_append]\n",
    "        return seq_masked, seq_unmask #return the masked sequence and the unmasked sequence\n",
    "    \n",
    "\n",
    "    # Get positions that were chosen to be masked\n",
    "    all_mask_positions = torch.nonzero(masked_indices).squeeze()*span #squeeze to remove the extra dimension, and multiply by span to get the actual positions in the original sequence\n",
    "    num_masked = all_mask_positions.numel()\n",
    "    \n",
    "    # Determine counts for the three groups: 80% truly masked, 10% random, 10% unchanged\n",
    "    num_mask = int(0.8 * num_masked)\n",
    "    num_random = int(0.1 * num_masked)\n",
    "    # To avoid rounding issues, let the remaining be unchanged\n",
    "    # num_unchanged = num_masked - num_mask - num_random\n",
    "    \n",
    "    # Shuffle the masked positions to randomly assign each to a category\n",
    "    permuted = all_mask_positions[torch.randperm(num_masked)]\n",
    "    mask_positions = permuted[:num_mask]  # 80%: replace with mask token\n",
    "    random_positions = permuted[num_mask:num_mask+num_random]  # 10%: random token\n",
    "    unchanged_positions = permuted[num_mask+num_random:]  # 10%: leave as is\n",
    "\n",
    "    if span > 1:\n",
    "        masked_indices = masked_indices.repeat_interleave(span) #so now we have a mask for every element in the span, so size length again\n",
    "        #and append zeros until the size of seq\n",
    "        extra = seq.shape[0] % span\n",
    "        if extra > 0:\n",
    "            masked_indices = torch.cat([masked_indices, torch.zeros(extra, dtype=torch.bool)]) #so now we have a mask for every element in the span, so size length again\n",
    "        \n",
    "        #now for each of the positions, we need to expand and then make masking apply per index\n",
    "        mask_positions = (mask_positions.unsqueeze(1) + torch.arange(span)).flatten()\n",
    "        random_positions = (random_positions.unsqueeze(1) + torch.arange(span)).flatten()\n",
    "        unchanged_positions = (unchanged_positions.unsqueeze(1) + torch.arange(span)).flatten()\n",
    "        #and now they are grouped and we can just deal with them\n",
    "\n",
    "    # Append the mask track to the sequence, resulting in a tensor of shape [seq_len, 6], or [seq_len, 2] if acc data\n",
    "    # where the last column is the mask track\n",
    "    seq_unmask = torch.cat([seq, masked_indices.unsqueeze(1).float()], dim=1) #so now seq_unmask is shape length x 6, where 6 is the 5 one hot classes and the mask\n",
    "    \n",
    "    seq_masked = seq_unmask.clone()  # Create a copy to modify, note that the mask track should be 0 for ones where it's not masked but is random or unchanged\n",
    "    seq_masked[mask_positions, :-1] = 0  # Set to zero for every class but the last (tells it it's masked)\n",
    "    \n",
    "    if mask_only:\n",
    "        #now forcibly mask the rest\n",
    "        seq_masked[unchanged_positions, :-1] = 0  # Set to zero for every class but the last (tells it it's masked)\n",
    "        seq_masked[random_positions, :-1] = 0  # Set to zero for every class but the last (tells it it's masked)\n",
    "        if span > 1 and extra_append > 0:\n",
    "            seq_masked = seq_masked[:-extra_append]\n",
    "            seq_unmask = seq_unmask[:-extra_append]\n",
    "        # print(seq_masked.shape)\n",
    "        return seq_masked, seq_unmask #return the masked sequence and the unmasked sequence, so we can use it for the rest of the processing\n",
    "    \n",
    "    if stype == 'category':\n",
    "        # print(f'random_positions shape: {random_positions.shape}, seq shape: {seq.shape}')\n",
    "        if replace_with_N:\n",
    "            random_max = seq.shape[1]\n",
    "        else:\n",
    "            random_max = seq.shape[1] - 1\n",
    "        random_tokens = torch.randint(0, random_max, (random_positions.numel()//span,)) #generate random values for each position\n",
    "        random_one_hot = torch.zeros((random_positions.numel()//span, seq.shape[1])) #one hot encode them\n",
    "        random_one_hot.scatter_(1, random_tokens.unsqueeze(1), 1.0)\n",
    "        #now repeat with the span\n",
    "        random_one_hot = random_one_hot.repeat_interleave(span, dim=0) #so now we have a one hot for each position in the span\n",
    "        seq_masked[random_positions, :seq.shape[1]] = random_one_hot #assign them to the set positions\n",
    "        \n",
    "    elif stype == 'continuous':\n",
    "        #for accessibility, we will select random values from somewhere else in the sequence and then slightly shift and noise them\n",
    "        #get a random value between 0 and len(seq)-span\n",
    "        rand_start = torch.randint(0, seq.shape[0]-span, (random_positions.numel()//span,)) #definitely divisble by span since it was extended by size span\n",
    "        rand_idx = (rand_start.unsqueeze(1) + torch.arange(span)) #so now we have a random index for each of the random positions, and we can just select from there\n",
    "        rand_vals = seq.squeeze(1)[rand_idx] #get the values from the sequence at those random positions, so now we have a random value for each of the random positions\n",
    "        #and we can add some noise to it, so we can just add a small random value to it. Noise will be values between -0.1 and 0.1\n",
    "        rand_vals_mean = rand_vals.mean(1, keepdim=True) #get the mean of the random values for each position, keeps the dim so we can broadcast it\n",
    "        noise = torch.randn(rand_vals.shape) * rand_vals_mean * 0.1 #gaussian noise with std of 0.1 times the mean of the random values, so we can add some larger nosie to larger values\n",
    "        rand_vals = torch.clamp((rand_vals + noise).flatten(), min = 0) #make sure values are at least 0, else obvious there's noise in the region\n",
    "        #and now set the values\n",
    "        seq_masked[random_positions, 0] = rand_vals #set the values to the random values with noise, so now we have a random value for each of the random positions\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"stype must be either 'category' or 'continuous'\")\n",
    "    \n",
    "    #and remove the masked value, it doesn't know it's masked\n",
    "    seq_masked[random_positions, -1] = 0\n",
    "    \n",
    "    #and we remove the mask token from the unchanged value\n",
    "    seq_masked[unchanged_positions, -1] = 0\n",
    "    # seq = seq_masked #now we have the masked sequence, so we can use this for the rest of the processing\n",
    "\n",
    "    if span > 1 and extra_append > 0:\n",
    "        seq_masked = seq_masked[:-extra_append]\n",
    "        seq_unmask = seq_unmask[:-extra_append]\n",
    "    \n",
    "    return seq_masked, seq_unmask #return the masked sequence and the unmasked sequence, so we can use it for the rest of the processing\n",
    "\n",
    "seq = torch.ones((100_000,50))\n",
    "seq_masked, seq_unmask = mask_seq(seq, mask_pct=0.3, replace_with_N=True, span=10, stype='category', weights=None, mask_only=True, mask_tie=1)\n",
    "print(seq_masked.shape, seq_unmask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2347288",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's test it and make sure each row of seq_masked is the same\n",
    "for i in range(50):\n",
    "    assert torch.allclose(seq_masked[:,i], seq_masked[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79554328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#yeah, seems right?\n",
    "seq_masked[:40,-10:] #yeah it seems to work well!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83a165b",
   "metadata": {},
   "source": [
    "# some more updates\n",
    "\n",
    "change the way mask tie functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ab62a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "num_categories = 10\n",
    "seq = torch.ones((20,num_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fc38328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically mask tie will change the values of 1-mask_tie values, and unmask 10% of them\n",
    "import torch\n",
    "def mask_seq(seq, mask_pct=0.15, replace_with_N=True, span=1, stype='category', weights=None, mask_only=False, mask_tie=1):\n",
    "    \"\"\"This function will mask the sequence data, it does the BERT masking where you do 80% truly masked, 10% random, 10% unchanged\n",
    "    Note that for random replacement, it cannot be the N token, sicne it's very rare anyways, always random nucleotide!\n",
    "    Args:\n",
    "        seq: the sequence to mask, this is a tensor of shape (length, N) if categorical, or (length,1) if continuous, N is the number of classes (5 for ohe nucleotide data)\n",
    "        mask_pct: the percentage of the sequence to mask, default is 0.15 or 15%\n",
    "        replace_with_N: whether to allow random replacement of values with N (for one hot encoded data). Keep True for other categorical data\n",
    "        span: the size of the span to mask, default is 1, so it masks every element independently, but can be larger to mask chunks of size span\n",
    "        stype: the type of sequence, 'category' for categorical like ohe nucleotide data and 'continuous' for continuous like raw accessibility data, default is 'category'\n",
    "        weights: the weights to use for weighting regions like peaks. default is None, must be a tensor of shape (length,) to weight the peaks higher for masking. can be the same as the seq itself\n",
    "        mask_only: whether to do the 10% unchanged and 10% random replacement, default is False. If True, will only do the 100% truly masked and leave the rest unchanged\n",
    "        mask_tie: how much masking is tied across categories. 1 means fully tied, so all tracks are masked the same, 0 means fully indepdendent masking across categories. If true, returns slightlly different values\n",
    "    Returns:\n",
    "        seq: the masked sequence, this is a tensor of shape (length, N+1) or N*2 if mask_tie is less than 1 if categorical or (length, 2) if continuous, where the last column is the mask track (only tells if masked, some are random or unchanged)\n",
    "        seq_unmask: the unmasked sequence, this is a tensor of shape (length, N+1) or N*2 if categorical or (length, 2), where the last column is the mask track (tells all elements that have been changed or goign to evaluate)\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(seq.shape) == 1: #if it's just a 1D tensor, we need to add a dimension for the mask track\n",
    "        seq = seq.unsqueeze(1) #so now it's shape length x 1, so we can concatenate other things\n",
    "    \n",
    "    extra_append = 0\n",
    "    if seq.shape[0]%span != 0:\n",
    "        #we append on values\n",
    "        remainder = seq.shape[0] % span\n",
    "        extra_append = span - remainder\n",
    "        seq = torch.cat([seq, torch.zeros((extra_append,seq.shape[1]), dtype=torch.float)]) #so now we can have a mask for every element in the span, so size length again\n",
    "    \n",
    "    num_elements = seq.shape[0]//span #chunks into chunks of size span\n",
    "\n",
    "    # Create a probability vector (one per token) and sample which tokens to mask\n",
    "    probability_matrix = torch.full((num_elements,), mask_pct) #size of length, defines for each element if we mask it or not\n",
    "    \n",
    "    #we can also weight peak regions more\n",
    "    if weights is not None:\n",
    "        assert mask_tie == 1, \"Weighting with weights is only supported for mask_tie=1 currently\"\n",
    "        weights = weights.squeeze()\n",
    "        assert weights.ndim == 1, f\"weights must be a 1D tensor, got {weights.shape}\"\n",
    "\n",
    "        #Trim weights to match the required size\n",
    "        if weights.shape[0] % span != 0:\n",
    "            #remove values until it is the right size\n",
    "            weights = weights[:num_elements*span]\n",
    "        \n",
    "        #compute mean over spans\n",
    "        weights = weights.view(num_elements, span).mean(1) #average the weights over the span, so now it's size length\n",
    "        \n",
    "        #normalize weights to have range 0.5 to 1.5\n",
    "        weights = torch.log(weights + 1) #log transform to reduce the scale of values\n",
    "        weights = (weights - weights.min()) / (weights.max() - weights.min()) + .5 #normalize to have different range, downweights small values, upweights large ones to almost 3x\n",
    "\n",
    "        #scale probability matrix by weights\n",
    "        probability_matrix = probability_matrix * weights #so now we have a weighted probability matrix, so we can mask more in peak regions\n",
    "        #and scale up probability matrix so that the mean is mask_pct\n",
    "        probability_matrix = probability_matrix / probability_matrix.mean() * mask_pct #so now we have a weighted probability matrix, so we can mask more in peak regions\n",
    "        \n",
    "        #clip to make sure between 0 and 1\n",
    "        probability_matrix = torch.clamp(probability_matrix, min=0, max=1) #clip to make sure between 0 and 1     \n",
    "    \n",
    "    masked_indices = torch.bernoulli(probability_matrix.float()).bool() #finds which indices to mask, so shape is length, and is True or False for each index\n",
    "\n",
    "    if mask_tie < 1: #have to implement own logic and loop, this is for the dependent tracks, otherwise unclear how to implement it, can make it like 0.999\n",
    "        assert mask_only, \"Not implemented for mask_only = False yet\"\n",
    "        extra = seq.shape[0] % span\n",
    "        #first replicate masked_indices to be of shape length x num_categories\n",
    "        masked_indices = masked_indices.unsqueeze(1).repeat(1, seq.shape[1])\n",
    "        all_expanded_masked_indices = torch.zeros((seq.shape[0], seq.shape[1]), dtype=torch.bool)\n",
    "        # print(masked_indices.shape, all_expanded_masked_indices.shape) length/span x categories, length x categories \n",
    "        #now per row we need to randomly change some of the true and falses at the 1-mask_tie proportion\n",
    "        \n",
    "        #let's just loop over it. Not the best, I know, but it is the easiest\n",
    "        base_mask = masked_indices[:,0].clone()\n",
    "        num_masked = base_mask.sum().item()\n",
    "        true_indices = torch.nonzero(base_mask).squeeze()\n",
    "        false_indices = torch.nonzero(~base_mask).squeeze()\n",
    "        # mask_positions = torch.zeros((masked_indices.shape[1], num_masked*span), dtype=torch.long) #preallocate max size\n",
    "        q = 1-mask_tie\n",
    "        for i in range(masked_indices.shape[1]):\n",
    "            #now we find 10% of the true values and turn them to false, and then get the same amount and turn them from false to true\n",
    "            num_change = int(num_masked * q)\n",
    "            #randomly select num_change indices from true_indices and false_indices\n",
    "            true_change_indices = true_indices[torch.randperm(true_indices.numel())[:num_change]]\n",
    "            false_change_indices = false_indices[torch.randperm(false_indices.numel())[:num_change]]\n",
    "            #now set them\n",
    "            masked_indices[true_change_indices, i] = False\n",
    "            masked_indices[false_change_indices, i] = True\n",
    "            #also just do the steps to get all mask positions. This metric keeps the amount of true and false at least? then we also need to decide which ones are true mask which ones are random?\n",
    "            #for now we can make it work with mask_only = True, this way we ignore the other things\n",
    "            expanded_masked_indices = masked_indices[:,i].repeat_interleave(span)\n",
    "            # print(expanded_masked_indices, expanded_masked_indices.shape)\n",
    "            if extra > 0:\n",
    "                expanded_masked_indices = torch.cat([expanded_masked_indices, torch.zeros(extra, dtype=torch.bool)]) #so now we have a mask for every element in the span, so size length again\n",
    "            all_expanded_masked_indices[:,i] = expanded_masked_indices\n",
    "            \n",
    "            # all_mask_positions = torch.nonzero(masked_indices[:,i]).squeeze()*span\n",
    "            # print(all_mask_positions, all_mask_positions.shape)\n",
    "            # mask_positions[i] = (all_mask_positions.unsqueeze(1) + torch.arange(span)).flatten()\n",
    "            # print(mask_positions[i], mask_positions[i].shape) #was a dict because the size changes depending on how many elements are masked. Although it should be a set value..., yeah don't need dict\n",
    "        \n",
    "        # print(all_expanded_masked_indices.shape, all_expanded_masked_indices) #same size as initial data, just now tells you if true or false!\n",
    "        seq_unmask = torch.zeros((seq.shape[0], seq.shape[1]*2), dtype=torch.float)\n",
    "        seq_unmask[:, :seq.shape[1]] = seq\n",
    "        seq_unmask[:, seq.shape[1]:] = all_expanded_masked_indices.float()\n",
    "        seq_masked = seq_unmask.clone()\n",
    "        # seq_masked = torch.zeros((seq.shape[0], seq.shape[1]*2), dtype=torch.float) #this should be a faster way to clone\n",
    "        # seq_masked[:, :seq.shape[1]] = seq\n",
    "        # seq_masked[:, seq.shape[1]:] = all_expanded_masked_indices.float()\n",
    "        \n",
    "        # seq_unmask = torch.cat([seq, all_expanded_masked_indices.float()], dim=1)\n",
    "        # seq_masked = seq_unmask.clone()\n",
    "        num_channels = seq.shape[1]\n",
    "        seq_masked[:, :num_channels] = seq_masked[:, :num_channels] * (~all_expanded_masked_indices).float()\n",
    "        if span > 1 and extra_append > 0:\n",
    "            seq_masked = seq_masked[:-extra_append]\n",
    "            seq_unmask = seq_unmask[:-extra_append]\n",
    "        return seq_masked, seq_unmask #return the masked sequence and the unmasked sequence\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f580d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pct=0.3\n",
    "replace_with_N=True\n",
    "span=2\n",
    "mask_only=True\n",
    "stype='category'\n",
    "weights=None\n",
    "mask_tie=0.5\n",
    "num_categories = 10\n",
    "seq = torch.ones((30,num_categories))\n",
    "\n",
    "seq_masked, seq_unmask = mask_seq(seq, mask_pct=mask_pct, replace_with_N=replace_with_N, span=span, stype=stype, weights=weights, mask_only=mask_only, mask_tie=mask_tie)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "537edc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok so by changing this, it will actually be incredibly fast, no need for loops!! This is much better!\n",
    "#can also rewrite so much of it!!\n",
    "\n",
    "import torch\n",
    "def mask_seq(seq, mask_pct=0.15, replace_with_N=True, span=1, stype='category', weights=None, mask_only=False, mask_tie=1):\n",
    "    \"\"\"This function will mask the sequence data, it does the BERT masking where you do 80% truly masked, 10% random, 10% unchanged\n",
    "    Note that for random replacement, it cannot be the N token, sicne it's very rare anyways, always random nucleotide!\n",
    "    Args:\n",
    "        seq: the sequence to mask, this is a tensor of shape (length, N) if categorical, or (length,1) if continuous, N is the number of classes (5 for ohe nucleotide data)\n",
    "        mask_pct: the percentage of the sequence to mask, default is 0.15 or 15%\n",
    "        replace_with_N: whether to allow random replacement of values with N (for one hot encoded data). Keep True for other categorical data\n",
    "        span: the size of the span to mask, default is 1, so it masks every element independently, but can be larger to mask chunks of size span\n",
    "        stype: the type of sequence, 'category' for categorical like ohe nucleotide data and 'continuous' for continuous like raw accessibility data, default is 'category'\n",
    "        weights: the weights to use for weighting regions like peaks. default is None, must be a tensor of shape (length,) to weight the peaks higher for masking. can be the same as the seq itself\n",
    "        mask_only: whether to do the 10% unchanged and 10% random replacement, default is False. If True, will only do the 100% truly masked and leave the rest unchanged\n",
    "        mask_tie: how much masking is tied across categories. 1 means fully tied, so all tracks are masked the same, 0 means fully indepdendent masking across categories. If true, returns slightlly different values\n",
    "    Returns:\n",
    "        seq: the masked sequence, this is a tensor of shape (length, N+1) or N*2 if mask_tie is less than 1 if categorical or (length, 2) if continuous, where the last column is the mask track (only tells if masked, some are random or unchanged)\n",
    "        seq_unmask: the unmasked sequence, this is a tensor of shape (length, N+1) or N*2 if categorical or (length, 2), where the last column is the mask track (tells all elements that have been changed or goign to evaluate)\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(seq.shape) == 1: #if it's just a 1D tensor, we need to add a dimension for the mask track\n",
    "        seq = seq.unsqueeze(1) #so now it's shape length x 1, so we can concatenate other things\n",
    "    \n",
    "    extra_append = 0\n",
    "    if seq.shape[0]%span != 0:\n",
    "        #we append on values\n",
    "        remainder = seq.shape[0] % span\n",
    "        extra_append = span - remainder\n",
    "        seq = torch.cat([seq, torch.zeros((extra_append,seq.shape[1]), dtype=torch.float)]) #so now we can have a mask for every element in the span, so size length again\n",
    "    \n",
    "    num_elements = seq.shape[0]//span #chunks into chunks of size span\n",
    "\n",
    "    # Create a probability vector (one per token) and sample which tokens to mask\n",
    "    probability_matrix = torch.full((num_elements,), mask_pct) #size of length, defines for each element if we mask it or not\n",
    "    \n",
    "    #we can also weight peak regions more\n",
    "    if weights is not None:\n",
    "        assert mask_tie == 1, \"Weighting with weights is only supported for mask_tie=1 currently\"\n",
    "        weights = weights.squeeze()\n",
    "        assert weights.ndim == 1, f\"weights must be a 1D tensor, got {weights.shape}\"\n",
    "\n",
    "        #Trim weights to match the required size\n",
    "        if weights.shape[0] % span != 0:\n",
    "            #remove values until it is the right size\n",
    "            weights = weights[:num_elements*span]\n",
    "        \n",
    "        #compute mean over spans\n",
    "        weights = weights.view(num_elements, span).mean(1) #average the weights over the span, so now it's size length\n",
    "        \n",
    "        #normalize weights to have range 0.5 to 1.5\n",
    "        weights = torch.log(weights + 1) #log transform to reduce the scale of values\n",
    "        weights = (weights - weights.min()) / (weights.max() - weights.min()) + .5 #normalize to have different range, downweights small values, upweights large ones to almost 3x\n",
    "\n",
    "        #scale probability matrix by weights\n",
    "        probability_matrix = probability_matrix * weights #so now we have a weighted probability matrix, so we can mask more in peak regions\n",
    "        #and scale up probability matrix so that the mean is mask_pct\n",
    "        probability_matrix = probability_matrix / probability_matrix.mean() * mask_pct #so now we have a weighted probability matrix, so we can mask more in peak regions\n",
    "        \n",
    "        #clip to make sure between 0 and 1\n",
    "        probability_matrix = torch.clamp(probability_matrix, min=0, max=1) #clip to make sure between 0 and 1     \n",
    "    \n",
    "    masked_indices = torch.bernoulli(probability_matrix.float()).bool() #finds which indices to mask, so shape is length, and is True or False for each index\n",
    "\n",
    "    if mask_tie < 1: #have to implement own logic and loop, this is for the dependent tracks, otherwise unclear how to implement it, can make it like 0.999\n",
    "        assert mask_only, \"Not implemented for mask_only = False yet\"\n",
    "        extra = seq.shape[0] % span\n",
    "        \n",
    "        expanded_mask = masked_indices.repeat_interleave(span) #so now we have a mask for every element in the span, so size length again\n",
    "        \n",
    "        #first replicate masked_indices to be of shape length x num_categories\n",
    "        masked_indices = masked_indices.unsqueeze(1).repeat(1, seq.shape[1])\n",
    "        all_expanded_masked_indices = torch.zeros((seq.shape[0], seq.shape[1]), dtype=torch.bool)\n",
    "        # print(masked_indices.shape, all_expanded_masked_indices.shape) length/span x categories, length x categories \n",
    "        #now per row we need to randomly change some of the true and falses at the 1-mask_tie proportion\n",
    "        \n",
    "        #let's just loop over it. Not the best, I know, but it is the easiest\n",
    "        base_mask = masked_indices[:,0].clone()\n",
    "        num_masked = base_mask.sum().item()\n",
    "        true_indices = torch.nonzero(base_mask).squeeze()\n",
    "        false_indices = torch.nonzero(~base_mask).squeeze()\n",
    "        \n",
    "        #now expand the base mask to full size\n",
    "        expanded_base_mask = base_mask.repeat_interleave(span)\n",
    "        if extra > 0:\n",
    "            expanded_base_mask = torch.cat([expanded_base_mask, torch.zeros(extra, dtype=torch.bool)]) #so now we have a mask for every element in the span, so size length again\n",
    "        \n",
    "        #now we repeat it to make same size as all\n",
    "        all_expanded_mask = expanded_base_mask.unsqueeze(1).repeat(1, seq.shape[1])\n",
    "        print(all_expanded_mask.shape, all_expanded_mask, sep='\\n')\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd4789bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 10])\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "mask_seq(seq, mask_pct=mask_pct, replace_with_N=replace_with_N, span=span, stype=stype, weights=weights, mask_only=mask_only, mask_tie=mask_tie)\n",
    "#currently haven't yuet implemented the part where it differs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60e4a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_seq(seq, mask_pct=0.15, replace_with_N=True, span=1, stype='category', weights=None, mask_only=False, mask_tie=1):\n",
    "    \"\"\"This function will mask the sequence data, it does the BERT masking where you do 80% truly masked, 10% random, 10% unchanged\n",
    "    Note that for random replacement, it cannot be the N token, sicne it's very rare anyways, always random nucleotide!\n",
    "    Args:\n",
    "        seq: the sequence to mask, this is a tensor of shape (length, N) if categorical, or (length,1) if continuous, N is the number of classes (5 for ohe nucleotide data)\n",
    "        mask_pct: the percentage of the sequence to mask, default is 0.15 or 15%\n",
    "        replace_with_N: whether to allow random replacement of values with N (for one hot encoded data). Keep True for other categorical data\n",
    "        span: the size of the span to mask, default is 1, so it masks every element independently, but can be larger to mask chunks of size span\n",
    "        stype: the type of sequence, 'category' for categorical like ohe nucleotide data and 'continuous' for continuous like raw accessibility data, default is 'category'\n",
    "        weights: the weights to use for weighting regions like peaks. default is None, must be a tensor of shape (length,) to weight the peaks higher for masking. can be the same as the seq itself\n",
    "        mask_only: whether to do the 10% unchanged and 10% random replacement, default is False. If True, will only do the 100% truly masked and leave the rest unchanged\n",
    "        mask_tie: how much masking is tied across categories. 1 means fully tied, so all tracks are masked the same, 0 means fully indepdendent masking across categories. If true, returns slightlly different values\n",
    "    Returns:\n",
    "        seq: the masked sequence, this is a tensor of shape (length, N+1) or N*2 if mask_tie is less than 1 if categorical or (length, 2) if continuous, where the last column is the mask track (only tells if masked, some are random or unchanged)\n",
    "        seq_unmask: the unmasked sequence, this is a tensor of shape (length, N+1) or N*2 if categorical or (length, 2), where the last column is the mask track (tells all elements that have been changed or goign to evaluate)\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(seq.shape) == 1: #if it's just a 1D tensor, we need to add a dimension for the mask track\n",
    "        seq = seq.unsqueeze(1) #so now it's shape length x 1, so we can concatenate other things\n",
    "    \n",
    "    extra_append = 0\n",
    "    if seq.shape[0]%span != 0:\n",
    "        #we append on values\n",
    "        remainder = seq.shape[0] % span\n",
    "        extra_append = span - remainder\n",
    "        seq = torch.cat([seq, torch.zeros((extra_append,seq.shape[1]), dtype=torch.float)]) #so now we can have a mask for every element in the span, so size length again\n",
    "    \n",
    "    num_elements = seq.shape[0]//span #chunks into chunks of size span\n",
    "\n",
    "    # Create a probability vector (one per token) and sample which tokens to mask\n",
    "    probability_matrix = torch.full((num_elements,), mask_pct) #size of length, defines for each element if we mask it or not\n",
    "    \n",
    "    #we can also weight peak regions more\n",
    "    if weights is not None:\n",
    "        assert mask_tie == 1, \"Weighting with weights is only supported for mask_tie=1 currently\"\n",
    "        weights = weights.squeeze()\n",
    "        assert weights.ndim == 1, f\"weights must be a 1D tensor, got {weights.shape}\"\n",
    "\n",
    "        #Trim weights to match the required size\n",
    "        if weights.shape[0] % span != 0:\n",
    "            #remove values until it is the right size\n",
    "            weights = weights[:num_elements*span]\n",
    "        \n",
    "        #compute mean over spans\n",
    "        weights = weights.view(num_elements, span).mean(1) #average the weights over the span, so now it's size length\n",
    "        \n",
    "        #normalize weights to have range 0.5 to 1.5\n",
    "        weights = torch.log(weights + 1) #log transform to reduce the scale of values\n",
    "        weights = (weights - weights.min()) / (weights.max() - weights.min()) + .5 #normalize to have different range, downweights small values, upweights large ones to almost 3x\n",
    "\n",
    "        #scale probability matrix by weights\n",
    "        probability_matrix = probability_matrix * weights #so now we have a weighted probability matrix, so we can mask more in peak regions\n",
    "        #and scale up probability matrix so that the mean is mask_pct\n",
    "        probability_matrix = probability_matrix / probability_matrix.mean() * mask_pct #so now we have a weighted probability matrix, so we can mask more in peak regions\n",
    "        \n",
    "        #clip to make sure between 0 and 1\n",
    "        probability_matrix = torch.clamp(probability_matrix, min=0, max=1) #clip to make sure between 0 and 1     \n",
    "    \n",
    "    masked_indices = torch.bernoulli(probability_matrix.float()).bool() #finds which indices to mask, so shape is length//span, and is True or False for each index\n",
    "\n",
    "    if mask_tie < 1: #have to implement own logic and loop, this is for the dependent tracks, otherwise unclear how to implement it, can make it like 0.999? should actually work for mask only true if mask tie is 1\n",
    "        assert mask_only, \"Not implemented for mask_only = False yet\"\n",
    "        extra = seq.shape[0] % span\n",
    "\n",
    "        all_masked_indices = masked_indices.unsqueeze(1).repeat(1, seq.shape[1])\n",
    "        # print(all_masked_indices.shape) #shape is length//span x num_categories\n",
    "        #now we find which ones will change based on mask_tie and only changing the masks to be unmasked\n",
    "        change = masked_indices & (torch.rand(masked_indices.shape) < (1 - mask_tie))\n",
    "        # print(change.shape, change) #shape is length//span\n",
    "        flip = change.unsqueeze(1) & (torch.rand_like(all_masked_indices.float()) < 0.10)\n",
    "        all_masked_indices = all_masked_indices & (~flip)\n",
    "        return flip, change, all_masked_indices\n",
    "        # all_masked_indices\n",
    "        for i in range(change):\n",
    "            2\n",
    "        \n",
    "        expanded_mask = masked_indices.repeat_interleave(span) #so now we have a mask for every element in the span, so size length again\n",
    "        all_expanded_mask = expanded_base_mask.unsqueeze(1).repeat(1, seq.shape[1])\n",
    "        \n",
    "        #first replicate masked_indices to be of shape length x num_categories\n",
    "        masked_indices = masked_indices.unsqueeze(1).repeat(1, seq.shape[1])\n",
    "        all_expanded_masked_indices = torch.zeros((seq.shape[0], seq.shape[1]), dtype=torch.bool)\n",
    "        # print(masked_indices.shape, all_expanded_masked_indices.shape) length/span x categories, length x categories \n",
    "        #now per row we need to randomly change some of the true and falses at the 1-mask_tie proportion\n",
    "        \n",
    "        #let's just loop over it. Not the best, I know, but it is the easiest\n",
    "        base_mask = masked_indices[:,0].clone()\n",
    "        num_masked = base_mask.sum().item()\n",
    "        true_indices = torch.nonzero(base_mask).squeeze()\n",
    "        false_indices = torch.nonzero(~base_mask).squeeze()\n",
    "        \n",
    "        #now expand the base mask to full size\n",
    "        expanded_base_mask = base_mask.repeat_interleave(span)\n",
    "        if extra > 0:\n",
    "            expanded_base_mask = torch.cat([expanded_base_mask, torch.zeros(extra, dtype=torch.bool)]) #so now we have a mask for every element in the span, so size length again\n",
    "        \n",
    "        #now we repeat it to make same size as all\n",
    "\n",
    "        #now we find the number to change\n",
    "        num_change = int(num_masked * q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b2b8818",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pct=0.3\n",
    "replace_with_N=True\n",
    "span=2\n",
    "mask_only=True\n",
    "stype='category'\n",
    "weights=None\n",
    "mask_tie=0.5\n",
    "num_categories = 10\n",
    "seq = torch.ones((30,num_categories))\n",
    "flip,change,allmask = mask_seq(seq, mask_pct=mask_pct, replace_with_N=replace_with_N, span=span, stype=stype, weights=weights, mask_only=mask_only, mask_tie=mask_tie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5ba4206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15]), torch.Size([15, 10]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change.shape, flip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569d179e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False,  True, False,  True, False, False,\n",
       "        False, False,  True, False, False])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change #only the 5th element in the sequence can have any true for example, so first 4 rows should be false only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e340c555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False,  True, False, False,  True, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False,  True, False, False,  True, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1a3681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [ True,  True,  True, False,  True,  True, False,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [False,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [ True,  True,  True, False,  True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allmask #indeed see some True becoming false, otherwise rows are identical!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's finish tthe function\n",
    "\n",
    "def mask_seq(seq, mask_pct=0.15, replace_with_N=True, span=1, stype='category', weights=None, mask_only=False, mask_tie=1):\n",
    "    \"\"\"This function will mask the sequence data, it does the BERT masking where you do 80% truly masked, 10% random, 10% unchanged\n",
    "    Note that for random replacement, it cannot be the N token, sicne it's very rare anyways, always random nucleotide!\n",
    "    Args:\n",
    "        seq: the sequence to mask, this is a tensor of shape (length, N) if categorical, or (length,1) if continuous, N is the number of classes (5 for ohe nucleotide data)\n",
    "        mask_pct: the percentage of the sequence to mask, default is 0.15 or 15%\n",
    "        replace_with_N: whether to allow random replacement of values with N (for one hot encoded data). Keep True for other categorical data\n",
    "        span: the size of the span to mask, default is 1, so it masks every element independently, but can be larger to mask chunks of size span\n",
    "        stype: the type of sequence, 'category' for categorical like ohe nucleotide data and 'continuous' for continuous like raw accessibility data, default is 'category'\n",
    "        weights: the weights to use for weighting regions like peaks. default is None, must be a tensor of shape (length,) to weight the peaks higher for masking. can be the same as the seq itself\n",
    "        mask_only: whether to do the 10% unchanged and 10% random replacement, default is False. If True, will only do the 100% truly masked and leave the rest unchanged\n",
    "        mask_tie: how much masking is tied across categories. 1 means fully tied, so all tracks are masked the same, 0 means fully indepdendent masking across categories. If true, returns slightlly different values\n",
    "    Returns:\n",
    "        seq: the masked sequence, this is a tensor of shape (length, N+1) or N*2 if mask_tie is less than 1 if categorical or (length, 2) if continuous, where the last column is the mask track (only tells if masked, some are random or unchanged)\n",
    "        seq_unmask: the unmasked sequence, this is a tensor of shape (length, N+1) or N*2 if categorical or (length, 2), where the last column is the mask track (tells all elements that have been changed or goign to evaluate)\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(seq.shape) == 1: #if it's just a 1D tensor, we need to add a dimension for the mask track\n",
    "        seq = seq.unsqueeze(1) #so now it's shape length x 1, so we can concatenate other things\n",
    "    \n",
    "    extra_append = 0\n",
    "    if seq.shape[0]%span != 0:\n",
    "        #we append on values\n",
    "        remainder = seq.shape[0] % span\n",
    "        extra_append = span - remainder\n",
    "        seq = torch.cat([seq, torch.zeros((extra_append,seq.shape[1]), dtype=torch.float)]) #so now we can have a mask for every element in the span, so size length again\n",
    "    \n",
    "    num_elements = seq.shape[0]//span #chunks into chunks of size span\n",
    "\n",
    "    # Create a probability vector (one per token) and sample which tokens to mask\n",
    "    probability_matrix = torch.full((num_elements,), mask_pct) #size of length, defines for each element if we mask it or not\n",
    "    \n",
    "    #we can also weight peak regions more\n",
    "    if weights is not None:\n",
    "        assert mask_tie == 1, \"Weighting with weights is only supported for mask_tie=1 currently\"\n",
    "        weights = weights.squeeze()\n",
    "        assert weights.ndim == 1, f\"weights must be a 1D tensor, got {weights.shape}\"\n",
    "\n",
    "        #Trim weights to match the required size\n",
    "        if weights.shape[0] % span != 0:\n",
    "            #remove values until it is the right size\n",
    "            weights = weights[:num_elements*span]\n",
    "        \n",
    "        #compute mean over spans\n",
    "        weights = weights.view(num_elements, span).mean(1) #average the weights over the span, so now it's size length\n",
    "        \n",
    "        #normalize weights to have range 0.5 to 1.5\n",
    "        weights = torch.log(weights + 1) #log transform to reduce the scale of values\n",
    "        weights = (weights - weights.min()) / (weights.max() - weights.min()) + .5 #normalize to have different range, downweights small values, upweights large ones to almost 3x\n",
    "\n",
    "        #scale probability matrix by weights\n",
    "        probability_matrix = probability_matrix * weights #so now we have a weighted probability matrix, so we can mask more in peak regions\n",
    "        #and scale up probability matrix so that the mean is mask_pct\n",
    "        probability_matrix = probability_matrix / probability_matrix.mean() * mask_pct #so now we have a weighted probability matrix, so we can mask more in peak regions\n",
    "        \n",
    "        #clip to make sure between 0 and 1\n",
    "        probability_matrix = torch.clamp(probability_matrix, min=0, max=1) #clip to make sure between 0 and 1     \n",
    "    \n",
    "    masked_indices = torch.bernoulli(probability_matrix.float()).bool() #finds which indices to mask, so shape is length//span, and is True or False for each index\n",
    "\n",
    "    if mask_tie < 1: #have to implement own logic and loop, this is for the dependent tracks, otherwise unclear how to implement it, can make it like 0.999? should actually work for mask only true if mask tie is 1\n",
    "        assert mask_only, \"Not implemented for mask_only = False yet\"\n",
    "\n",
    "        all_masked_indices = masked_indices.unsqueeze(1).repeat(1, seq.shape[1])\n",
    "        # print(all_masked_indices.shape) #shape is length//span x num_categories\n",
    "        #now we find which ones will change based on mask_tie and only changing the masks to be unmasked\n",
    "        change = masked_indices & (torch.rand(masked_indices.shape) < (1 - mask_tie))\n",
    "        # print(change.shape, change) #shape is length//span\n",
    "        flip = change.unsqueeze(1) & (torch.rand_like(all_masked_indices.float()) < 0.10)\n",
    "        all_masked_indices = all_masked_indices & (~flip)\n",
    "        #and expand to full size\n",
    "        all_expanded_masked_indices = all_masked_indices.repeat_interleave(span, dim=0)\n",
    "        # if extra > 0:\n",
    "        #     all_expanded_masked_indices = torch.cat([all_expanded_masked_indices, torch.zeros((extra, seq.shape[1]), dtype=torch.bool)]) #so now we have a mask for every element in the span, so size length again\n",
    "        \n",
    "        #now we can create the masked and unmasked sequences\n",
    "        seq_unmask = torch.zeros((seq.shape[0], seq.shape[1]*2), dtype=torch.float)\n",
    "        seq_unmask[:, :seq.shape[1]] = seq\n",
    "        seq_unmask[:, seq.shape[1]:] = all_expanded_masked_indices.float()\n",
    "        seq_masked = seq_unmask.clone()\n",
    "\n",
    "        seq_masked[:, :seq.shape[1]] = seq_masked[:, :seq.shape[1]] * (~all_expanded_masked_indices).float()\n",
    "        if span > 1 and extra_append > 0:\n",
    "            seq_masked = seq_masked[:-extra_append]\n",
    "            seq_unmask = seq_unmask[:-extra_append]\n",
    "        return seq_masked, seq_unmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee18afbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([30, 20]), torch.Size([30, 20]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_mask, seq_unmask = mask_seq(seq, mask_pct=mask_pct, replace_with_N=replace_with_N, span=span, stype=stype, weights=weights, mask_only=mask_only, mask_tie=mask_tie)\n",
    "seq_mask.shape, seq_unmask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca15b1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_mask.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c58f8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_unmask.int() #the original data, left half should all be 1, right half tells you if masked or not!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "025aad1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 10]), torch.Size([20, 10]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it looks good, let's see what happens if span is 7\n",
    "mask_pct=0.3\n",
    "replace_with_N=True\n",
    "span=3\n",
    "mask_only=True\n",
    "stype='category'\n",
    "weights=None\n",
    "mask_tie=0.5\n",
    "num_categories = 5\n",
    "seq = torch.ones((20,num_categories))\n",
    "seq_mask, seq_unmask = mask_seq(seq, mask_pct=mask_pct, replace_with_N=replace_with_N, span=span, stype=stype, weights=weights, mask_only=mask_only, mask_tie=mask_tie)\n",
    "seq_mask.shape, seq_unmask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7b792397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_mask.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8e5df86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_unmask.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934d3bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0, 1, 0, 1, 1, 1],\n",
       "        [0, 1, 0, 0, 0, 1, 0, 1, 1, 1],\n",
       "        [0, 1, 0, 0, 0, 1, 0, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looks and works exactly as expected, but mask tie seems off??\n",
    "seq_mask, seq_unmask = mask_seq(seq, mask_pct=mask_pct, replace_with_N=replace_with_N, span=span, stype=stype, weights=weights, mask_only=mask_only, mask_tie=mask_tie)\n",
    "seq_mask.int() #ok this seems right, mask tie is just way too rare??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d570587f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 0, 1, 1, 1, 0, 1],\n",
       "        [0, 0, 0, 1, 0, 1, 1, 1, 0, 1],\n",
       "        [0, 0, 0, 1, 0, 1, 1, 1, 0, 1],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_mask, seq_unmask = mask_seq(seq, mask_pct=mask_pct, replace_with_N=replace_with_N, span=span, stype=stype, weights=weights, mask_only=mask_only, mask_tie=mask_tie)\n",
    "seq_mask.int() #ok this seems right, mask tie is just way too rare?? I think this is fine actually? let's just run it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
